{"posts":[{"title":"人际关系的构成","content":"亲密关系第一章，人际关系的构成。 人际关系的构成 人类是非常社会化的动物，如果剥夺了和他人的紧密接触，会令人很痛苦，人类社会属性的核心部分正是对亲密关系的需要。 亲密关系的性质 亲密关系是一个复杂的概念，与之对应的是泛泛之交，了解两者之间的差异，可以让我们更好的认识什么是亲密关系。第一章第一节介绍道“亲密关系和泛泛之交至少在六个方面存在程度差异：了解（knowledge）、关心（care）、相互依赖性（interdependence）、相互一致性（mutuality）、信任（trust）和承诺（commitment）”。 了解与关心：亲密的伴侣之间熟知彼此的经历、爱好、情感和心愿；关心对方并能从对方身上感受到更多的关爱。如果人们认为自己的伴侣了解、理解并欣赏自己，亲密程度就会增加。 相互依赖性：彼此需要的成都和影响对方的程度。人际关系变得相互依赖时，一方的行为在影响自己的同时也会影响对方。 相互一致性：认同双方在生活上的融合，称谓上从“我”变化到“我们”常常标志着人际关系发展到微妙而又意义重大的阶段。 信任：保持信任，相信亲密关系不会带来伤害，期待对方会善待和尊重自己。 承诺：亲密伴侣通常会承诺他们的亲密关系，希望他们的关系能持续到地老天荒，并为此不惜投入大量的时间、人力和物力。 这六个方面未必 全部出现在亲密关系中，任何一个要素都可以单独出现于亲密关系中。但一般而言，最令人满意和最有意义的亲密关系应当包含以上所有六个方面。 亲密关系为什么值得关注？ 事实上，与他人建立亲密关系的普遍而又强烈的内驱力，或许是人类的一种本性。如果我们要正常生活，保持身心健康，就要在长久而关爱的亲密关系中经常与伴侣愉快地交往。在亲密关系中包含有人的归属需要（need to belong），如果这种需要得不到满足，就会有各种问题。 因此，为了满足归属需要，我们努力与他人建立和维持亲密的人际关系，我们还期待与那些了解、关心我们的人交往和沟通。归属需要本质上和我们伴侣是谁并无太大的关系，只要他们能给予我们持续的关爱和包容，我们的归属需要就能得到满足。因而，即使一段重要的亲密关系终结，我们也往往能找到替代伴侣满足我们的归属需要。 归属需要是人类长期演化的产物，逐渐成为所有人的自然倾向。 另一方面，当我们珍视的人际关系出现危机时，我们往往会魂不守舍，进而变得癫狂痴迷，充分表明这段亲密关系对我们的重要性。 影响人际关系的因素 文化的影响 不断变化发展的文化，是规范亲密关系的社会标准。 文化标准是人们建立人际关系的基石，它影响着人们对人际关系的期望，限定了正常的人际关系模式。当文化环境发生了重大变化，人们的人际关系也会发生变化。例如：越来越少的人结婚成家；结婚的年龄越来越大；婚前同居越来越普遍；未婚先育现象增加。 支配亲密关系的规范即社会文件变化的原因有很多： 经济的发展：社会工业化程度越高、越富足，就能越接纳单身、包容离婚和支持晚婚。教育和财政资源额充裕，足以让人们更为独立。 **个人主义：支持自我表现，重视个人成就。**这种对自我实现的重视让我们期望从亲密关系中获取到更多的东西——更多的快乐和享受，更少的麻烦和付出。 新科技：现代生殖技术（如人工授精、体外受孕）能让妇女在掌控生育权，独立生育后代。现代通讯科技的发展也改变了人们亲密关系交往的方式。在互联网上，我们能无限地接触聊天各一方的伙伴，自由地披露和掩盖消息，更有时间静坐下来思考我们的主张。影响人们面对面交往的一些重要品质，如相貌吸引力、地理位置的邻近等，在网络关系中不太重要。 性别比率的变化：社会规范的演变总是要满足那些掌握经济、政治和法律权力的强势人权的利益。而当今社会文化中，强势人群就是男性。因此当性别比率发生变化时，人际关系的规范总是向着有利于男性的方向变化。性别比率居高，女性较少时，男性得到女性的芳心想要长相思守时，便会鼓励女性成为家庭妇女，从而使她在经济上依赖自己，并且会反对离婚。当性别比率较低时，女性较多，男人就不太想被一个女人拴住，妇女就得工作，推迟结婚，男性不满意的话还可方便地离婚。 个人经历的影响 如果大人对孩子的照料无法预测而且并不持续，照料者有时热情关注，有时却心不在焉、焦急烦躁，有时根本就不出现。这些孩子就会对他人产生焦虑、复杂的情感，这种依恋类型就是焦虑—矛盾型（anxiousambivalent）。这些孩子由于不能确定照料者是否以及何时会回来关照自己，与他人的关系就会变得紧张和过分依赖，表现出对他人的过分贪求。 成人有四种依恋类型： 安全型 感情上很容易接近他人。不管是依赖他们还是被人依赖都感觉心安。不会担忧独处和不为人接纳。 痴迷型 希望在亲密关系中投入全部的感情，但经常发现他们并不乐意把关系发展到如自己期望的那般亲密。没有亲密关系让我不安，有时还担心伴侣不会像我看重他一样看重我。 恐惧型 和他人发生亲密接触使我不安。感情上我渴望亲密关系，但很难完全相信他人或依赖他人。担心自己和他人变得太亲密会受到伤害。 疏离型 即使没有亲密关系也安心。对我而言，独立和自给自足更加重要，我不喜欢依赖别人或让人依赖。 依恋类型看似是人们对人际关系的适应行为，这种适应大部分是从与他人交往的经验中习得的。我们带入新的人际关系的癖好和观点，部分来自于与以前伴侣的交往经历，这是人际关系适应行为最好的例证。 依恋类型不断地受到我们成人后经历的影响。依恋类型既然是习得的，就可能发生变化。随着时间的推移，依恋类型的确会发生新的改变。一次悲痛欲绝的分手会让原本安全型的人不再安全，一段如胶似漆的恋情也能慢慢让回避亲密的人不再怀疑和戒备亲密感情。 我们幼时对人际交往价值和他人是否可信的观念，起源于我们与照料者的交往，由于运气的好坏，我们就此走向了信任或恐惧的亲密关系之路。这段历程永远不会停止，同行者随后给予的阻碍或帮助会改变我们亲密关系的方向和进程。视乎人际交往经验的不同，我们习得的依恋类型既可随时间发生变化，也可永久保持稳定。 个体差异的影响 依恋类型一旦形成，就决定了人们与他人交往时显示出的独特个体特征。每个人都是由不同的经验和特质组合而成的独特个体。这些经验和特质又塑造了不同的能力和偏好，正是这些差异影响了我们的亲密关系。 这一节重点介绍了四种不同类型个体差异：性别差异、性认同差异、人格差异和自尊差异。 一般人对男女两性的认识都存在刻板印象，把两性在兴趣、风格和能力上的差别过度夸大了。但是实际上，两性在性别差异上，两性之间的兴趣和才能重合的程度很大。其实，“性别差异”这种说法具有误导性，因为它只强调两性之间的差异性，而忽略相似性，这容易使人产生错误的认识。所以，宣扬男人和女人来自不同的星球根本就是误导人，因为它根本就不对。“研究不支持男人和女人来自不同文化的观点，更别提来自不同的世界了”。个体差异才是影响人际交往的更重要的力量。无论男女，人们在很多方面彼此各异（例如依恋类型），这些差异一般都比性别差异更能影响人际关系。 性认同差异指的是由文化和教育引起的两性在社会性和心理上的差异，或者叫社会性别。 性认同最好的例子是性别角色（gender roles），即社会文化所期待的男女两性应有的“正常”行为模式。男人当然应该有“男子气”，他们应该自信、独立、果敢、能干、好强。女人就应该有“女人味”，热情、敏感、多情、友善。 大多数人都认为男人和女人是相反的两性，因此全世界都不同程度地期望男性和女性有各自不同的独特社会行为。然而遗传在决定人们自信或友善的倾向时只起到四分之一到三分之一的作用，大部分行为是后天习得的。 然而，刻板印象并不像你认为的那般符合现实中的人；只有一半人的特质刚好符合性别角色期望（Bem，1993）。相当多的人（约35%）并不是完全的“男子气”或“女人味”，他们既自信又热情，既敏感又独立。这些人同时拥有传统上认为应该属于男性和女性的特质，因而被称为双性化（androgynous）。 把与任务有关的“男子气”的才能称为工具性（instrumental）特质，把与社交和情感有关的“女人味”的技能称为表达性（expressive）特质，在研究中更为准确。 表达性低的人（不怎么热情、温柔、敏感）不太容易表现出热情和温柔；也不怎么充满深情。低工具性的人（缺乏自信和个人魄力的人）往往不如那些高工具性的人（任务导向的技能高的人）自尊程度高和适应能力强。 工具性和表达性都是有价值的特质，幸福、适应能力强、有效率和心理健康的人士通常都同时拥有这两组技能。详而言之，那些拥有满意、幸福伴侣的理想夫妻，他们的工具性和表达性通常都很高。在实际生活中，如果人们可以选择的话，大多数人更喜欢双性化的恋人或配偶，而不是完全男子气或完全女人味的恋人或配偶。 人类本性的影响 演化学的观点还能用来解释人们在短期和长期性行为策略上的不同（Buss &amp; Schmitt，1993）。男女双方在短期的艳遇和长期、稳定的亲密关系中所追求的异性的特征存在差别。详而言之，男人比女人更渴望短期的性关系；更嗜好与多个伴侣保持短期的风流关系，建立新的亲密关系后，也比女性更早地发生性关系（Schmitt，2005）。结果是，男人在猎艳时，看起来性感且“容易”得手的女人特别有吸引力（Schmitt et al.，2001）。然而，如果男人想结婚安顿下来，常常偏好贞洁的女人作为将来的伴侣，即使这个男人仍然认为在偶然的性关系中放荡的女子是最理想的目标（Buss，2000）。男人还常常追求年轻、漂亮的妻子。当男人想确立长期的亲密关系时，比女人更看重外貌，随着年纪增长，老男人更加喜欢与更年轻的女子结婚（Kenrick &amp; Keefe，1992）。 人际互动的影响 人际关系的最后一个构成要素是两人之间的互动。化学家常常以这种方式来思考：把两种元素结合在一起（比如氢和氧）就得到化合物（如水），这个化合物与组成它的任何部分都不一样。类似地，两个人创造出的人际关系来自于每个人的贡献，但它也许与这两个人其他的人际关系不太相似。就个体而言，伴侣各方不可避免地会面临情绪的波动，健康和精力的变化；那么当他们互动时，他们彼此的相互影响就可能产生千变万化的结果。 总之，人际关系是由多种影响因素构成的，其范围从当前文化的流行时尚到人类种族的基本属性，非常广泛。在这些一般的影响因素之外，还有很多个体独有的影响因素如人格和经验，它们有些是习得的，有些是遗传的。最终，两个来自同一星球，但在很多方面存在一定程度差异的人，开始了他们的互动。互动的结果或许令人沮丧，或许令人满意。但这种可能的互动结果总是让人着迷，这就是人际关系的构成。 人际关系的消极面 的确，有些人总是担忧别人会拒绝他们，忧心忡忡地等待亲密关系的破裂（Romero-Canyas et al.，2009）。但无论我们的担忧是臆想或现实的，我们都有可能经历人际关系带来的意外的、令人沮丧的伤害（Miller，1997b）。亲密关系中失望和烦恼的恶果会严重地影响我们的身体健康（Whisman et al.，2010）。 那么为什么还要冒这种风险呢？因为我们人类是社会化的动物，我们需要彼此。没有与他人的亲密联系，我们就会枯萎和死亡。 ","link":"https://Angus1996.github.io/post/du-lesslessqin-mi-guan-xi-greatergreater-di-yi-zhang-ren-ji-guan-xi-de-gou-cheng/"},{"title":"左连接也有笛卡尔积","content":"总结一下数据分析中常用的联表查询方式。 什么是笛卡尔积？ 笛卡尔积在数学上，是两个集合X和Y的笛卡尔积（Cartesian product），又称直积。 在 SQL 查询中，笛卡尔积又叫 [cross] join，是两表连接的一种方式。 假设表A和表B的数据如下所示： 表A 表B id id 1 1 0 0 1 0 3 2 执行以下语句后 SELECT a.id, b.id FROM table_a AS a cross join table_b AS b; a_id b_id 1 1 1 0 1 0 1 2 0 1 0 0 0 0 0 2 1 1 1 0 1 0 1 2 3 1 3 0 3 0 3 2 即 A 表所有元素与 B 表所有元素进行组合。假设 A 表的行数为 m，B 表的行数为 n，则返回的行数为 m*n。 1. 内连接 内连接 INNER JOIN 是最常用的连接操作。求左右两张表的交集，从笛卡尔积中挑出ON子句条件成立的记录。也可以直接写作 JOIN 。 同样是上面的例子，执行以下语句后 SELECT a.id, b.id FROM table_a AS a inner join table_b AS b ON a.id=b.id; 查询结果如下： a_id b_id 1 1 1 0 1 0 1 2 0 1 0 0 0 0 0 2 1 1 1 0 1 0 1 2 3 1 3 0 3 0 3 2 查询返回的结果只有 4 条。因为 A 表在连接时的重复 key 值为2条，B表在连接时重复的 key 值为 2 条记录，因此总共查询返回 4 条。 2. 外连接 外连接可以分为左连接和右连接。左右是根据主表在连接时的位置而定的。 2.1 左连接 左连接即左表为主表。左连接是求主表和另一张表的交集外加主表剩下的数据。从笛卡尔积的角度讲，就是先从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表——主表中剩余的记录。 有一些博客说左连接返回的行数和左表行数一致不完全正确，这种情况仅限于左右表连接时的key值唯一。 左连接可以写作 LEFT [OUTER] JOIN，即 OUTER 可以省略。 执行以下 SQL 查询语句后 SELECT a.id, b.id FROM table_a AS a left outer join table_b AS b ON a.id=b.id; a_id b_id 1 1 0 0 0 0 1 1 3 NULL 最后一行即为左表剩余的记录 2.2 右连接 右连接即右表为主表。右连接同样是求主表和另一张表的交集外加主表剩下的数据，只是这时的主表是右表。从笛卡尔积的角度来说，就是先从笛卡尔积中挑出ON子句条件成立的记录，然后加上右表——主表中剩余的记录。 右连接可以写作 RIGHT [OUTER] JOIN，同样可以省略 OUTER。 执行以下 SQL 查询语句后 SELECT a.id, b.id FROM table_a AS a right outer join table_b AS b ON a.id=b.id; a_id b_id 1 1 0 0 0 0 1 1 NULL 2 最后一行即为右表剩余的记录。 3. 全连接 FULL OUTER JOIN，返回左右表中的所有记录。从笛卡尔积的角度来讲，就是从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表和右表剩余的记录。 执行以下 SQL 查询语句后 SELECT a.id, b.id FROM table_a AS a full outer join table_b AS b ON a.id=b.id; a_id b_id 1 1 0 0 0 0 1 1 3 NULL NULL 2 总结 SQL 中多表查询 JOIN 操作是常用操作，需要对其中的笛卡尔积有较好的理解。千万不要认为外连接查询返回的行数就是主表的行数！！！ ","link":"https://Angus1996.github.io/post/zuo-lian-jie-ye-you-di-qia-er-ji/"},{"title":"毕业近况","content":"更新一波博客，聊聊近况。 好久没有更新博客了，上一次发文还是在上次，距今已有六个月左右。工作几个月后，逐渐适应了工作节奏以及杭州的生活。 离开校园 毕业最快乐的一瞬间应该就是毕业论文交出去盲审那一刻，反反复复修改后，看自己的论文都会看吐。在发了一篇SCI论文后，硕士毕业论文在已发表的论文基础进行了深入的工作。也许是一心都想顺利毕业，实习期间看到的一篇博客后迸发出的 idea 正好用在了毕业论文上 。 功夫不负有心人，很荣欣毕业论文盲审的时候拿到了双A，事实上我也是一直以双A 为目标的。虽然我知道双 B 就能顺利毕业。自从本科毕业设计拿了优秀以后，我也想硕士毕业论文能做到最好，不给自己留下太多遗憾。若干年后，自己或者别人看到这篇论文，无论是正文、致谢还是参考文献，都不想被吐槽。 硕士毕业答辩那天，袁老去世的消息反复出现最终被证实，那一天我并没有答辩完的那种快乐。答辩完意味着我即将步入社会了，可是我相信我很难成为像袁老这么优秀的人了。 毕业旅行本来是想去厦门看看海，奈何疫情反复。那段时间厦门也有几例台湾来的新冠病毒患者。最好去西安看了看钟楼、鼓楼以及兵马俑等，也去非常火的大唐不夜城逛了逛。那几天天公不作美，一直下大雨，所以也没有去爬华山。 毕业典礼后搬东西回家的时候，导师给我最后的嘱托是“健康第一，保重身体”。在导师的培养下，在实验室呆了接近四年，还是很感激导师以及实验室学长学姐学弟学妹们的帮助的。虽然最后他们大部分都去了深圳广州，而我去了杭州，但那段时光会记住的。 前往杭州 2021年7月1日入职阿里，那天也是建党100周年。我选择这么一个时间点，是希望自己能够从头开始，抛弃过去的荣誉，好好打拼。 入职阿里的第一天就拥抱了变化。去了实习时候的组报到，被告知组织架构调整要去另一个组了。虽然很遗憾没能和认识的好朋友们一组，可去一个新组对我来说其实没有多大区别，毕竟我本来就是一个新人。而且我相信HRG 和 leader 考虑的时候，肯定也考虑了个人的特长。 新的组更加偏向于数据开发与设备攻防，工作内容就不说了。 去年实习还是在西溪 A 区，今年就搬到了 B 区。去年实习看着还没装修完的 B 区就心想在这楼里办公，离租的房子实在是太近了。事实上，如今的确和租房的小区只是隔了一条马路。每天步行十分钟就可以到工位，中午还能回去午休。 阿里的工作没有传说的 996 那种恐怖，我们部门更加偏向 995 ，周五可以早点下班而且都有双休。双休对于打工人来说太重要了，单休实在是太难恢复了。很高兴组里有个年纪相仿的师姐，带我认识了很多新朋友，每周六都会组织大家打羽毛球。我一度以为自己毕业后再也不会打羽毛球了，所以就将从大一开始陪伴我的羽毛球拍留在实验室。如今它又回到了我的手上。师姐也很喜欢健身，慢慢的我也开始每天早上都会去健身一个小时，淋个浴再去上班。园区有个健身房以及配套的淋浴房也方便了很多。 作为一个新人，学会融入团队、学会不懂就问，成长可以慢但不能过得浑浑噩噩、没有目标。 试用期三个月，九月底时候就转正了。由于去年实习转正答辩过一次，试用期便没有了答辩，互联网公司的制度上还是非常灵活的。 国庆回家 中秋和国庆挨得太近了，所以中秋并没有回家。今年中秋，买了几盒月饼送给对自己以及家里人帮助比较大的叔叔和舅舅。步入社会后，的确要慢慢学会各种礼仪了。 国庆回武汉的票没有想到那么难买，第一次参加抢票还是很紧张的。而且同学结婚是请了我当伴郎的，肯定要回去的。幸运的是抢到了一张票，虽然比较晚。那天在火车上，我看了一场非常温柔的日落。杭州这边感觉天黑的比武汉早，而且我现在吃晚饭也比学校时候晚，很难看到一场日落。 国庆回家后，挺珍惜每一天的。因为我知道下一次回来，很有可能就是过年了。一年能回家的机会也就两三次，所以也见了很多同学和朋友。请了两天年假，带爸妈去做了一次体检。阿里的父母体检福利还是挺不错的，如果需要自费，他们很有可能就不去了。 写在最后 在这个周五的晚上，又絮絮叨叨念了好久。在逐渐适应了工作和生活后，我想我还是需要坚持锻炼和学习，最好还能培养一些兴趣爱好。 未来留在杭州还是回武汉，且走且看。 ","link":"https://Angus1996.github.io/post/bi-ye-jin-kuang/"},{"title":"《统计数据会说谎》读后感","content":"很久没有更新博客了，一直在忙研究生的毕业设计和毕业论文。毕业论文上传盲审之后，每天放松之余花了一点时间阅读这本早就在书立中的《统计数据会说谎》。这本书共分为十章。 1.带有偏差的样本 经典案例：耶鲁大学1924届毕业生平均年收入高达25111美元。 该案例中的样本不具有代表性。25111的平均年收入仅仅能够代表地址明确、愿意公开收入的部分高收入群体。 统计结果受样本影响，抽样方法不合适会导致样本不具有代表性；样本的答案受到其他如政治倾向、个人隐私等因素影响也会导致统计结果不够真实。 随机样本要保证：在一个总体中每个人或每件事被抽到的概率是相等的。当纯随机抽样难度较大时，可以使用分层抽样进行替代。分组比例、每组内部随机样本的抽取都是分层抽样会存在偏差的地方。 任何情况下，统计结果都带有一定的偏差。 2.精挑细选的平均数 案例：XX小区住户平均年收入说法一是15000美元，说法二是3500美元。 平均数究竟是哪一种？——均值、中位数还是众数。 当数据呈现类似“正态分布”的特点，均值、中位数、众数差别不大；然而数据分布呈现倾斜状态时，均值和中位数相差甚远。 3.没有透露的小小数据 案例：使用多克斯牙膏后蛀牙减少了23%。 然而这一广告小字写明仅仅是12个用户参与测试。 只有试验的样本数目足够庞大时，平均数定律才是一个有用的描述或猜测。 观察的结果不代表作者的观点（如金西博士观察发现青少年的性行为是普遍存在的，是正常现象。然而这并不代表他“赞成”这一行为） 没有任何人能在任何方面达到绝对标准，好比抛100次硬币，几乎不可能50次正面50次反面。要搞清楚“正常的”和“理想的”。 在没有重要数据的情况下，不要轻易相信一个平均数、一张图表或者一条趋势线。否则，会盲目地根据平均气温选择露营地点而忽略了温差。 4.无事瞎忙 案例：Peter智商98，Linda智商101,&quot;正常水平&quot;为100。 Linda比较聪明，高于平均水平，Peter就不聪明？ 任何测验都有一定的误差：概率误差和标准误差。假如智力测验的误差为3%，Linda的智商就是101±3101 \\pm 3101±3 ，Peter的智商为98±398 \\pm 398±3。因此，对待智商和其他抽样结果应该看范围 ，要时刻谨记±\\pm± 号。 只有显现出来的差别有意义时才可称之为差别。如香烟的有毒成分差异很小，但最后一名却利用这种排名大肆宣传捞金。 5.惊人的图形 改变图标纵坐标和横坐标的比例、截短图表，可以将变动较小的数据夸张成波动幅度较大的效果。 6.一维图形 使用图画来表明数据时，尤其是数据之间的倍数关系时，使用巧妙的图形可以夸大数据之间的差距。 如一个钱袋表示30美元，再画一个两倍高的钱袋表示60美元，实际上的视觉效果却是4倍（宽、高都是两倍）。如果图像在现实中是立体的，如高炉，甚至视觉上达到了8倍。 不过随意改动物体尺寸也有弊端。如奶牛数量的增长如果以图形表示，会被误解为奶牛体积的增长。 7.看似相关的数据 如果无法证明自己想要证明的东西，就展示一些其他东西，假装它们是一样的（相关的）。这时人们容易得出错误的结论。 例1：半盎司特效药可以在11秒内杀死试管中31108个细菌。 实际上，特效药在试管里效果明显不代表在人体咽喉中也明显，特别是常规服药会对药物进行稀释。 也许感冒根本不是细菌引起的 例2：27%的名医抽XX品牌的烟 这个数据其实并不代表XX品牌的香烟就更加健康，医生未必比你更加了解香烟。 例3：因为晴天的事故比雾天的事故多，所以雾天开车更安全。 实际上，仅仅是因为晴天比雾天多，雾天开车更危险。 例4：现在与过去相比，更多的人死于飞机失事，所以现在的飞机更危险。 实际上仅仅是因为现在坐飞机的人是以前的成千上万倍。 例5：1898年战争期间，美国海军的死亡率是0.9%，而纽约市民的死亡率是1.6%，所以待在部队更加安全。 实际上，两组数据没有可比性，海军的主要构成人员的年轻力壮的青年人，而市民中包含了婴儿、老年人和病人等。 8.因果颠倒 “如果B事件发生在A事件之后，那么就是A时间引起了B事件”，这是一种非常古老的谬误推理。 为了避免陷入这种谬误，需要严格检验各种与相关性有关的说明。相关性往往通过一些令人信服的精确数据来证明两件事情之间的因果关系，然而相关性却有多种类型： 机缘巧合之下得出的相关。样本规模较小时，任何两个事物之间都能建立显著的相关性。例如XX牙膏能减少蛀牙，其实是一次小规模实验偶然的结果。 “协变关系”，两个变量存在相关性，但无法确定因果。某些情况下会随时交换位置，有时互相既是因又是果。例如收入和拥有的股票。 变量之间不存在因果关系，但变量之间的确存在某种相关性。例如抽烟者成绩也不好。此时，两个变量可能都受到第三个因素的影响。 当原本论证的相关数据超出一定范围，正相关达到一个极点就会转变为负相关。雨水越多，庄稼长势越好。然而超过一个极点时，雨水越多，庄稼收成就会减少。 相关表示的是一种趋势，并非人们理想的“一对一”关系。受教育一般能增加收入，但也能证明教育会使某人破产。我们要时刻谨记：即使相关性存在并有真实的因果关系，仍然不能凭此进行决策。 如何避免被一个真实的相关被拿去支持的未经证实的因果关系所迷惑，想想相关发生的过程以及整个时代背景。 案例：XX岛的人认为虱子有益于身体健康，因为健康的人身上都有虱子，而体弱者没有。 事实是，体弱者多是因为发烧，而体温升高又导致虱子离开身体。因此是健康不发烧才会有虱子。这里将因果颠倒了。 9.如何操作统计 通过利用统计材料给人传递错误的信息，这一行为在统计学上可称为人为操纵。刻意歪曲、故意操纵统计数据的人不是专业的统计学家，只要这些错误是单方面的，我们就很难将之归咎于粗心或者意外。 例1：基金会统计的美国家庭平均年收入是5004美元，而美国人口普查局统计的同年美国家庭平均年收入却是3100美元。 基金会使用了“均值”平均数，而非更小但更为贴切的中位数 基金会假设家庭收入与家庭人数成正比，然而事实并非如此。 例2：4.9%的兼职家庭帮工周工资为18美元 实际上，这4.9%仅仅是两个人，这一类帮工的总人数也就41人 根据小规模样本得出一个具有误导性的百分数 例3：现在购买圣诞礼物可少花100%的钱 这并不意味是免费的，省下的钱相当于新价钱的100%，实际上就是打五折了。 通过混淆、更换基数，让人产生错觉。 例4：一年365天减去122天睡觉的时间，45天三餐的时间，90天暑假时间，21天法定节假日，最后剩余的时间甚至不够你过周末。 将一些不该相加的东西相加在一起就会产生许多愚蠢的错误和强词夺理的狡辩。 将各种百分比加在一起纯粹异想天开：买了20样东西，每一样的价格都上涨了5%，加在一起是100%，所以生活成本翻了一番？ 例5：投资回报率从第一年的3%上涨到第二年的6%。可以说增加了3个百分点，也可以说增长高达100%。 混淆了百分比和百分点，也是极具欺骗性。 例6：在某次数学测验中，比较John与其他同学时使用百分位数。如300人参与，前三名的百分位数就是99，4-6名是98。 实际上，百分位数99的学生比百分位数90的学生优秀一点，但是百分位数40和60的学生水平差不多。 正态分布的数据中，特征聚集在平均数周围，百分位数具有欺骗性。 例7：去年1夸脱牛奶价格为20美分，一条面包价格为5美分，而今年牛奶价格降至每夸脱10美分，面包价格涨到一条10美分。 将去年看作基期，牛奶价格下跌一半（50%），面包价格上涨一番（200%），平均数是125%，所以物价上涨了25%。 将今年看作基期，去年牛奶价格是今年两倍（200%），面包价格是今年一半（50%），平均数是125%，所以去年物价比今年高25%，即物价降低了25%。 使用几何平均数，将去年作为基期，50%乘以200%，再开方，结果是100%，物价没有变化。 基期就是确定开始计算的时间，也就是时间范围内的初值。通过更改基期和平均数计算方式，可以达到欺骗或者迷惑的目的。 统计学是一门科学，也是一门艺术。在允许的范围内，可以进行大量的统计操纵，甚至扭曲事实。一般的统计学家从多个方法中选出一个阐述事实的方法，这是一个主管的过程。然而在商业活动中，统计学家不会选择对自己不利的方法。 10.如何反驳统计数据？ 并非所有统计信息都能用设备检验，但是可以提出5个简单的问题来避免被一些似是而非的东西所迷惑。 是谁这么说？ 要找到偏差，包括有意识的偏差和无意识的偏差。有意识的偏差如选出对自己有利的数据、改变衡量的标准、使用不恰当的测算方式（中位数更能说明问题时却使用均值，还用“平均数”这种措辞）。 要警惕各种“专家”，确定到底是不是权威人士。 他怎么知道？ 样本是否带有偏差，案例是否多到具备显著性？要确保样本的规模足够庞大才能根据这个样本得出真实可信的结论。 漏掉了什么？ 当数据来源关系到利益关系时，数据缺乏会让人对整件事产生怀疑。比如一个相关如果缺乏可信的测算方式检验，就未必真相关。 要留心未加说明的平均数。 当没有其他数据作为对比时，数据本身会变得没有意义。 只给出百分数，却没有给出原始数据的材料也往往带有欺骗性。如大学1/3的女生嫁给了大学男老师，然而当年只有3名女生。 如果给出了一个指数，往往要注意是否漏掉了基数。 有时漏掉的还有导致变化的因素。 有人偷换了概念吗？ 要注意原始数据和最终结论之间是否存在被偷换概念的地方。如某个候选人在一场非官方的民意测验中获胜并不一定意味着他会在选举中获胜。 这是否合乎清理？ 任何以一个未经证实的假设为基础的结论都需要问问“这是否合乎情理”。例如假设词语和句子的长度决定了文章的阅读难度，从而使用公式进行难度判断，这不合情理。 看研究和预测中用到的图表时要谨记：截至目前的趋势或许是事实，但是未来的趋势不过是预测者的猜测。 ","link":"https://Angus1996.github.io/post/lesslesstong-ji-shu-ju-hui-shuo-huang-greatergreater-du-hou-gan/"},{"title":"一作论文被Neurocomputing接收！","content":"📣📣一作论文被Neurocomputing接收。使用图卷积神经网络对安卓函数调用图进行学习、特征提取，在众多分类器都取得了超过99%的准确性和召回率💪💪。 👏👏👏👏👏历时大半年，经过大修、小修，论文“Learning Features from Enhanced Function Call Graphs for Android Malware Detection”终于被Neurocomputing接收了❤️❤️❤️❤️❤️ 函数调用图 从android app反编译的smali文件中中提取函数调用图，具体形式是邻接矩阵。使用图卷积神经网络进行学习处理。使用word2vec算法获取函数结点语义表示，构成图卷积神经网络所需的函数结点特征矩阵。 分类效果 在从Androzoo获取的5万多的app数据集上，五折交叉验证，图卷积神经网络从函数调用图提取的特征在众多机器学习分类器上都表现出色。对比特征包括权限、敏感API等静态特征。 ","link":"https://Angus1996.github.io/post/yi-zuo-lun-wen-bei-neurocomputing-jie-shou/"},{"title":"第一次的独自旅行","content":"上大学以前，除了走亲戚，基本没出过武汉市的范围，更别说旅游了。随着我走进大学，姐姐们相继工作，家里的经济状况才开始慢慢改善。这时候，旅游才从我的脑海里蹦出来。 其实，很多时候，我不是很喜欢去太拥挤的景点旅游。游玩项目的话，人多要排很长时间的队伍；看人文风景的话，人挤人也看不到啥。尤其是我不太喜欢在拍照的时候，风景里还会突兀得多出来人。 2015年大二的时候，和两个姐姐趁着国庆假期去成都游玩了一次。那应该是我第一次坐火车去外省。记忆深刻的是，火车晃晃悠悠了16多个小时，我们才从武昌站出发到了成都。去成都之前，姐姐们也是做好了攻略要去哪些地方看一看，去哪些地方拍照。不外乎宽窄巷子、杜甫草堂、青羊宫、武侯祠、春熙路，然后是比较偏远的大熊猫基地。后来大学期间好像也没有再出去旅游了。 读研以后，我自己慢慢也有了一些收入来源，基本也没有再向家里要过生活费了。2019年五一四天假的时候，随着大姐认识的一群跑步青年自驾去徒步武功山。同行的是各行各业的，但是大家都很好相处。后来六月份被老师要求出差去干活，去郑州，晚上休息的时候，独自一人打了个滴滴溜到二七广场逛了一下。八月份的时候又去魔幻城市——重庆出差了。 今年实习来到了杭州，作为出了名的旅游城市。景点是不少的，而且因为今年疫情的影响，各地旅游业是逐步恢复的。现在旅游的人数也是大大减少。 听了那么多年西湖，今年暑假也总算见识到了西湖的美。西湖不比武汉东湖磅礴大气，横跨在西湖上的苏堤和白堤，矗立在西湖边上的雷峰塔，都给西湖增添了几分格外的魅力。可惜六月份，还没能看到“接天莲叶无穷碧，映日荷花别样红”的场景。西湖的音乐喷泉也因为疫情没有开放。 端午三天假，一直想要出去玩。又不想去外省，免得还要做核酸检测，麻烦。一起游西湖的同学也因为有事，没法出来。一开始想要去的东极岛，可能是受了韩寒《后会无期》电影的影响。总想去中国最东边，感受第一缕阳光照耀在身上的感觉。查了行程，感觉三天也有点赶。最后在西塘和乌镇之间选择了乌镇。 虽然端午节那天，杭州是大雨。计划在脑海中差点泡汤。不过假期不易，我还是说走就走了。6月20号推行无纸化火车票以后，我也是第一次发现，身份证加人脸识别是如此方便，没有了以前排队取票的麻烦。从杭州东站到桐乡站，高铁也就跑了18分钟。桐乡市为了发展乌镇旅游业，桐乡站就有直达乌镇的公交，非常方便。我也是在公交车上才买了东栅和西栅的联票。 按照网上的攻略，白天游玩东栅，晚上适合游玩西栅。东栅就是典型的江南水乡，房子傍水而建，一条河贯穿其中，时而有一座拱桥横跨在河流之上。河流边有妇人洗衣，河流上有船夫撑船。 在东栅里我拜访了茅盾先生的纪念馆，了解了茅盾先生伟大的一生，以及他所设立的茅盾文学奖。在茅盾纪念馆对面请中书协的王召诹先生题了一副姓名藏头诗，他在诗中也提醒我要顺时应势。也探寻了《似水年华》的拍摄地——晴耕雨读，可能没有开门。东栅有人在直播，也有人穿着古装或者旗袍在拱桥上拍照。东栅白墙黑瓦之下，如今也还是能够看到一些老人居住在里面。 西栅更像经过现代化商业开发的古镇，进门是造型别致的乌镇大剧院和木心美术馆。两座建筑都是在水之上，木心美术馆的造型更是别致，方正有形，与旁边的绿树，倒映在绿水中的建筑，蓝天白云融为一体。美中不足的是，建筑经历风雨，白墙上也出现了黑色污渍。 西栅里还有一座月老庙，信月老的单身男女也可以给自己求上一支签。西栅比东栅总体要大，沿着薰衣草地和龙形田的柏油路可以慢慢地往里面走。远远地也能看到白莲塔。到了夜晚的时候，酒吧一条街也是人满为患了。人多的让我以为疫情已经结束了。船夫撑着船，载着人在河上漫游，河流两边的灯光也把各种建筑妆点了起来。孩童提着灯笼在石板路上跑来跑去，丝毫不畏生。 逛完西栅，找了一个酒店住了一晚，硬是没睡着，第二天一早便动身准备离开乌镇。在去乌镇汽车站的公交上，一个学生模样小菇凉反复看手里纸条，上面似乎记录着路线。我才想起那天是浙江省中考的日子，她妈妈也是一直把她送上公交的。坐在她旁边，真想说一句鼓励的话，可最后我下车时也还是没能说出口。我相信她会加油的，至少会为了她妈妈而加油。 一个人的独自旅行，始于杭州的大雨天气下出门，回来已经是晴天。 下一次，我想去看看海。 ","link":"https://Angus1996.github.io/post/di-yi-ci-de-du-zi-lu-xing/"},{"title":"C++程序设计教程（第3版）（通用版）--钱能","content":"第一部分 C++过程化语言基础 第3章 表达式和语句 表达式是操作符、操作数和标点符号组成的序列，其目的是说明一个计算过程。 表达式根据某些约定、求值次序、结合性和优先级规则来进行计算。 左值（left value，缩写为lvalue）是能出现在赋值表达式左边的表达式。左值表达式具有存放数据的空间，并且存放是允许的。 显然常量不是左值，因为C++规定常量的值一旦确定是不能更改的。 右值（right value，缩写为rvalue）只能出现在赋值表达式的右边。左值表达式也可以作为右值表达式。 由表达式组成的语句称为表达式语句，它由一个表达式后接一个分号“;”组成。 块（或称复合语句）是指括在一对大括号{}里的语句序列。从语法上来说，块可以被认为是单个语句。 对于整型数则为除法取整操作。例如，5/2得到结果为2。 对于浮点数则为通常意义的除法。例如，5.0/2.0得到结果为2.5。 如整数加法是将两个整型数相加，而浮点数加法是将两个浮点数相加，相加的具体操作（在机器指令级上）浮点和整数是不同的。 %如果对浮点数操作，则会引起编译错误。 赋值构成一个表达式，因而它具有值。赋值表达式的值为赋值符左边表达式的值。 进行算术运算时，很可能溢出结果。发生溢出是由于一个变量被赋予一个超出其数据类型表示范围的数值。数值溢出是不会引起编译错误的，只要分母不为0也不会引起除0运行故障，但会使运行结果发生偏差。 一个整数类型的变量，用任何一个超过表示范围的整数初始化，得到的值为用该整数范围作模运算后的值。 转换总是朝表达数据能力更强的方向，并且转换总是逐个运算符进行的 数据运算过程中自动进行的类型转换称为隐式类型转换。 如果让第1次乘法的结果以long型数保留下来，就能得到正确的结果。这就要求参加乘法运算的两个数至少有一个为long型数。 强制转换又称显式转换，其语法是在一个数值或变量前加上带括号的类型名。也可以类型名后跟带括号的数值或表达式。 前增量操作++a的意义为：先修改操作数使之增1，然后将增1过的a值作为表达式的值。而**后增量操作a++**的意义为：先将变量a的值作为表达式的值确定下来，再将a增1。 由于增量与减量操作修改内存实体，所以操作数不能是常量，它必须是一个左值表达式。 增量与减量操作符是两个+或两个-的一个整体，中间不能有空格。如果有多于两个+或两个-连写的情况，则编译首先识别前面两个+或-为增量或减量操作符。 a++是个非左值表达式 **真和假是逻辑值。**在C++中，假意味着0，真意味着非0。所以，任意一个非0数都是真，表示为逻辑值就是1。 如果多个表达式用&amp;&amp;连接，则一个假表达式将使整个连接都为假（此处需要数理逻辑知识）。 同理，如果多个表达式用||连接，则一个真表达式将使整个连接都为真。 else连接到上面第1个没有配对的且为可见的if上 它是C++中唯一一个三元运算符，它们之间用“?”和“:”隔开。上例中，把a和b中较小的值赋给x。该例是if…else语句的一个替代： 条件运算符的嵌套可读性不够好，应通过加括号将意义明确。 在一个条件运算符的表达式中，如果后面两个表达式的值类型相同，均为左值，则该条件运算符表达式的值为左值表达式。 任何被转换的变量都不是左值。 在C中，条件运算符是不能作左值的，所以“（x?a：b）=1；”将通不过编译。 逗号表达式是有值的，这一点是语句所不能代替的。逗号表达式的值为第n个子表达式的值，即表达式n的值 逗号表达式作为值的形式，可以用于几乎所有的地方。 C++中，如果逗号表达式的最后一个表达式为左值，则该逗号表达式为左值。 在C中，逗号表达式是不能作左值的，所以“（a=1，b，c+1，d）=5；”将通不过编译。 先求前操作数的值还是先求后操作数的值，C++并无明确规定。 表达式和语句的副作用说明编程者对程序思路还有不够完善、不够周密的地方。它导致可读性下降，也破坏了可移植性。所以编程时务必要避免副作用的产生。 解决表达式副作用的方法是分解表达式语句，即将复合表达式语句写成几个简单的表达式语句。 第4章 过程化语句 高级语言源程序的基本组成单位是语句。语句按功能可以分为两类：一类用于描述计算机执行的操作运算（如表达式语句），即操作运算语句；另一类是控制上述操作运算的执行顺序（如循环控制语句），即流程控制语句。后一类语句也称为过程化语句。 如果循环体包含一个以上的语句，应该用大括号括起来，以块语句形式出现。如果不加大括号，则while的范围只到while后面第一条语句。 C++有足够的能耐让代码最大限度的优化。该代码也显示了C++的灵活与技巧，但可读性较差，所以它不是现代程序设计所追求的。我们介绍的用意是让初学者见识这类代码，以达到更好地领会概念的目的。 当流程到达do后，立即执行循环体语句，然后再对条件表达式进行测试。若条件表达式的值为真（非0），则重复循环，否则退出。 该语句结构使循环至少执行一次。 为明显区分它们，do…while循环体即使是一个单语句，习惯上也使用大括号包围起来，并且while（表达式）直接写在大括号“}”的后面。这样的书写格式可以与while循环清楚地区分开来。例如： switch后面括号中的表达式只能是整型、字符型或枚举型。 case语句起标号的作用。标号不能重名，所以每一个case常量表达式的值必须互不相同，否则就会出现编译错误。 case通常与break语句联用，以保证多路分支的正确实现。 多个case可以共用一组执行语句。 default语句是可选的。当default不出现时，则当表达式的值与所有常量表达式的值都不相等时，越过switch语句。 switch语句可以嵌套。case与default标号是与包含它的最小的switch相联系的。 因为switch语句只能对等式进行测试，如果测试值包含一个较大的范围，就需要关系表达式比较，这时候用if语句较好。 if…else语句的执行体等价于switch语句的case中含有break的语句组。 在switch语句中，break语句用来使流程跳出switch语句，而执行switch后的语句。 continue语句用在循环语句中，作用为结束本次循环，即跳过循环体中尚未执行的语句，接着进行下一次是否执行循环的判定。 由于在C++中有块语句的支持，所以经常使用反条件的if语句，把continue后面的语句以块的形式包含在if语句之中，可以避免使用continue语句。 语句标号用标识符表示，它的命名规则与变量名相同。 用goto语句实现的循环完全可以用while或for循环来表示。现代程序设计方法主张限制使用goto语句，因为滥用goto语句将使程序流程无规则，可读性差。goto语句只在一个地方有使用价值：当要从多重循环深处直接跳转到循环之外时，如果用break语句，将要用多次，而且可读性并不好，这时goto可以发挥作用。 程序设计更多的是体现其艺术性，可读性是我们追求的重要目标。 第5章 函数 要编好程序，就要会合理地划分程序中的各个程序块，C++称之为函数。 领会函数调用的内部实现机制，区分函数声明与定义，掌握全局变量、静态局部变量和局部变量之间的区别，理解并运用递归、内联、重载和默认参数的函数。 标准库函数是C++提供的可以在任何程序中使用的公共函数。程序总是从main（）函数开始启动。 函数可以被函数调用也可以调用函数。 C++不允许函数定义嵌套，即在函数定义中再定义一个函数是非法的。 函数原型是一条程序语句，即它必须以分号结束。它由函数返回类型、函数名和参数表构成 在C++中，函数声明就是函数原型。 函数原型和函数定义在返回类型、函数名和参数表上必须完全一致。如果它们不一致，就会发生编译错误。 函数原型不必包含参数的名字，而只要包含参数的类型。 该代码能够正确通过编译，因为函数声明的原型与函数调用相吻合。但在连接时，发现没有与函数声明相一致的函数定义，结果产生“不能确定的外部函数”的连接错误。 函数的返回值也称函数值。返回的不是函数本身，而是一个值。 编译器遇到一个函数调用时，需要判断该函数调用是否正确，该机制即函数原型。 一个程序将操作系统分配给其运行的内存块分为4个区域： （1）代码区，存放程序的代码，即程序中的各个函数代码块。 （2）全局数据区，存放程序的全局数据和静态数据。 （3）堆区，存放程序的动态数据。 （4）栈区，存放程序的局部数据，即各个函数中的数据。 在函数外边访问的变量被认为是全局变量，并在程序的每个函数中是可见的。全局变量存放在内存的全局数据区。全局变量由编译器建立，并且初始化为0，在定义全局变量时，进行专门初始化的除外。 这样定义的全局变量n在所有函数中都可见。如果一个函数修改了n，则所有其他的函数都会看到修改后的变量。 全局变量通常在程序顶部定义。全局变量一旦定义后就在程序的任何地方可知。可以在程序中间的任何地方定义全局变量，但要在任何函数之外。全局变量定义之前的所有函数定义，不会知道该变量。 **在函数内部定义的变量仅在该函数内是可见的。**另外，局部变量的类型修饰是auto，表示该变量在栈中分配空间，但习惯上都省略auto。 一个函数可以为局部变量定义任何名字，而不用担心其他函数使用过同样的名字。 函数中的局部变量存放在栈区。在函数开始运行时，局部变量在栈区被分配空间；函数退出时，局部变量随之消失。 **局部变量没有默认初始化。**如果局部变量不被显式初始化，那么，其内容是不可预料的。 函数调用时，C++首先： （1）建立被调函数的栈空间。 （2）保护调用函数的运行状态和返回地址。 （3）传递参数。 （4）将控制转交给被调函数。 funcA（）可以修改其变量aa和bb，但始终不会影响main（）中的a和b。这便是C++函数的参数传值特性。 可以看出，如果一层层地调用下去，或者过多地定义局部变量，特别是数组（将在第7章介绍），最后可能导致栈空间枯竭而引起程序运行出错。如果程序确实要占用相当大的栈空间，可以在连接前通过设置栈空间大小来改善。 函数在返回时，将把返回值保存在临时变量空间中（如果有返回值的话）。然后恢复调用函数的运行状态，释放栈空间，使其属于调用函数栈空间的一部分，最后根据返回地址，回到调用函数代码执行处。 在局部变量前加上“static”关键字，就成了静态局部变量。静态局部变量存放在内存的全局数据区。函数结束时，静态局部变量不会消失，每次调用该函数时，也不会为其重新分配空间。它始终驻留在全局数据区，直到程序运行结束。 静态局部变量与全局变量共享全局数据区，但静态局部变量只在定义它的函数中可见。 程序控制每次进入func（）函数时，局部变量b都被初始化。而静态局部变量a仅在第一次调用时被初始化，第二次进入该函数时，不再进行初始化，这时它的值是第一次调用后的结果值4。 静态局部变量的用途有很多：可以使用它确定某函数是否被调用过；使用它保留多次调用的值。 **递归函数（recursive function）**即自调用函数，在函数体内部直接或间接地自己调用自己，即函数的嵌套调用是函数本身。 任何函数之间不能嵌套定义，调用函数与被调用函数之间相互独立，但彼此可以调用。 发生函数调用时，被调函数中保护了调用函数的运行环境和返回地址，使得调用函数的状态可以在被调函数运行返回后完全恢复，而且该状态与被调函数无关。 被调函数运行的代码虽是同一个函数的代码体，但由于调用点、调用时状态、返回点的不同，可以看作是函数的一个副本，与调用函数的代码无关，所以函数的代码是独立的。 被调函数运行的栈空间独立于调用函数的栈空间，所以与调用函数之间的数据也是无关的。函数之间靠参数传递和返回值来联系，函数看作为黑盒。 理论上已经证明，递归函数都能用非递归函数来代替。 递归增加了系统开销。时间上，执行调用与返回的额外工作要占用CPU时间。空间上，随着每递归一次，栈内存就多占用一截。 内联函数也称内嵌函数，它主要是解决程序的运行效率。 编译器看到inline后，为该函数创建一段代码，以便在后面每次碰到该函数的调用都用相应的一段代码来替换。内联函数可以在一开始仅声明一次。 内联函数必须在被调用之前声明或定义。因为内联函数的代码必须在被替换之前已经生成被替换的代码 **内联函数中不能含有复杂的结构控制语句，如switch和while。**如果内联函数有这些语句，则编译将该函数视同普通函数那样产生函数调用代码。 另外，递归函数（自己调用自己的函数）是不能被用来做内联函数的。 通过一个内联函数可以得到所有宏的替换效能和所有可预见的状态以及常规函数的类型检查： 对于在不同类型上作不同运算而又用同样的名字的情况，则称之为重载。 （1）寻找一个严格的匹配，如果找到了，就用那个函数。 （2）通过内部转换寻求一个匹配，只要找到了，就用那个函数。 （3）通过用户定义的转换寻求一个匹配，若能查出有唯一的一组转换，就用那个函数（见18.5节中的后增量函数type operator++（type&amp;，int））。 重载函数至少在参数个数、参数类型或参数顺序上有所不同。 typedef定义的类型只能使之相同于一个已存在的类型，而不能建立新的类型，所以不能用typedef定义的类型名来区分重载函数声明中的参数。 让重载执行不同的功能，是不好的编程风格。同名函数应该具有相同的功能。 C++用名字粉碎（name mangling）的方法来改变函数名，以区分参数不同的同名函数。名字粉碎是十分简单的过程，一系列代码被附加到函数名上以指示参数类型以及它们出现的次序。 默认参数在函数声明中提供，当又有声明又有定义时，定义中不允许默认参数。如果函数只有定义，则默认参数才可出现在函数定义中。 如果一个函数中有多个默认参数，则形参分布中，默认参数应从右至左逐渐定义。当调用函数时，只能向左匹配参数。 默认值可以是全局变量、全局常量，甚至是一个函数 默认值不可以是局部变量，因为默认参数的函数调用是在编译时确定的，而局部变量的位置与值在编译时均无法确定。 第6章 程序结构 要求掌握外部存储类型和静态存储类型在多文件程序中的联络作用，理解作用域、可见性与生命期的概念，学会使用头文件，理解多文件结构，理解编译预处理的概念。 一般具有应用价值的程序由多个源文件组成。根据C++程序的定义，其中只有一个源文件具有主函数main（），而其他的文件不能含有main（），否则程序不知道该从何处开始执行了。 构成一个程序的多个源文件之间，通过声明数据或函数为外部的（extern）来进行沟通。它们告诉连接程序，在所有组成该程序的文件（这里是ch6_1.cpp和ch6_1_1.cpp）中搜索该函数的定义。其中，fn1（）在本文件中定义，fn2（）在ch6_1_1.cpp中定义。 虽然在包含main（）函数的源文件中分配变量是最合理的，但哪个文件真正分配该变量（全局变量定义）是无关紧要的。 带extern的变量说明是变量声明，不是变量定义。 **在全局变量前加一个static，使该变量只在这个源文件中可用，称之为全局静态变量。**全局静态变量就是静态全局变量。 但是在多文件组成的程序里，全局变量与全局静态变量是不同的。全局静态变量使得该变量成为由定义该变量的源文件所独享。 静态全局变量对组成该程序的其他源文件是无效的。 使一个变量只在一个源文件中全局使用有时是必要的。第一，不必担心另外源文件使用它的名字，该名字在源文件中是唯一的；第二，源文件的全局变量不能被其他源文件所用，不能被其他源文件所修改，保证变量的值是可靠的。 函数的声明和定义默认情况下在整个程序中是外部（extern）的。有时候，你可能需要使某个函数只在一个源文件中有效，不能被其他源文件所用，这时在函数前面加上static。 在文件作用域下声明的inline函数默认为static存储类型。在文件作用域下声明的const的常量也默认为static存储类型。它们如果加上extern，则为外部存储类型。 作用域是标识符在程序中有效的范围，标识符的引入与声明有关，作用域开始于标识符的声明处。C++的作用域范围分为局部作用域（块作用域）、函数作用域、函数原型作用域、文件作用域和类作用域 局部变量不具有函数作用域。 函数原型声明（不是函数定义）中所作的参数声明在该作用域中。这个作用域开始于函数原型声明的左括号，结束于函数原型声明的右括号。 参数中有了标识符可以增强可读性。上面参数中带标识符的函数原型声明使人一看就明白一个参数是宽度值，另一个参数是长度值。所以，习惯上，在函数原型声明中，都为参数指定一个有说明意义的标识符，而且一般总是与该函数定义中参数的标识符一致。 文件作用域是在所有函数定义之外说明的，其作用域从说明点开始，一直延伸到源文件结束 在头文件的文件作用域中所进行的声明，若该头文件被一个源文件嵌入，则声明的作用域也扩展到该源文件中，直到源文件结束。 例如，cout和cin都是在头文件iostream.h的文件作用域中声明的标识符，这两个标识符的作用域延伸到嵌入iostream.h的源文件中。 可见性从另一角度表现标识符的有效性，标识符在某个位置可见，表示该标识符可以被引用。可见性与作用域是一致的。作用域指的是标识符有效的范围，而可见性是分析在某一位置标识符的有效性。 可见性在分析两个同名标识符作用域嵌套的特殊情况时，非常有用。在内层作用域中，外层作用域中声明的同名标识符是不可见的，当在内层作用域中引用这个标识符时，表示的是对内层作用域中声明的标识符的引用。 标识符的可见性范围不超过作用域，作用域则包含可见范围。 在内部块中，double i的作用域和可见性是一致的，int i的作用域存在，但不可见。在外部块中，ch的作用域与可见性是一致的，因为ch的可见性渗透至内部块中。 如果被隐藏的是全局变量，则可用符号：：来引用该全局变量。 变量在固定的数据区中分配空间的，具有静态生命期。所以，全局变量、静态全局变量、静态局部变量都具有静态生命期。具有文件作用域的变量具有静态生命期。 被调用函数不能享有使用调用函数中数据的权利。 静态生命期的变量，若无显式初始化，则自动初始化为0。 **具有局部生命期的变量也具有局部作用域。但反之不然，具有局部作用域的变量若为局部变量，则具有局部生命期；若为静态局部变量，则具有静态生命期。**静态局部变量的生命期是从定义它的函数第一次被调用时开始存在，直到程序运行结束。 具有这种生命期的变量驻在内存的堆中。当用函数malloc（）或new为变量分配空间时，生命期开始；当用free（）或delete释放该变量的空间或程序结束时，生命期结束。 同一名字的声明可以多次，具有外部存储类型的声明可以在多个源文件中引用，因此方便的方法是将它们放在头文件中。头文件起着源文件之间接口的作用。 工程文件中的3个文件都含有myarea.h的头文件，这样可以使信息共用，保证程序的一致，在大型程序开发中尤为必要。 预处理程序也称预处理器，它包含在编译器中。预处理程序首先读源文件。预处理的输出是“翻译单元”，它是存放在内存中的临时文件。 预处理器遇到这种格式的包含指令后，首先在当前文件所在目录中进行搜索，如果找不到，再按标准方式进行搜索。这种方式适合于规定用户自己建立的头文件 条件编译的指令有#if、#else、#elif、#endif、#ifdef、#ifndef和#undef。 条件编译的一个有效使用是协调多个头文件。 第7章 数组 求理解数组下标，掌握初始化数组的方法，学会把数组用作函数参数，学会二维数组的使用，并学习数组应用的技术。 **下标是数组元素到数组开始的偏移量。**第1个元素的偏移量是0，第2个元素的偏移量是1，以此类推。由此，数组是一系列大小相同的连续项，每项到公共基点的偏移量是固定的。 一个数组定义是具有确定含义的操作，它分配固定大小的空间。如果方括号的值不能在编译时确定，那就只能在运行时确定，即在函数调用时即兴分配数组空间。这使得为局部作用域的数组分配数据空间的语句具有不同的意义，它随每次函数调用的不同而不同，这是不允许的。 编程时，如果要定义一个很大的数组，可以通过将其定义为静态或全局来解决，也可以将其在堆内存中分配（见8.4节）。 管变量size已经赋有值50，紧接着就是数组的定义，阅读上都能理解，但是size是变量这一性质是编译不能原谅的。对于常量，编译可以用一个值直接代替，但对于变量，编译不能用值来代替，而是编译为取该变量的值。取值是一个操作，不是值本身，不能决定数组下标。程序运行中，通常通过常量来决定数组大小。 如果循环条件误写成“i＜=10”，那么程序将会执行到包括“iArray[10]=90；”的语句，改变不属于数组空间的内存单元（见图7-2）。这个代码的失误不会在程序的编译与连接中反映出来，而是可能一直运行下去，直到出现结果不正确，或严重时导致死机。 字符数组若用来存储字符串，则要考虑字符串末尾的'\\0'结束符。 cin.get（）在用户输入的最后字符后面加上'\\0'。 初始化数组的值的个数不能多于数组元素个数，初始化数组的值也不能通过跳过逗号的方式来省略，这在C中是允许的，但在C++中不允许。 其中，全局数组和全局静态数组的初始化是在主函数运行之前完成的，而局部数组和局部静态数组的初始化是在进入主函数后完成的。 第一种方法用途较广，初始化时，系统自动在数组没有填值的位置用'\\0'补上。另外，这种方法中的大括号可以省略 这里不要忘记为最后的'\\0'分配空间。如果要初始化一个字符串＂hello＂，那为它定义的数组至少有6个数组元素。 **编译时必须知道数组的大小。**通常，声明数组时方括号内的数字决定了数组的大小。有初始化的数组定义又省略方括号中的数组大小时，编译器统计大括号之间的元素个数，以求出数组的大小。 sizeof操作使for循环自动调整次数。如果要从初始化a数组的集合中增删元素，只需重新编译即可，其他内容无须改动。 对于字符串的初始化，要注意数组实际分配的空间大小是字符串中字符个数加上末尾的'\\0'结束符。 省略数组大小只能在有初始化的数组定义中。 无论何时，将数组作为参数传给函数，实际上只是把数组的地址传给函数 C++中有一个memset（）函数，它可以一字节一字节地把整个内存区块设置为一个指定的值。memset（）函数在string.h头文件中声明，它的第一个参数是内存区块的起始地址，第二个参数是设置每个字节的值，第三个参数是内存区块的长度（字节数，不是元素个数） 数组名作参数即数组作参数，它仅仅只是一个数组的起始地址而已。 在函数memset（）栈区，从返回地址往上依次为第1、2、3个参数。第1个参数中的内容是main（）函数中定义的数组ia1的起始地址；第2个参数是给数组设置的值（0）；第3个参数是数组的长度（50×2）。 数组大小参数是需要的，因为从传递的数组参数（地址）中，没有数组大小的信息。 数组形参的空方括号只是告诉函数，该参数是个数组的起始地址。由于数组参数是地址，对数组参数不能通过sizeof求得数组大小，所以sum（）函数必须要有第二个参数：数组的大小，即数组的元素个数。 二维数组是按先行后列的顺序在内存中线性排列的。 如果某行没有足够的初始化值，那么该行中的剩余元素都被初始化为0。初始化还可以将多个大括号简化为一个大括号。 如果对全部元素赋初值，则定义数组时对第一维的大小可以忽略，但第二维的大小不能省。 编译器会根据数据总个数分配空间，每行4列，所以确定该数组为3行。 在定义时，也可以只对部分元素赋初值而省略第一维的大小，但应分行赋初值。 作为参数传递一个二维数组给函数，其意义也为内存地址，所以原型中，声明整数数组参数的形式只能省略左边的方括号。要注意被传递的数组地址不要用数组名表示，要用第一个元素的地址表示，因为数组名表示的是二维数组的首地址，尽管地址值相同，但操作不同 函数调用时，数组参数的实参为整型变量的地址，函数原型中，数组参数的形参为整型数组的首地址 第8章 指针 这种用来操纵地址的特殊类型变量就是指针。指针用于数组，作为函数参数，用于内存访问和堆内存操作。 指向整型数的指针是包含该整型数地址的变量或常量 指向字符的指针是包含字符地址的变量或常量 **指针是一个内存实体，具有值。**要使用指针，就必须定义指针。**指针有指针常量和指针变量之分，定义指针通常定义的是指针变量，即可以随时改变指针的指向。**所以，指针与指针变量经常划等号。 建立指针包括定义指针和给指针赋初值。 变量存在于内存中的某位置（地址）。例如，一旦有了变量，则放置该变量的地方就用内存地址描述。 用&amp;操作符可以获取变量的地址，指针用于存放地址。 间接引用指针时，可获得由该指针指向的变量内容。 *放在可执行语句中的指针之前，为间接引用操作符；*放在指针定义中时，为指针定义符。 非指针是不能用间接引用操作符的，因为*只能作用于地址。 指针也是变量，是变量就具有内存地址。所以指针也有地址。 不要将“int* iPtr=&amp;iCount；”与“*iPtr=&amp;iCount；(error)”混淆。前者是定义语句，*是指针定义符，C++为iPtr指针分配一个指针空间，并用iCount的地址值初始化；后者是赋值语句，左右两边类型不匹配。 *操作符在指针上的两种用途要区分开：定义或声明时，建立一指针；执行时，间接引用一指针。 指针忘了赋值比整型变量忘了赋值危险得多。 iPtr当前指向什么地方？该代码能通过编译，但没有赋初值的指针iPtr是一个随机地址。“*iPtr=58；”是把58赋到内存中的随机位置，因此将改写另一存储位置的数值，甚至修改了栈中的函数返回地址，计算机将死机或进入死循环。 指针是有类型的，给指针赋值，不但必须是一个地址，而且应该是一个与该指针类型相符的变量或常量的地址。 iPtr是整型指针，它总是访问该地址中的整型数；而fPtr是浮点指针，总是访问该地址的浮点数。 指针是具有某个类型的地址。 加减运算的结果，指针挪移到了邻近的内存单元，于是指针的运算与数组扯上了关系。 **数组名本身，没有方括号和下标，它实际上是地址，表示数组起始地址。**整型数组的数组名本身得到一整数地址，字符数组的数组名得到一字符型地址。 只有加法和减法可用于指针运算。 指针减法的原理与加法相同。只是，不论指针的加法还是减法，其访问操作都必须是有意义的，否则是危险的。 下标操作是针对地址而不仅仅是针对数组名的，所以iPtr[i]也表示第i个元素的值。 数组名本身是一指针，它的类型是指向数组元素的指针。&amp;a[i]表示数组第i个元素的地址。 数组名是指针常量，区别于指针变量，所以，给数组名赋值是错误的。 对于编译器来说，数组名表示内存中分配了数组的固定位置，修改了这个数组名，就会丢失数组空间，所以数组名所代表的地址不能被修改。 堆（heap）是内存空间。堆是区别于栈区、全局数据区和代码区的另一个内存区域。 堆允许程序在运行时（而不是在编译时）申请某个大小的内存空间。 运行中申请的内存就是堆内存，所以堆内存是动态的。堆内存也称动态内存。 因为malloc（）函数并不知道用这些内存干什么，所以它返回一个没有类型的指针（见8.6节）。但对整数指针ap来说，malloc（）函数的返回值必须显式转换成整数类型指针才能被接受（ANSI C++标准）。 上例中并没有保证一定可以从堆中获得所需内存。有时，系统能提供的堆空间不够分配，这时系统会返回一个空指针值NULL。这时所有对该指针的访问都是破坏性的，因此调用malloc（）函数更完善的代码应该如下 函数free（）返还由malloc（）函数分配的堆内存 new返回一个具有操作数的数据类型的指针。 delete的操作数是new返回的指针，当返还的是new分配的数组时，应该带[]。 可以看到，一个指针涉及两个变量：指针本身pi和指向的变量a。修改这两个变量的对应操作为“pi=&amp;a；”和“*pi=58；”。 在指针定义语句的类型前加const，表示指向的对象是常量。 定义指向常量的指针只限定指针的间接访问只能读而不能写，而没有限定指针值的读写访问性。 常量指针定义“const int* pi=&amp;a；”告诉编译，*pi是常量，不能将*pi作为左值进行操作。 在指针定义语句的指针名前加const，表示指针本身是常量。 pc是指针常量，在定义指针常量时必须初始化，就像常量初始化一样。 指针常量定义“int* const pc=&amp;b；”告诉编译，pc是常量，不能作为左值进行操作，但是允许修改间接访问值，即*pc可以修改。 可以定义一个指向常量的指针常量，它必须在定义时进行初始化。 cpc和cpi都是指向常量的指针常量，它们既不允许修改指针值，也不允许修改*cpc的值 常量指针常量定义“const int* const cpc=&amp;b；”告诉编译，cpc和*cpc都是常量，它们都不能作为左值进行操作。 考虑到安全性，指针一旦初始化或者赋了初值后，不轻易改动，于是指针访问数组中的元素便多用下标而不是频繁修改指针的指向。绝大多数指针应用是指针常量和常量指针常量。 一旦把数组作为参数传递到函数中，则在栈上定义了指针，可以对该指针进行递增、递减操作。 传递的数组参数在Sum（）中，实质上是一个指针，所以声明Sum（int array[]，int n）与Sum（int*array，int n）是等价的。 由于形参array是指针而不是数组，所以它所占的空间是指针大小而不是数组空间大小。不能用sizeof（array）/sizeof（*array）来求取数组元素个数，这就是第二参数n（表示数组元素个数）必须要给的原因。 传递指针的函数调用实现过程为： （1）函数声明中指明指针参数，即本例中的void swap（intx，inty）。 （2）函数调用中传递变量的地址，即本例中的swap（&amp;a，&amp;b）。 （3）函数定义中对形参进行间接访问。 指针的灵活是以破坏函数的黑盒特性为代价的。它使函数可以访问本函数的栈空间以外的内存区域（函数的副作用初露端倪），以致引起了以下问题。 （1）可读性问题：因为间接访问比直接访问相对难理解，传递地址比传递值的直观性要差，函数声明与定义也相对比较复杂。 （2）重用性问题：函数调用依赖于调用函数或整个外部内存空间的环境，丧失了黑盒的特性，所以无法作为公共的函数模块来使用。 （3）调试复杂性问题：跟踪错误的区域从函数的局部栈空间扩大到整个内存空间。不但要跟踪变量，还要跟踪地址。错误现象从简单的不能得到相应的返回结果，扩展到系统环境遭破坏甚至死机。 **返回指针的函数称为指针函数。**指针函数不能把在它内部说明的具有局部作用域的数据地址作为返回值。 该程序中的getInt（）函数返回一个局部作用域变量的地址是不妥的。因为getInt（）函数结束时，其栈中的变量value随之消失。 可以返回堆地址，可以返回全局或静态变量的地址，但不要返回局部变量的地址。 **void指针是空类型指针，它不指向任何类型，即void指针仅仅只是一个地址。**所以空类型指针不能进行指针运算，也不能进行间接引用，因为指针运算和间接引用都需要指针的类型信息。 由于其他指针都包含地址信息，所以将其他指针的值赋给空类型指针是合法的；反之，将空类型指针赋给其他指针则不被允许，除非进行显式转换。 字符串用于字符数组初始化时，其在完成将内容填写到所创建的字符数组中之后，随即消失，不再另辟存储空间；而当字符串用于表达式，或输出，或赋值，或作参数传递，则其在运行中有它自己的存储空间，可以寻址访问。 字符串的类型是指向字符的指针（字符指针char*），它与字符数组名同属于一种类型。字符串在内存中以'\\0'结尾。这种类型的字符串称为C字符串，或ASCIIZ字符串（ASCII序列后跟Zero之意）。 当编译器遇到一字符串时，就把它放到字符串池（data区的const区）中，以'\\0'作结束符，记下其起始地址，在所构成的代码中使用该地址。这样，字符串就“变成”了地址。 由于字符串的地址属性，所以两个同样字符组成的字符串的地址是不相等的。 程序中两个字符串的比较实质上是两个地址的比较。在编译时，给了这两个字符串不同的存放地点，所以两个“join”字符串的地址是不同的。 字符串、字符数组名、字符指针均属于同一种数据类型。 输出字符指针就是输出字符串。 输出字符指针的间接引用，就是输出单个字符 当pc指向buffer后，字符串字面值“hello”仍逗留在内存的data区，但是再也访问不到该字符串（数据丢失）了。所以对于字符串赋给字符指针的情形，指针一般不再重新赋值。 字符串比较应该是逐个字符一一比较，通常使用标准库函数strcmp（），它在string.h或cstring头文件中声明，其原型为：其返回值如下： （1）当str1串等于str2串时，返回值0； （2）当str1串大于str2串时，返回一个正值； （3）当str1串小于str2串时，返回一个负值。 C++中可以用字符串去初始化字符数组，但是不能对字符数组赋予一个字符串，原因是数组名是常量指针，不是左值。 函数strcpy（）仅能对以'\\0'作结束符的字符数组进行操作。若要对其他类型的数组赋值，可调用函数memcpy（）： #include&lt;iostream&gt; #include&lt;string.h&gt; using namespace std; int main() { char src[10] = &quot;*********&quot;; char dst[10]; char* pc = (char*) mempcpy(dst, src, 10); cout&lt;&lt;pc&lt;&lt;endl; //输出字符串 cout&lt;&lt;src&lt;&lt; endl; } 一个数组中若每个元素都是一个指针，则为指针数组。 在二维数组情况下，每一列的大小必须是一样的，因此只能将数组中所要存储的字符串中最长列的大小作为数组的列的大小。这样，共需3×8=24字节。如果被赋值的各字符串长短相差悬殊，则二维数组空间就浪费多一些。二维数组是作为一个整体存储在某一个区域中。 指针数组是数组，则其名字便为指针常量。指针具有类型，那么指针数组名是什么类型呢？ 指针数组名是指向指针的指针（即二级指针）。 这里的初始化值＂a＂＂b＂＂c＂必须为双引号，如果是单引号则表示是字符而不是字符串，而且字符没有'\\0'的结束标记。字符总是占一个字节。 传递数组给函数就是传递指针给函数。传递指针数组给函数就是传递二级指针给函数。 NULL是空指针值，它不指向任何地方。 NULL与void*是不同的概念，NULL是一个值，一个指针值，任何类型的指针都可赋予该值；而void*是一种类型，它定义无类型指针。 C++程序只不过是操作系统调用的函数。 argc表示参数个数，argv表示参数数组。 尽管main（）函数返回类型为void，即无返回值，但仍可使用exit（）给操作系统返回一个值。任何其他的函数使用exit（），即意味着程序终止，返回到操作系统中。 函数代码是程序的算法指令部分，它们同样也占有内存空间，存放在代码（code）区。每个函数都有地址。指向函数地址的指针称为函数指针。函数指针指向代码区中的某个函数，通过函数指针可以调用相应的函数。 FUN是一个函数指针类型，该指针类型中的指针指向一个函数，它有两个整数参数，返回一个整型数。FUN不是指针，只是一个指针类型名。通过第二个语句的函数指针定义，才确定一个函数指针funp。 程序中，sigma（）函数的第一个参数为函数指针，该指针指向的函数有一个double参数并返回double类型数。sin和cos就是这样的函数，它们作为实参赋给函数指针func。 最后一行声明一个函数，该函数返回一个函数指针，且有一个整型参数和一个函数指针参数。返回的函数指针是指向返回整型且无参数的函数。作为函数指针参数的指针指向无返回且无参数的函数。 指针不仅仅是地址，还有对数据类型的操作性规定。这是理解指针的关键。 堆允许程序在运行时，而不是在编译时，确定所申请的内存大小。在C++中，堆分配一般用new和delete两个操作符，malloc（）和free（）函数则相对过时，只在阅读用C编制的程序时才需要这些知识。 第9章 引用 引用是个别名，当建立引用时，程序用另一个变量或对象（目标）的名字初始化它。从那时起，引用作为目标的别名而使用，对引用的改动实际就是对目标的改动。 引用不是值，不占存储空间，声明引用时，目标的存储状态不会改变。所以，既然定义的概念有具体分配空间的含义，那么引用只有声明，没有定义。 #include&lt;iostream&gt; using namespace std; int main(){ int intOne = 5; int&amp; rInt = intOne; cout &lt;&lt; &quot;intOne: &quot; &lt;&lt; intOne &lt;&lt; endl; cout &lt;&lt; &quot;rInt: &quot; &lt;&lt; rInt &lt;&lt; endl; rInt = 7; cout &lt;&lt; &quot;intOne: &quot; &lt;&lt; intOne &lt;&lt; endl; cout &lt;&lt; &quot;rInt: &quot; &lt;&lt; rInt &lt;&lt; endl; cout &lt;&lt; &quot;&amp;intOne: &quot; &lt;&lt; &amp;intOne &lt;&lt; endl; cout &lt;&lt; &quot;&amp;rInt: &quot; &lt;&lt; &amp;rInt &lt;&lt; endl; } /* intOne: 5 rInt: 5 intOne: 7 rInt: 7 &amp;intOne: 0x61fe14 &amp;rInt: 0x61fe14 */ 引用在声明时必须被初始化，否则会产生编译错误。 引用运算符与地址操作符使用相同的符号。尽管它们显然是彼此相关的，但它们不一样。 引用运算符只在声明的时候使用，它放在类型名后面 为了提高可读性，不应在同一行上同时声明引用、指针和变量。 如果程序寻找引用的地址，它只能找到所引用的目标的地址。 C++没有提供访问引用本身地址的方法，因为它与指针或其他变量的地址不同，它没有任何意义。引用在建立时就初始化，而且总是作为目标的别名使用，即使在应用地址操作符时也是如此。 引用一旦初始化，它就维系在一定的目标上，再也不分开。任何对该引用的赋值，都是对引用所维系的目标赋值，而不是将引用维系到另一个目标上。 引用与指针有很大的差别，指针是个变量，可以把它再赋值成指向别处的地址；然而建立引用时必须进行初始化并且绝不会再指向其他不同的变量。 指针也是内存实体，所以可以有指针的引用： 对void进行引用是不允许的。 引用虽在语法上代表一种类型，但在概念上只是其他实体的附体，所以对同一实体可以定义多个引用，但对不存在的引用实体，就没有引用的引用，也没有指向引用实体的指针（所谓引用的指针）。 因为引用是变量或对象的引用，而不是类型的引用。所以有空指针，无空引用。 C++的目标之一就是让使用函数的用户无须考虑函数是如何工作的。传递指针给使用函数的用户增加了编程和理解的负担，这些负担本应属于被调用函数。 #include&lt;iostream&gt; using namespace std; void swap(int&amp; x, int&amp; y); int main(){ int x = 5, y = 6; cout &lt;&lt; &quot;Before swap, x: &quot; &lt;&lt; x &lt;&lt; &quot; y: &quot; &lt;&lt; y &lt;&lt; endl; swap(x, y); cout &lt;&lt; &quot;After swap, x: &quot; &lt;&lt; x &lt;&lt; &quot; y: &quot; &lt;&lt; y &lt;&lt; endl; } void swap(int&amp; rx, int&amp; ry){ int tmp = rx; rx = ry; ry = tmp; } /* Before swap, x: 5 y: 6 After swap, x: 6 y: 5 */ 引用隐藏了函数所使用的参数传递的类型，所以无法从所看到的函数调用判断其是值传递还是引用传递。 函数只能返回一个值。如果程序需要从函数返回两个值怎么办？解决这一问题的办法之一是用引用给函数传递两个参数，然后由函数往目标中填入正确的值。因为用引用传递允许函数改变原来的目标，这一方法实际上让函数返回两个信息。这一策略绕过了函数的返回值，使得可以把返回值保留给函数，作报告运行成败或错误原因用。 #include&lt;iostream&gt; using namespace std; bool Factor(int, int&amp;, int&amp;); int main(){ int number, squared, cubed; cout &lt;&lt; &quot;Enter a number between 0 and 20 : &quot;; cin &gt;&gt; number; bool error = Factor(number, squared, cubed); if(error) cout &lt;&lt; &quot;Error encoutered!\\n&quot;; else{ cout &lt;&lt; &quot;Number: &quot; &lt;&lt; number &lt;&lt; endl; cout &lt;&lt; &quot;Squared: &quot; &lt;&lt; squared &lt;&lt; endl; cout &lt;&lt; &quot;Cubed: &quot; &lt;&lt; cubed &lt;&lt; endl; } } bool Factor(int n, int&amp; rSquared, int&amp; rCubed){ if(n &gt; 20 | n &lt; 0) return true; rSquared = n*n; rCubed = n*n*n; return false; } /* Enter a number between 0 and 20 : 10 Number: 10 Squared: 100 Cubed: 1000 */ 函数返回值时，要生成一个值的副本。而用引用返回值时，不生成值的副本。 这种情况，函数fn2（）的返回值不产生副本，所以直接将变量temp返回给主函数。主函数的赋值语句中的左值c直接从变量temp中得到复制，这样避免了临时变量的产生。当变量temp是一个用户自定义的类型时，这种方式直接带来了程序执行效率和空间利用的利益。 如果返回的引用是作为一个左值进行运算，也是程序员最忌讳的。 由于返回的是引用，所以可以作为左值直接进行增量操作。该函数调用代表typeA还是typeB的左值视具体的学生成绩统计结果而定。 本例说明：返回引用的函数，可以使函数成为左值 引用变量概念上是不占空间的，引用变量被理解为粘附在初始化的实体上，它的实现对用户来说不可见。但并不等于具体实现的时候，非得不占任何空间。 保护实参不被修改的办法是传递const指针和引用。 C++不区分变量的const引用和const变量的引用**。程序绝不能给引用本身重新赋值，使它指向另一个变量，因此引用总是const的**。如果对引用应用关键词const，其作用就是使目标成为const变量 返还堆空间有两种方式，一种是delete pd，另一种是delete&amp;rd，因为&amp;rd和pd都指向同一个堆空间地址 函数的副作用是良性还是恶性，各人自有评说，对于函数潜在的破坏性，是放任自流，还是适当地抑制，专家们动尽了脑筋，直到C++类机制的实现，才使函数的恶性作用得以控制。 引用是C++独有的特性。指针存在种种问题，间接引用指针会使代码可读性差，易编程出错。而引用正好扬弃了指针 引用具有表达清晰的优点。引用将对传递的参数的责任附给了编写函数的程序员，而不是使用它们的各个用户。 第10章 结构 学习本章后，应能掌握结构声明、结构变量定义与访问结构成员的方法，掌握结构作为参数传递与返回结构的函数方法，掌握链表结构的各项基本操作。 用结构变量就可以有组织地把这些不同类型的数据信息存放在一起。 **结构是用户自定义的新数据类型，除此之外，它可与int、float等基本数据类型同等看待。**声明结构类型时，首先指定关键字struct和结构名，然后用一对大括号将若干个结构成员数据类型说明括起来。 通常情况下，结构声明在所有函数之外，位于main（）函数之前。这使新声明的数据类型在程序的任何地方都可以被使用。 声明一个结构并不分配内存，内存分配发生在定义这个新数据类型的变量中。 结构中包含的数据变量称为该结构的成员，如code、salary是结构Employee的成员。 一旦通过定义相应结构变量，分配了空间，就可以使用点操作符“.”（或称结构成员操作符）来访问结构中的成员。左操作数为结构类型变量，右操作数为结构中的成员。点操作符运算的结果可以是左值，也可以是右值。 两个不同结构名的变量是不允许相互赋值的，即使二者包含同样的成员。 根据结构类型可以定义一个变量，是变量就有地址。结构不像数组，结构变量不是指针。通过取地址“&amp;”操作，可以得到结构变量的地址，这个地址就是结构的第一个成员地址。 可以将结构变量的地址赋给结构指针，结构指针通过箭头操作符“-＞”（也是一种结构成员操作符）来访问结构成员。 但必须清楚，当用点操作符时，它的左边应是一个结构变量；当用箭头操作符时，它的左边应是一个结构指针。 指针是有类型的，（间接）引用一个整型指针得到一个整数，引用一个结构指针得到一个结构。即*prPtr的值就是结构Person的变量pr1的值，而不会是其他类型的值。 结构数组中，每个元素都是结构变量，访问结构数组元素中的成员，方法与前类似。 发生交换时，并不是两个结构变量值交换，而是两个结构指针交换，所以交换的临时变量是一个结构指针。 结构可以按值传递，这种情况下整个结构值都将被复制到形参中去。 结构也可以引用传递，这种情况下仅仅把结构地址传递给形参 由于结构的大小是随用户定义而定的，所以有时候会很大。当结构很大时，引用传递的优越性才真正开始体现。引用传递的进一步介绍在18.3节。在编程经验上，除非是小结构，一般很少按值传递。 由于结构返回时，要复制结构值给一个临时结构变量（见9.6节），当结构很大时，运行效率会受影响。可以用一种效率更高的结构参数引用传递的方法来代替。结构参数引用传递时无须复制结构值，连赋值操作都不需要了。 结构可以嵌套，即结构中可以包含结构成员。 结构不可以递归嵌套，即结构成员不能是自身的结构变量，但可以用自身结构指针作为成员。 name成员含有结构中的实际信息，pN成员是指向另一个List的指针。这种结点（结构的实例）通过每个List的pN成员链接起来，能用于构造任意长的结构链，这样的结构链称为链表。链表中的每个List结构变量称为结点。 第二部分 面向对象程序设计 第11章 类 学习本章后，要求掌握声明和定义类和成员函数的方法，掌握访问成员函数的方法，理解保护数据屏蔽外部访问的原理，使得对类的封装有更好的认识。 C的结构不含成员函数。C++的类既能包含数据成员（data member），又能包含函数成员或称成员函数（member function）。 关键字class表示类，Savings是类名，一般首字符用大写字母表示，以示与对象名的区别。关键字public和protected（或private）表示访问控制。 在类中说明的，要么是数据成员，要么是成员函数。它们或者说明为public的，或者说明为protected的，或者说明为private的。 而C++中，默认情况下类（class）定义中的成员是private的。 结构在C中不允许有成员函数，而在C++中可以有成员函数。 在面向对象中，算法与数据结构被捆绑成一个类，从这样的角度看问题，就不用为如何实现通盘的程序功能而费尽心机了。现实世界本身就是一个对象的世界，任何对象都具有一定的属性与操作，也就总能用数据结构与算法二者合一地来描述。 类名Tdate的作用是指出Set（int，int，int）是Tdate的一个成员函数，而不是其他类的成员函数（如Teacher∷Set（int）），也不是普通函数。没有类名的函数也称为非成员函数 成员函数也叫方法（mathod），它多出现于面向对象方法论的叙述中。 ∷叫作用域区分符，指明一个函数属于哪个类或一个数据属于哪个类。∷可以不跟类名，表示全局数据或全局函数（即非成员函数）。 类定义和其成员函数定义分开，是目前开发程序的通常做法。我们把类定义（头文件）看成类的外部接口，类的成员函数定义看成类的内部实现。 在类定义的外部定义成员函数，比在类内部定义时，成员函数名前多加上一个类名。如果该函数的前面没有用“类名∷”表达形式把它与该类紧紧连在一起，编译器就会认为该函数是一个普通函数，它只是与类中的成员函数有相同的名字罢了。以后在连接时，会查出缺少与成员函数相对应的定义而报错。 类名加在成员函数名之前而不是加在函数的返回类型前。 由于类名是成员函数名的一部分，所以一个类的成员函数与另一个类的成员函数即使同名，也不能认为是重载。 一个对象要表现其行为，就要调用它的成员函数。调用成员函数的形式类似于访问一个结构对象的分量，先指明对象，再指明分量。它必须指定对象和成员名，否则无意义。 对象可以由指针来引导。 用对象的引用来调用成员函数，看上去和使用对象自身的形式一样。 成员函数必须用对象来调用。另一方面，在成员函数内部，访问数据成员或成员函数无须如此。 原来，在对象调用s.Set（2，15，1998）时，成员函数除了接受3个实参外，还接受了一个对象s的地址。这个地址被一个隐含的形参this指针所获取，它等同于执行this=&amp;s。所有对数据成员的访问都隐含地被加上前缀this-＞ 因为成员函数是所有对象共享的代码，不是某一个对象所独占的，所以不能在成员函数内使用某个特定的对象。在编译期间，s对象由于没有在成员函数内部或文件作用域中声明而导致失败。 一个类对象所占据的内存空间由它的数据成员所占据的空间总和所决定。类的成员函数不占据对象的内存空间。 可以把类的成员声明作为私有的（private），使外部不能访问它们而起到保护作用。一个类定义，如果不写访问控制说明符（public、protected、private），那么它就默认为private。 protected和private的区别，在类的继承中才表现出来 编制应用程序，想要使用某个类，所要了解的全部内容是它的公共成员，它们有什么用，参数是什么 math.h是C库函数头文件，专门描述数学函数，而cmath则是对应C++的数学函数头文件，其为math.h的改造版，使之适应C++编程，例如允许函数重载等。此处包含cmath和math.h等价。 由于类很好地屏蔽了内部数据表示，所以由类负责的内部实现上的维护不影响应用程序的开发，类编程与应用编程作了分工，职责明确，使得编程工作可以模块化运作，这大大减轻了开发应用程序的强度。 一个类的所有成员位于这个类的作用域内，一个类的任何成员都能访问同一类的任一其他成员。C++认为一个类的全部成员都是一个整体的相关部分。 类作用域是指类定义和相应的成员函数定义范围。在该范围内，一个类的成员函数对同一类的数据成员具有无限制的访问权。 类X的数据成员m的作用域尽管在类X中，但是成员函数中定义了同名的局部作用域变量后，就把数据成员m给隐藏了。 一个类名被在后面的函数中的形参所覆盖，在该函数内，要定义一个类对象，则加上class即可 在函数中定义的类称为局部类，局部类在面向对象程序设计中并不多见。类作为类型也有作用域，局部类的作用域在定义该类的函数块中。 局部类的成员函数必须在类定义内部定义，因为若在类外部和包含该类的函数内部中定义，则导致在函数内部定义函数的矛盾。如果在包含类的函数外部定义，则该局部类无法与其取得联系。 非类型名（变量名、常量名、函数名、对象名或枚举成员）不能重名 在一个作用域中，一个名字可以声明为一个类型，也可以声明为一个非类型。当二者同时登场时，类型名要加前缀，以区别非类型名。 数据与算法（操作）结合，构成一个不可分割的整体（对象）。其次是，在这个整体中一些成员是保护的，它们被有效地屏蔽，以防外界的干扰和误操作；另一些成员是公共的，它们作为接口提供给外界使用。 将类的描述分成类的外部接口和类的内部实现就是下面两个文件的代码 在point.h头文件中，是一个类定义。其中保护数据成员并不是外部接口部分，但作为类定义的整体（从开括号起到闭括号止）描述，只好把它放在头文件中。对于面向对象程序设计之严格的内外界面描述来说，这是C++类机制中无可奈何的一面。但它不妨碍类的外部接口的有效性。 其中，class.cpp's表示多个类成员函数定义的源文件；function.cpp's表示多个函数定义的源文件。 类定义以头文件的方式提供，成员函数定义则以一定的计算机硬件或操作系统为背景而编译实现的内部代码方式提供。 自定义类库头文件称为类库设计。而在main（）函数开始之后的面向对象程序设计，则显得相对自然和简洁。往往是先定义若干对象，然后调用其成员函数，由成员函数来完成程序员所规定的操作（即让对象表现自己）。 第12章 构造函数 C++的构造函数和析构函数使类对象能够轻灵地被创建和撤销。构造函数创建类对象，初始化其成员；析构函数撤销类对象。 学习本章后，要求理解类与对象的区别，掌握定义构造函数和析构函数的方法，把握默认构造函数的意义，了解类成员初始化的问题，掌握构造类成员的方法。 一个类描述一类事物，描述这些事物所应共同具有的属性，如人有身高、体重、文化程度、性别、年龄、民族等。 一个对象是类的一个实例，它具有确定的属性，如张三（人的实例）身高180cm，体重70kg，大学本科，男，21岁，汉族。 人类只有一个，人类的实例可以有无数个。对象可以被创建和销毁，但类是无所不在的。 全局对象在主函数开始执行前先被建立，局部对象在程序执行遇到它们的对象定义时才被建立。与定义变量类似，定义对象时，C++为其分配内存空间。 对象的意义表达了现实世界的实体，因此，一旦建立对象，需要有一个有意义的初始值。C++建立和初始化对象的过程专门由该类的构造函数来完成。这个构造函数很特殊，只要对象建立，它马上被调用，给对象分配内存空间和初始化。 C++另有一种析构函数，它也是类的成员函数，当对象撤销时，就会马上被调用，其作用是释放与对象捆绑的资源，做一些善后处理 我们要求建立对象的同时自动调用构造函数，省去人为调用的麻烦。 **类只有一个名字，但可以有多个对象名，每个对象创建时，都要调用该类的构造函数。**类的唯一性和对象的多样性，使我们马上想到用类名而不是对象名来作为构造函数名是比较合适的。 与成员函数相同，构造函数可以放在类的外部定义。 构造函数另一个特殊之处是它没有返回类型，函数体中也不允许返回值，但可以有无值返回语句“return；”。因为构造函数专门用于创建对象并为其初始化，所以它不能随意被调用。没有返回类型，正显得它与众不同。 如果一个类对象是另一个类的数据成员，则在创建那个类的对象所调用的构造函数中，对该成员（对象）自动调用其构造函数。 #include&lt;iostream&gt; using namespace std; class Student { private: int someHours; float gpa; public: Student(){ cout &lt;&lt; &quot;Constructing student.\\n&quot;; someHours = 100; gpa = 3.5; } ~Student(){ cout &lt;&lt; &quot;Destroying student.\\n&quot;; } }; class Teacher{ public: Teacher(){ cout &lt;&lt; &quot;Constructing teacher.\\n&quot;; } ~Teacher(){ cout &lt;&lt; &quot;Destroying teacher.\\n&quot;; } }; class TutorPair{ public: TutorPair(){ cout &lt;&lt; &quot;Constructing tutorPair.\\n&quot;; } ~TutorPair(){ cout &lt;&lt; &quot;Destroying tutorPair.\\n&quot;; } private: Student student; Teacher teacher; int noMeetings; }; int main(){ TutorPair tp; cout &lt;&lt; &quot;Back to Main!\\n&quot;; } /* Constructing student. Constructing teacher. Constructing tutorPair. Back to Main! Destroying tutorPair. Destroying teacher. Destroying student. */ 该构造启动时，首先分配对象空间（包含一个Student对象、一个Teacher对象和一个int型数据），然后根据在类中声明的对象成员的次序依次调用其构造函数。这里先调用Student（）构造函数，再调用Teacher（）构造函数，最后才执行它自己的构造函数的函数体。按照这个顺序，分别产生运行结果的第一、第二、第三行输出。当执行完TutorPair（）构造函数后，控制权回到主函数中，产生第四行输出。 这个例子告诉我们，类在工作过程中分工十分明确，每个类只负责初始化它自己的对象。当TutorPair类要初始化成员Student类对象的时候，马上调用Student构造函数，而不是由自己去包办 一个类可能在构造函数里分配资源，这些资源需要在对象不复存在前被释放。例如，如果构造函数打开了一个文件，文件就需要被关闭；或者，如果构造函数从堆中分配了内存，这块内存在对象消失之前必须被释放。析构函数允许类自动完成这些清理工作，不必调用其他成员函数。 **析构函数也是特殊的类成员函数，它没有返回类型，没有参数，不能随意调用，也没有重载。**它只是在类对象生命期结束的时候，由系统自动调用。在12.5节和12.6节将会看到，构造函数不同于析构函数，它可以有参数，可以重载。 析构函数名就在构造函数名前加上一个逻辑非运算符“~”，表示“逆构造函数”。 析构函数以调用构造函数相反的顺序被调用。 当主函数运行到结束的大括号处时，析构函数依次被调用，其调用顺序正好与构造函数相反。 构造函数可以被重载，C++根据声明中的参数选择合适的构造函数。 无参的构造函数被称为默认构造函数。 由于构造函数用于创建对象，所以调用它来给对象赋值是错误的。 显式调用构造函数将创建一个无名对象 要想共享初始化的过程，可以先定义一个共享成员函数，然后每个构造函数都调用之 还可以通过给最后一个构造函数以参数默认值，例如设定最后一个构造函数的3个参数的默认值为12、31、2003，那么参数不同的4种调用都能匹配该函数，从而使这4个构造函数结合成一个。 只要一个类定义了一个构造函数（不一定是无参构造函数），C++就不再提供默认的构造函数。也就是说，如果为类定义了一个带参数的构造函数，还想要无参构造函数，则必须自己定义。 与变量定义类似，在用默认构造函数创建对象时，如果创建的是全局对象或静态对象，则对象的位模式全为0，否则，对象值是随机的。 “Student s（＂Randy＂）；”语句执行步骤如下： （1）分配s对象空间，调用Student构造函数。 （2）建立s对象空间中的结构，第一为name[20]，第二为id。因id属于StudentID类，于是创建过程启动了调用StudentID的构造函数，这时，id的保护数据value得到了赋值，全局变量nextStudentID也得到了赋值，并且输出第一行信息。之后，返回到Student构造函数。 （3）执行Student构造函数体。输出第二行信息，数据成员name得到了赋值。之后返回到主函数main（）。 类是一个抽象的概念，并不是一个实体，并不含有属性值，而只有对象才占有一定的空间，含有明确的属性值。 我们需要一个机制来表示“构造已分配了空间的对象成员，而不是创建一个新对象成员”。该机制应在建立对象空间的结构时反映出来，即需要出现在函数调用刚刚转入之时，函数体执行（开括号）之前。 #include&lt;iostream&gt; #include&lt;cstring&gt; using namespace std; class StudentID{ public: StudentID(int id = 0){ value = id; cout &lt;&lt; &quot;Assigning student id &quot; &lt;&lt; value &lt;&lt; endl; } ~StudentID(){ cout &lt;&lt; &quot;Destroying id &quot; &lt;&lt; value &lt;&lt; endl; } private: int value; }; class Student{ public: Student(char* pName = &quot;no name&quot;, int ssID = 0) :id(ssID){ cout &lt;&lt; &quot;Constructing student &quot; &lt;&lt; pName &lt;&lt; endl; strncpy(name, pName, sizeof(name)); name[sizeof(name)-1] = '\\0'; } private: char name[20]; StudentID id; }; int main(){ Student s(&quot;Randy&quot;, 9818); Student t(&quot;Jenny&quot;); } **在Student构造函数头的后面，冒号表示后面要对类的数据成员的构造函数进行调用。**id（ssID）表示调用以ssID为实参的StudentID构造函数。 冒号语法使得常量数据成员和引用数据成员的初始化成为可能。 在SillyClass类的构造函数进入之后（开始执行大括号后的函数体语句时），对象结构已经建立，数据成员ten和refI已经存在，所以再在构造函数体内对常量赋值或对引用变量指派就不是初始化了 常量和引用变量的初始化必须放在构造函数正在建立数据成员结构空间的时候，也就是放在构造函数的冒号后面。 对于类的数据成员是一般变量的情况，则放在冒号后面与放在函数体中初始化都一样。 创建对象的唯一途径是调用构造函数。构造函数是一段程序，所以构造对象的先后顺序不同，直接影响程序执行的先后顺序，导致不同的运行结果。 局部和静态对象是指块作用域和文件作用域中的对象。它们声明的顺序与它们在程序中出现的顺序是一致的。 静态对象和静态变量一样，文件作用域中的静态对象在主函数开始运行前全部构造完毕。块作用域中的静态对象，则在首次进入定义该静态对象的函数时，进行构造。 和全局变量一样，所有全局对象在主函数开始运行之前，全部已被构造。 有两种方法可以解决这个问题：一是将全局对象先作为局部对象来调试；二是在所有怀疑有错的构造函数的开头增加输出语句，这样在程序开始调试时，可以看到来自这些对象的输出信息。 对于简单应用的单文件程序来说，全局对象可以按照它们出现的顺序依次进行构造。但是，单文件程序只是出现在实验室或教室里，真正有用的程序都是由多个文件组成的，这些文件被分别编译、连接。因为编译器不能控制文件的连接顺序，所以它不能决定不同文件中全局对象之间的构造顺序。 不要允许一个全局对象访问另一个全局对象。 由于按成员在类定义中的声明顺序进行构造，而不是按构造函数说明中冒号后面的顺序，所以num成员被赋的是一个随机值，并不是想赋的16，因为这时候，成员age还没有被赋值，age的内存空间中是一个随机值（此次运行，其值为0）。 第13章 面向对象程序设计 C++区别于C的特征是C++支持面向对象程序设计。在知道了C++中如何创建类后，必须搞清什么是面向对象程序设计，类适用于现实世界中的哪些问题，才能真正进行面向对象的思考和编程。 层层分类，使概念逐渐细化，即具体化。相反，归类的结果，便是逐步抽象的过程。 在面向对象的计算机世界中，我们把一辆实实在在的桑塔纳小轿车称作类（class）桑塔纳的一个实例（instance）或者说是对象（object）。 在面向对象的程序设计中，对象被分成类。类又是层层分解的，这些类与子类的关系可以被规格化地描述。描述了类，再描述其子类，就可以只描述其增加的部分。所有子类层次上的编程，都只需在已有的类的基础上进行。 在面向对象的分析和设计中，我们执行下面的步骤： （1）找出类； （2）描述类和类之间的联系； （3）用类来定义程序结构。 一般来说，有一个数据属性，就有该数据属性的访问操作。每个数据成员和成员函数的取名也是一个环节，应该使用易懂的组合单词，没有用的名字应删掉。 面向对象程序设计使用户既不需要懂计算机太多，也不需要懂业务太多。 面向对象程序设计可以将程序员分成两类： 一类是面向对象应用程序设计。他（她）们无须了解类的实现细节，就像使用微波炉那样，这要比结构化程序设计简单得多。 另一类是类库设计。他（她）们为面向对象程序设计提供“素材”。这些素材涉及各个领域，由各领域的专业人员来设计完成。他（她）们需要了解特定类的知识，如Josephus问题的解答。 **类定义是面向对象程序设计中的基础问题，对象定义是面向对象程序设计的一般操作。**定义类的过程要求了解问题中的组织思想和弄清本质。 类是很容易想象的，如果选择了一个错误的类，则描述起来很困难；如果是正确的类，则将很容易理解它，并清楚地描述出其成员函数和数据成员 第14章 堆与拷贝构造函数 在C++中，堆分配的概念得到了扩展，不仅C++的关键字new和delete可以分配和释放堆空间，而且通过new建立的对象要调用构造函数，通过delete删除对象也要调用析构函数。 应该掌握new和delete这两个操作符的使用，并能把握从堆中分配和释放对象以及使用对象数组的时机；领会拷贝构造函数的实质，区别浅拷贝和深拷贝，在程序中适当地运用拷贝构造函数。 C++程序的内存格局通常分为4个区： （1）全局数据区（data area）； （2）代码区（code area）； （3）堆区（即自由存储区）（heap area）； （4）栈区（stack area）。 全局变量、静态数据、常量及字面量存放在全局数据区，所有类成员函数和非成员函数代码存放在代码区，为运行函数而分配的局部变量、函数参数、返回数据、返回地址等存放在栈区，余下的空间都被作为堆区。 作符new和delete是C++语言的一部分，无须包含头文件。它们都从堆中分配和释放内存块 **操作堆内存时，如果分配了内存，就有责任回收它，否则运行的程序将会造成内存泄漏。**这与函数在栈区分配局部变量有本质的不同。 从C++的立场上看，不能用malloc（）函数的一个原因是，它在分配空间的时候不能调用构造函数。类对象的建立是分配空间、构造结构以及初始化的三位一体，它们统一由构造函数来完成。 然而malloc（）仅仅只是一个函数调用，它没有足够的信息来调用一个构造函数，它所接受的参数是一个unsigned long类型 不必显式指出从new返回的指针类型，因为new知道要分配对象的类型是Tdate。而且new还必须知道对象的类型，因为它要藉此调用构造函数。 “pD=new Tdate（1，1，1998）；”这一语句，使new去调用了构造函数Tdate（int，int，int），new是根据参数匹配的原则来调用构造函数的。 分配过程将激发noOfObjects次构造函数的调用，从0至noOfObjects-1。调用构造函数的顺序依次为pS[0]，pS[1]，pS[2]，…pS[noOfObjects-1]。由于分配数组时，new的格式是类型后面跟［元素个数］，不能再跟构造函数参数，所以，从堆上分配对象数组，只能调用默认的构造函数，不能调用其他任何构造函数。 delete[]pS中的[]是要告诉C++，该指针指向的是一个数组。如果在[]中填上了数组的长度信息，C++编译系统将忽略，并把它作为[]对待。但如果忘了写[]，则程序将会产生运行错误。 堆空间相对其他内存空间比较空闲，随要随拿，给程序运行带来了较大的自由度。使用堆空间往往由于： （1）直到运行时才能知道需要多少对象空间； （2）不知道对象的生存期到底有多长； （3）直到运行时才知道一个对象需要多少内存空间。 可用一个对象去构造另一个对象，或者说，用另一个对象值初始化一个新构造的对象 对象作为函数参数传递时，也要涉及对象的拷贝。函数fn（）的参数传递的方式是传值，参数类型是Student，调用时，实参ms传给了形参fs，ms在传递的过程中是不会改变的，形参fs是ms的一个拷贝。这一切是在调用的开始完成的，也就是说，形参fs用ms的值进行构造。 类定义中，如果未提供自己的拷贝构造函数，则C++提供一个默认拷贝构造函数，就像没有提供构造函数时，C++提供默认构造函数一样。 在默认拷贝构造函数中，拷贝的策略是逐个成员依次拷贝。但是，一个类可能会拥有资源，当其构造函数分配了一个资源（例如堆内存）的时候，会发生什么呢？如果拷贝构造函数简单地制作了一个该对象的拷贝，而不对它本身进行资源分配和复制，就得面临一个麻烦的局面：两个对象都拥有同一个资源。当对象析构时，该资源将经历两次资源返还。 创建p2时，对象p1被复制给了p2，但资源并未复制，因此，p1和p2指向同一个资源，这称为浅拷贝。 当一个对象创建时，分配了资源，这时，就需要定义自己的拷贝构造函数，使之不但拷贝成员，也分配和拷贝资源。 创建p2时，对象p1被复制给了p2，同时资源也作了复制，因此，p1和p2指向不同的资源，这称为深拷贝。 **堆内存并不是唯一需要拷贝构造函数的资源，但它是最常用的一个。**打开文件，占有硬设备（例如打印机）服务等也需要深拷贝。它们也是析构函数必须返还的资源类型。因此，一个很好的经验是：如果你的类需要析构函数来析构资源，则它也需要一个拷贝构造函数。 一般规定，创建的临时对象，在整个创建它们的外部表达式范围内有效，否则无效。也就是说，“s=fn（）；”这个外部表达式，当fn（）返回时产生的临时对象拷贝给s后，临时对象就析构了。 因为外部表达式“Student&amp;refs=fn（）；”到分号处结束，以后从fn（）返回的临时对象便不再有效，这就意味着引用refs的实体已不存在，所以接下去的任何对refs的引用都是错的。 可以直接调用构造函数产生无名对象。 无名对象可以作为实参传递给函数，还可以拿来拷贝构造一个新对象，也可以初始化一个引用的声明。 因为有Student（char*）的构造函数，又有fn（Student&amp;s）函数，于是，fn（＂Jenny＂）便被认为是fn（Student（＂Jenny＂）），最终予以匹配。把构造函数用来从一种类型转换为另一种类型，这是C++从类机制中获得的附加性能 第15章 静态成员与友元 将所要共享的数据声明为static便能在类范围中共享，声明为static的类成员称为静态成员。友元函数完全是普通的C++函数，不同的是，它可以访问类的保护成员或私有成员，这样既方便编程，也提高了效率，但破坏了类的封装性。 类成员有数据成员和成员函数之分，静态成员也有静态数据成员和静态成员函数之分。静态成员用static声明。 但无论对象有多少，甚至没有，静态成员noOfStudents也只有一个。所有Student对象都能共享它，并且能够访问它。 静态数据成员是类的一部分，静态数据成员的定义是类定义的一部分，将其放在类的内部实现部分中定义是再合适不过了。定义时要用类名引导。重用该类时，简单地包含其头文件便可。 在类的外部，访问静态数据成员的形式可以是s1.noOfStudents，它等价于s2.noOfStudents，更通常的用法是Student∷noOfStudents（不能用Student.noOfStudents）。其意义是，静态数据成员是属于Student类的，而不是属于哪个特定对象的，它也不需要依赖某个特定对象的数据。 静态数据成员用得比较多的场合一般为： （1）用来保存流动变化的对象个数（如noOfStudents）； （2）作为一个标志，指示一个特定的动作是否发生（如可能创建几个对象，每个对象要对某个磁盘文件进行写操作，但显然在同一时间里只允许一个对象写文件，在这种情况下，用户希望说明一个静态数据成员指出文件何时正在使用，何时处于空闲状态）； （3）一个指向链表第一个成员或最后一个成员的指针（如pFirst）。 **静态成员函数定义在类的内部实现，属于类定义的一部分。**它的定义位置与一般成员函数一样。 一个静态成员函数不与任何对象相联系，故不能对非静态成员进行默认访问。 它们的根本区别在于静态成员函数没有this指针，而非静态成员函数有一个指向当前对象的指针this。 在函数内部，Sc∷nsfn（）对非静态成员的访问将自动地把this参数作为指向当前对象的指针，而当Sc∷sfn（）被调用时，没有任何对象的地址被传递。因此，当访问非静态成员时，无this指针（出错）。这就是为什么一个静态成员函数与任何当前对象都无联系的原因。 在类里声明一个普通函数，标上关键字friend，就成了该类的友元，可以访问该类的一切成员。 友元函数不是成员函数，它是类的朋友，因而能够访问类的全部成员。在类的内部，只能声明它的函数原型，加上friend关键字。友元声明的位置可在类内部的任何位置，既可在public区，也可在protected区，意义完全一样。友元函数定义则在类的外部，一般与类的成员函数定义放在一起。 一个类的成员函数可以是另一个类的友元。 不能在类名声明“class Student；”后声明Student类之前，出现定义类对象语句：Student ss；）。 **整个类可以是另一个类的友元，该友元称为友类。**友类的每个成员函数都可访问另一个类中的保护或私有数据成员。 使用静态数据成员，实际上可以消灭全局变量。全局变量给面向对象程序带来的问题就是违背封装原则。使用静态数据成员必须在main（）程序运行之前分配空间和初始化。 第16章 继承 我们也可以为一个派生类指定多个基类，这样的继承结构被称为多重继承或多继承。应能理解多继承的工作原理，了解多继承要解决的问题，认识虚拟继承的实质，把握多继承的方法，并能简单地从多个基类中派生出新类。 面向对象程序设计可以让你声明一个新类作为另一个类的派生。**派生类（也称子类）继承它父类的属性和操作。子类也声明了新的属性和新的操作，剔除了那些不适合于其用途的继承下来的操作。**这样，继承可让你重用父类的代码，专注于为子类编写新代码。 继承的方式是在类定义中类名后跟：public Student。一个研究生是一个大学生，当然，研究生类GraduateStudent也包含有自己特有的成员。 在布局上gs对象的最初部分是Student数据成员，fn（gs）等于做了一个Student（gs）的隐式转换，指向gs的this指针也就是指向Student对象的指针。由此看出，gs对象中包含有Student对象空间部分，gs用this指针访问Student成员与访问自己增加的成员没有差别。 根据类的实现机制，派生类对象创建时，将执行其默认的构造函数。该默认构造函数会首先调用基类的默认构造函数，而基类没有默认构造函数，但正好匹配默认参数的构造函数。所以在运行结果中，gs对象的name值为“no name”。 在构造一个子类时，完成其基类部分的构造由基类的构造函数去做，C++类的继承机制满意地提供了这种支持。 在构造函数原型的后面是Student（pName），advisor（adv），表示对数据成员初始化的方式。 基类初始化由Student（pName）去完成，派生类的构造总是由基类的初始化开始的。 派生类的析构函数以构造函数相反的顺序被调用，所以函数fn（）返回时，系统开始处理gs对象的析构，先调用GraduateStudent的析构函数，执行析构函数体的代码，然后调用Advisor析构函数，最后调用Student析构函数。 参数advisor与gs对象中的数据成员advisor处在两个不同的对象空间，所以当fn（）函数返回时，析构gs之后，并没有把函数fn（）的形参advisor析构掉，由于该形参是传引用方式，所以fn（）返回时只是解除引用关系，对其不做其他处理。 advisor形参就是main（）函数中的Advisor对象da。一直到main（）函数结束时，才由Advisor析构函数将da析构。 一个类作为基类时，对于使用基类的应用编程，其在类作用域之外，只能访问基类的公有成员，不能访问基类的保护成员和私有成员；对于公有继承基类的类编程，其在派生类作用域中，只能访问基类的公有成员和保护成员，不能访问基类的私有成员。这便是保护成员与私有成员的区别。 保护成员专为继承而设。 如果是公共继承，将使基类作为开源代码不断让类程序员派生代码从而迅速传播。 如果是保护继承，那么将使基类作为公司内部技术不断接续和派生。 如果是私有继承，那么将使技术世代单传，开发者在其派生类中也只能通过调用基类的成员函数来访问基类。 一个私有的或保护的派生类不是子类，因为非公共的派生类不能做基类能做的所有事。 Giraffe类私有继承了Animal类，意味着对象gir不能直接访问Animal类的成员。其实，在gir对象空间中，包含Animal类的对象，只是无法让其公开访问。 #include&lt;iostream&gt; using namespace std; class Animal{ public: Animal() {} void eat(){cout &lt;&lt; &quot;Eat.\\n&quot;;} }; class Giraffe : private Animal { public: Giraffe(){} void StretchNeck(){ cout &lt;&lt; &quot;stretch neck.\\n&quot;;} void take() { eat(); } }; void Func(Giraffe&amp; an){ an.take(); } int main() { Giraffe gir; gir.StretchNeck(); // gir.eat(); // error: 'Animal' is not an accessible base of 'Giraffe' Func(gir); } /* stretch neck. Eat. */ 私有继承就像是离家出走的小孩，一个人在外面飘泊。他（她）不能拥有父母的住房和财产（如gir.eat（）是非法的），在外面自然也就不能代表其父母，甚至他（她）不算是其父母的小孩（如Func（gir）调用被禁）。但是在他（她）的身体中，毕竟流淌着父母的血液（在gir对象空间中，含有Animal对象），所以，在小孩自己的行为中又有着与父母相似的成分（可以通过自身成员函数访问父类私有成员）。 保护继承与私有继承类似，继承之后的类相对于基类来说是独立的，保护继承的类对象，在公开场合同样不能使用基类的成员 公有继承将基类的保护成员和公有成员视为自己的保护和公有成员。 保护继承将基类的保护成员和公有成员全变为自己的保护成员。 私有继承将基类的保护成员和公有成员全变为自己的私有成员。 基类的私有成员在派生类采用任何继承方式下都是隔离的，也就是视派生类为“外人”，必须通过基类的保护成员或公有成员函数去访问它们。 基类的公有成员在派生类中的访问属性随继承方式而定。即公有继承下为公有成员，保护继承下为保护成员，私有继承下为私有成员。 调整访问控制属性的前提是在派生类中该成员必须是可见的。 类以另一个类对象作数据成员，称为组合。 GraduateStudent有一个Advisor；而在继承的场合，称GraduateStudent是一个Student。 **采用继承方式还是组合方式，要看类层次的描述，需要分析对象之间的关系。**例如，汽车与马达的关系，更多的是包含关系，所以应该设计成汽车组合马达更合适。而小轿车作为车辆的一种，更多的是分类关系，所以应该设计成车辆派生小轿车更合适。而在技术上，无论组合设计还是继承设计，都能实现所需功能。 成员构造和基类构造的不同在于，前者是以成员的名义去初始化，后者是调用基类构造函数，完成基类对象构造。 但是一些类却代表两个类的合成。例如，两用沙发，它是一个沙发，也是一张床，两用沙发应允许同时继承沙发和床的特征，即SleeperSofa继承Bed和Sofa两个类， 在编写应用程序时，程序员还得额外知道类的层次信息，加大了复杂度。这些在单继承中是不会出现的。 // ch16_5.cpp 多继承 #include&lt;iostream&gt; using namespace std; class Bed{ public: Bed(): weight(0){} void Sleep(){ cout&lt;&lt;&quot;Sleeping...\\n&quot;;} void SetWeight(int i){ weight = i;} protected: int weight; }; class Sofa{ public: Sofa() : weight(0){} void WatchTV(){ cout&lt;&lt;&quot;Watching TV.\\n&quot;;} void SetWeight(int i){ weight=i; } protected: int weight; }; class SleeperSofa : public Bed, public Sofa{ public: SleeperSofa(){} void FoldOut(){ cout&lt;&lt;&quot;Fold out the sofa.\\n&quot;; } }; int main() { SleeperSofa ss; ss.WatchTV(); ss.Sleep(); ss.FoldOut(); ss.Sofa::SetWeight(10); } SleeperSofa只需一个Furniture，所以我们希望它只含一个Furniture拷贝，同时又要共享Bed和Sofa的成员函数与数据成员，C++实现这种继承结构的方法称为虚拟继承（virtual inheritance）。 在Bed和Sofa继承Furniture中加上virtual关键字，这相当于说，“如果还没有Furniture类，则加入一个Furniture拷贝，否则就用已有的那一个。”此时一个SleeperSofa在内存中的布局见图16-7。 // ch16_6.cpp 虚拟继承 #include&lt;iostream&gt; using namespace std; class Furniture{ public: Furniture(){} void SetWeight(int i) { weight=i; } int GetWeight() const { cout&lt;&lt;weight&lt;&lt;endl;return weight; } protected: int weight; }; class Bed : virtual public Furniture{ public: Bed(){} void Sleep(){ cout&lt;&lt;&quot;Sleeping...&quot;&lt;&lt;endl;} }; class Sofa : virtual public Furniture{ public: Sofa(){} void WatchTV(){ cout&lt;&lt;&quot;Watching TV...&quot;&lt;&lt;endl;} }; class SleeperSofa : public Bed, public Sofa{ public: SleeperSofa() : Sofa(), Bed(){} void FoldOut(){ cout&lt;&lt;&quot;Fold out the sofa\\n&quot;; } }; int main() { SleeperSofa ss; ss.SetWeight(20); ss.GetWeight(); ss.Sleep(); ss.WatchTV(); } 在虚拟继承的情况下，应用程序main（）中引用GetWeight（）不再模糊，我们得到了真正的图16-4所示的继承关系。虚拟继承的虚拟和虚拟函数的虚拟没有任何关系。 构造对象的规则需要扩展以控制多重继承。构造函数按下列顺序被调用： // ch16_7.cpp 多继承的构造顺序 /* 构造函数按照下列顺序被调用： （1）任何虚拟基类的构造函数按照它们被继承的顺序构造； （2）任何非虚拟积累的构造函数按照它们被继承的顺序构造； （3）任何成员对象的构造函数按照它们声明的顺序调用； （4）类自己的构造函数。 */ #include&lt;iostream&gt; using namespace std; class OBJ1{ public: OBJ1(){ cout&lt;&lt;&quot;OBJ1\\n&quot;; } }; class OBJ2{ public: OBJ2(){ cout&lt;&lt;&quot;OBJ2\\n&quot;; } }; class B1{ public: B1(){ cout&lt;&lt;&quot;B1\\n&quot;; } }; class B2{ public: B2(){ cout&lt;&lt;&quot;B2\\n&quot;; } }; class B3{ public: B3(){ cout&lt;&lt;&quot;B3\\n&quot;; } }; class B4{ public: B4(){ cout&lt;&lt;&quot;B4\\n&quot;; } }; class Derived : public B1, virtual public B2, public B3, virtual public B4 { public: Derived() : B4(), B3(), B1(), obj2(), obj1() { cout&lt;&lt;&quot;Derived ok.\\n&quot;; } protected: OBJ1 obj1; OBJ2 obj2; }; int main(){ Derived d; cout&lt;&lt;&quot;This is ok!\\n&quot;; } /* B2 B4 B1 B3 OBJ1 OBJ2 Derived ok. This is ok! */ Derived的虚基类Base2和Base4最先构造，尽管它在Derived类中出现的顺序不在最前面；Derived的非虚基类其次构造，不管它在Derived构造函数中出现的顺序如何；Derived的组合对象obj1和obj2随后构造，它以类定义时数据成员排列顺序为准，不管在Derived构造函数中出现顺序怎样；最后是Derived类构造函数本身。 **单个继承提供了足够强大的功能，不一定非用多重继承不可。**我们应先学会阅读一些商品化的类库源程序中有关多重继承的部分，因为那些都是经过测试的安全代码。 第17章 多态 理解多态性对于继承的意义，掌握多态的工作原理，理解真正的多态是要维护类编程的独立性，不干扰应用编程；理解抽象类和具体类的区别，特别是看到多态支持抽象类时，对抽象编程的理解，学会运用纯虚函数。 C++允许子类的成员函数重载基类的成员函数 研究生对象gs调用其学费计算函数时，两个重载函数都在它自己可使用范围内，C++编译规定：gs.calcTuition（）指的是GraduateStudent∷calcTuition（）。若派生类没有定义其calcTuition（），则gs.calcTuition（）才指的是基类Student∷calcTuition（）。 C++的继承机制中用一种称为多态性（polymorphism）的技术来解决上面的问题。这种在运行时，能依据其类型确认调用哪个函数的能力，称为多态性，或称迟后联编（late binding），也有的译为滞后联编。 编译时就能确定哪个重载函数被调用的，称为先期联编（early binding） 例如，一个人对另一个人吆喝“开门”，彼此都处于同一场景中，明白是开机舱门还是开冰箱门等等。 为了指明某个成员函数具有多态性，用关键字virtual来标志其为虚函数。 由于fn（）标志为虚函数，编译看见b.fn（）后，将其作为迟后联编来处理，以保证在运行时确定调用哪个fn（）虚函数。 编译通常是在先期联编状态下工作的，只有看见虚函数，才把它作为迟后联编来实现。 fn（）在基类中声明为virtual，该虚函数的性质自动地向下带给其子类，所以SubClass子类中virtual可以省略。 多态性让类的设计者更多地去考虑工作的细节，而且这个细节简单，就是在成员函数前加一个virtual关键字。多态性使应用程序代码极大地简化，它是开启继承能力的钥匙。 如果虚函数在基类与子类中仅仅是名字相同，但参数类型不同，或返回类型不同，这样即使写上了virtual关键字，系统也不进行迟后联编。 而对于传自SubClass类对象的引用b，编译看见b.fn（i）的调用，分析到fn（i）虽然是多态函数，但是SubClass却没有自己的版本，对于首要的精准匹配性，自然只能调用Base：：fn（int）了，所以也就无须迟后联编了。 上述程序的编译分析与运行结果，关键是因为不恰当的虚函数没有构成多态，使编译看作为先期联编。有一种例外，如果基类中的虚函数返回一个基类指针或返回一个基类的引用，子类中的虚函数返回一个子类的指针或子类的引用，则C++将其视为同名虚函数并进行迟后联编。 一个类中将所有的成员函数都尽可能地设置为虚函数对编程固然方便，Java语言中正是这样做的，但是会增加一些时空上的开销。C++是在性能上有偏激追求的编程语言，只选择设置个别成员函数为虚函数。 只有类的成员函数才能说明为虚函数。这是因为虚函数仅适用于有继承关系的类对象，所以普通函数不能说明为虚函数。 静态成员函数不能是虚函数，因为静态成员函数不受限于某个对象。 内联函数不能是虚函数，因为内联函数是不能在运行中动态确定其位置的 构造函数不能是虚函数，因为构造时，对象还是一片未定型的空间。只有在构造完成后，对象才能成为一个类的名副其实的实例。 析构函数可以是虚函数，而且通常声明为虚函数。 pHeapObject是传递过来的一个对象指针，它或者指向基类对象，或者指向子类对象。在执行delete pHeapObject时，要调用析构函数，但是执行基类的析构函数？还是执行子类的析构函数？将析构函数声明为虚的，就可以解决这个问题。 继承给程序员在一个过程中从不同类里组合共有特征的能力，这个过程称为分解（factoring）。也就是把共同的特征分解到基类中。 一个程序员努力工作，写出比较巧妙的代码，以达到减少一些程序行的目的，是不值得的。这种巧妙常常会弄巧成拙。但是通过继承而分解出多余部分，可以合理地减少编程的工作量。 C++允许程序员声明一个不能有实例对象的类，这样的类唯一的用途是被继承。这种类称为抽象类（abstract class）。一个抽象类至少具有一个纯虚函数。所谓纯虚函数（pure virtual function）是指被标明为不具体实现的虚成员函数。 **在Withdrawal（）的声明之后的“=0”表明程序员将不定义该函数。**该声明是为派生类而保留的位置。Account的派生类被期待用一个具体的函数来重载该函数。 一个抽象类不能有实例对象，即不能由该抽象类来制造一个对象。 抽象类是作为基类为其他类服务的。一个Account类包含一个银行账户的所有特征。可以通过继承Account来创建其他类型的银行账户类，但是Account自身不能有实例对象。 所有纯虚函数被重载之前，抽象类的子类也一直保持抽象状态。 不能创建一个抽象类的对象，但是可以声明一个抽象类的指针或引用。 在这里，函数func（）的参数pA是一个Account指针。从otherFunc（）函数调用func（）时，传递的实参都是具有实际地址的子类对象。它们要么是Savings类对象，要么是Checking类对象，但绝不可能是Account类对象，因为在otherFunc（）函数中，绝不可能创建Account对象。 C++是强类型语言。当访问一个成员函数时，C++坚持要证明该成员函数在类中存在，否则拒绝接受。 如果Withdrawal（）是Account的成员函数，即使是纯虚函数，也能顺利通过编译。这正是纯虚函数为什么非要不可的原因所在。 纯虚函数是在基类中为子类保留的一个位置，以便子类用自己的实在函数定义来覆盖之。如果在基类中没有保留位置，则无法覆盖。 因为继承，所以有了类族对象，有了批量处理类族对象的需求。而多态便是专为处理类族对象而设。 显然，一个指针链表承载着一叠类族中的异类对象。但是它们的结点又同属一种Account*类型，使得循环（批量）处理异类对象成为可能。 而带有指针Account*参数的函数doBusiness（）接应着来自同一类族的异类对象的指针传递，通过调用Withdrawal（）和Display（）函数，展现了多态。 第18章 运算符重载 运算符重载的目的是：使C++代码更直观，更易读，由简单的运算符构成的表达式常常比函数调用更简洁、易懂。学习本章后，应该理解怎样重定义与类有关的运算符，学会怎样把一个类对象转换为另一个类对象，能把握重载运算符的时机。 如果不定义运算符重载，则expense2（）中principle*rate和principle+interest是非法的。因为参加运算的操作数是类对象而不是浮点值。 重载运算符时，要注意该重载运算符的运算顺序和优先级不变 运算符的操作数是规定好了的，例如，乘法和加法是双目运算符，++是单目运算符，等等。如果改变运算符的操作数个数，将带来编译器错误。 运算符是函数，除了运算顺序和优先级不能更改外，参数和返回类型是可以重新说明的，即可以重载 C++规定，运算符中参数说明都是内部类型时，不能重载。 C++还规定了点操作符（.）、域操作符（∷）、成员间访操作符（.）、成员指针操作符（-＞）、条件操作符（?：），这五个运算符不能重载，也不能创造新运算符。 不是必须要让operator+（）执行加法，可以让它做任何事。但是不让它做加法，而做其他操作是一个很糟的想法。如果重载＋运算符，向一个文件写10次“I like C++”，语法上可以，但与语义相差悬殊，不利于可读性，背离了允许运算符重载的初衷。当别人读这个程序时，发现s1+s2的操作，想象是某种加法操作，怎么也想不到会是这样的写操作。所以在使重载运算符脱离原义之前，必须保证有充分的理由。 如果只给出一个operator++（）定义，那么它一般可用于前缀、后缀两种形式。即d3++与++d3不作区别。 对于operator+（），两个对象相加，不改变其中任一个对象。而且它必须生成一个结果对象来存放加法的结果，并将该结果对象以值的方式返回给调用者。 虽然它无编译问题，可以运行，但是该堆空间无法回收，因为没有指向该堆空间的指针，会导致内存泄漏，程序不断做加法时，堆空间也在不断流失。 如果坚持结果对象从堆中分配，而返回一个指针，那样在应用程序中就要付出代价： 与operator+（）不一样，operator++（）确实修改了它的参数，而且其返回值要求是左值，这个条件决定了它不能以值返回。 可见函数体中内容几乎相同，只是非成员形式加s1和s2，成员形式s加当前对象，当前对象的成员隐含着由this指向。即yuan意味着this-＞yuan。 一个运算符成员形式，将比非成员形式少一个参数，左边参数是隐含的。 该变换可以是显式的，如s=RMB（1.5）+s那样，也可以是隐含的。此时，由于其中的一个操作数是RMB对象，而且参数个数相同，所以它首先假定operator+（RMB&amp;，RMB&amp;）可以匹配，然后寻找能够使用的转换。发现构造函数RMB（double）可作为转换的依据。在完成转换后，真正匹配operator+（RMB&amp;，RMB&amp;）运算符。所以程序员可以通过定义转换函数，来减少定义的运算符个数。 C++规定：=、（）、[]、-＞这4种运算符必须为成员形式。 使用前增量时，对对象（操作数）进行增量修改，然后再返回该对象。所以前增量运算符操作时，参数与返回的是同一个对象。这与基本数据类型的前增量操作类似，返回的也是左值。 使用后增量时，必须在增量之前返回原有的对象值。为此，需要创建一个临时对象，存放原有的对象，以便对操作数（对象）进行增量修改时，保存最初的值。后增量操作返回的是原有对象值，不是原有对象，原有对象已经被增量修改，所以，返回的应该是存放原有对象值的临时对象。 前后增量操作的意义，决定了其不同的返回方式。前增量运算符返回引用，后增量运算符返回值。 后增量运算符中的参数int只是为了区别前增量与后增量，除此之外没有任何作用。因为定义中无须使用该参数，所以形参名在声明与定义中均省略 转换运算符将对象转换成类型名规定的类型 转换运算符与转换构造函数（简称转换函数）互逆。例如，RMB（double）转换构造函数将double转换为RMB，而RMB∷operator double（）将RMB转换成double。 还要防止同一类型提供多个转换路径（转换的二义性），它会导致编译出错。 通常赋值运算符有两部分，第一部分与析构函数类似，在其中取消对象已经占用的资源。第二部分与拷贝构造函数类似，在其中分配新的资源。 对象t创建时，具有名字“temporary”，它在堆中存放。在t=s赋值过程中，通过调用deleteName（），原先名字占用的空间还给堆，再另外调用copyName（）从堆中分配新存储区去存储新名字“claudette”。 如果赋值运算符说明为保护或私有的，则可以将赋值操作限定在类的作用域范围，防止应用程序中使用赋值操作： 因为Name类对象newN使得=匹配为Name类的赋值运算符，但是protected限定符使之不能在普通函数中被调用，从而防止了对象非法赋值操作。 如果在类中没有说明本身的拷贝构造函数和赋值运算符，编译程序将会提供，但它们都只是对对象进行成员浅拷贝。在那些数据成员是指向堆空间指针的类中，必须避免使用浅拷贝，而要为类定义自己的赋值运算符，以给对象分配堆内存。 this指针指向当前的对象，它是所有成员函数的不可见的参数，在重载运算符时，经常返回this指针的间接引用。 拷贝构造函数用已存在的对象创建一个相同的新对象。而赋值运算符用已存在的对象赋予一个已存在的同类对象。 第19章 I/O 学习了本章后，应该理解怎样使用C++面向对象的I/O流，能够格式化输入和输出，理解I/O流类的层次结构，理解怎样输入和输出用户自定义类型的对象，能够建立用户自定义的流操作符，能够确定流操作的成败，能够把输出流系到输入流上。 上面这些语句，用错了数据类型，而编译都能通过。为此，程序员将花更多的代价在程序运行中出现的错误诊断上。特别对于scanf（）中的错误，往往是致命的。 printf（）和scanf（）却无能为力，它们既不能识别，也不能学会如何识别用户定义的对象 iostream是I/O流的标准头文件。 当程序测试并处理关键错误时，不希望程序的错误信息从屏幕显示重定向到其他地方，这时使用cerr流显示信息。 #include&lt;iostream&gt; using namespace std; void fn(int a, int b){ if(b==0) cerr &lt;&lt; &quot;Zero encoutered.&quot; &lt;&lt; &quot;The message cannot be redirected\\n&quot;; else cout &lt;&lt; a/b &lt;&lt; endl; } int main() { fn(20, 2); fn(20, 0); } 主函数第一次调用fn（）函数时，没有碰到除0运算，得到文件的写内容10，第二次调用fn（）函数时，碰到除0运算，于是在屏幕上输出错误信息。写到cerr上的信息是不能被重定向的，它只能输出到屏幕。 此处的文件名要说明其路径，斜杠要双写，因为编译器理解下的斜杠是转义字符。这与包含头文件时的路径不一样，因为包含头文件是由编译预处理器处理的。 假定程序中原来的有效位数设置不知道，“cout.precision（4）”可以返回原来设置的有效位数，保存该值在prePrecision变量中，使得最后用该值恢复原来的设置。 当程序使用cin输入时，cin用空白符和行结束符将各个值分开。但根据所需输入的值，可能需要读取一整行文本包括空白符。为了读取整行文本，可以使用getline成员函数。 程序中的X为大小写敏感的。一个小写X不会结束第一个cin.getline（）的输入，而且，在输入X之前，可以按一到多次回车键，而并不结束第一个cin.getline（）的输入。第一个cin.getline（）的输入操作将以键入X后的第一个回车结束。 根据程序的输入要求，有时需要执行每次输入一个字符。这时，可以使用get（）成员函数。 #include&lt;iostream&gt; #include&lt;cctype&gt; using namespace std; int main(){ char letter; while(!cin.eof()){ letter = cin.get(); letter = toupper(letter); if(letter == 'Y'){ cout &lt;&lt; &quot;'Y' be met.&quot;; break; } cout &lt;&lt; letter; } } 使用流成员函数的输入操作不只限于键盘，上例程序可从重定向输入中每次读入一个字符。 cin≫letter将跳过在文件中发现的任何空白字符（空白字符指空格、tab符、backspace符和回车符）。而cin.get（）则不跳过空白字符。 用get（）成员函数的第二种形式可以输入一系列字符，直到输入流中出现结束符或所读字符个数已达到要求。 getline（）和get（）第二种形式相同。唯一的不同是getline（）从输入流中输入一系列字符时包括分隔符，而get（）不包括分隔符。 cout＜＜letter；与cout.put（letter）；有一个区别，前者显示以该数据类型表示的形式，后者将参数值以字符方式显示。所以，若letter是char型，那么这两种方法都可以用来显示字母，若letter为int型，那么前者将在屏幕上显示65到90的数字，而不是字母A到Z。 #include&lt;iostream&gt; using namespace std; int main(){ for(char letter = 'A'; letter &lt;= 'Z'; letter++){ cout.put(letter); } cout &lt;&lt; &quot;\\n&quot;; for(char letter = 'A'; letter &lt;= 'Z'; letter++){ cout &lt;&lt; letter; } } 左移运算符也称插入运算符，它比较形象，执行“cout≪x；”输出时，好像x被插入到输出设备上。重载插入运算符的特性使得流I/O可扩展，这与printf（）是重要的区别。 #include&lt;iostream&gt; #include&lt;iomanip&gt; using namespace std; class RMB{ unsigned int yuan; unsigned int jf; public: RMB(double v = 0.0){ yuan = v; cout &lt;&lt; &quot;yuan: &quot; &lt;&lt; yuan &lt;&lt; endl; jf = (v-yuan)*100.0+0.5; cout &lt;&lt; &quot;jf: &quot; &lt;&lt; jf &lt;&lt; endl; } operator double(){ return yuan+jf/100.0; } void display(ostream&amp; out){ out &lt;&lt; yuan &lt;&lt; &quot;.&quot; &lt;&lt; setfill('0') &lt;&lt; setw(2) &lt;&lt; jf &lt;&lt; setfill(' '); } }; ostream&amp; operator &lt;&lt;(ostream&amp; oo, RMB&amp; d){ d.display(oo); return oo; } int main() { RMB rmb(1.5); // cout &lt;&lt; double(rmb) &lt;&lt; endl; cout &lt;&lt; &quot;Initially rmb=&quot; &lt;&lt; rmb &lt;&lt; &quot;\\n&quot;; rmb = 2.0 * rmb; cout &lt;&lt; &quot;then rmb=&quot; &lt;&lt; rmb &lt;&lt; endl; } 这时候，重载插入运算符应为RMB类的友元，因为它要直接访问RMB类的保护数据。但是它不能是成员，因为首先，插入运算符跟在ostream对象的后面，显然它不能是RMB类的成员；其次，ostream类在iostream头文件中定义，是标准类库，用户只能继承，不能修改标准类库，所以它更不能是ostream类的成员。 重载插入运算符中最后一条语句是“return oo；”，为什么要返回传递给它的ostream对象？ 这样允许该运算符在单个表达式中与其他插入运算符联结在一起。≪的运算顺序是从左到右，下面的表达式 这个运算符返回它的ostream对象，这一点很重要，这样做，对象才能被传递给下一个插入运算符。 插入运算符不能是成员函数，也就不能成为虚函数 cout≪a；能匹配重载的插入运算符，但是执行的结果是输出a的人民币值而不能输出a作为派生的附加信息a.c。 解决方法：在重载插入运算符中，不直接实现输出，而是调用display（）成员，再将display（）定义为虚函数。这样，重载插入运算符的行为便可随display（）的不同而不同。这就是上一节为什么要间接实现重载插入运算符的用意。 类Currency有三个子类RMB、EUR和USD。Currency中display（）成员定义为纯虚函数。在每一个子类中，display（）成员被重载，从而可以适当的格式输出相应对象。重载插入运算符函数对display（）的调用是一个虚调用。因此当它被传递以RMB类对象时，则像人民币那样输出；当它被传递以EUR对象时，则像欧元那样输出。因而，尽管重载的插入运算符不是虚拟的，因为它调用了一个虚函数，结果令人满意。 因为Currency是抽象类，不能构造该类的对象。 如果要打开一个文件用于输入，可以用ifstream类。 第20章 模板 本章介绍了模板的概念、定义和使用模板的方法，通过这些介绍，使读者有效地把握模板，以便能正确使用C++系统中日渐庞大的标准模板类库。 若一个程序的功能是对某种特定的数据类型进行处理，则若将所处理的数据类型说明为参数，就可把这个程序改写为模板。模板可以让程序对任何其他数据类型进行同样方式的处理。 其中的类型形式参数表可以包含基本数据类型，也可以包含类类型。如果是类类型，则须加前缀class。 函数模板是模板的定义，定义中使用通用类型参数。 模板函数是实实在在的函数定义，它是由函数模板生成的。编译系统在发现具体的函数调用时，匹配类型参数，生成函数代码。 这样的一个说明（包括成员函数模板定义），不是一个实实在在的类，只是对类的描述，称为类模板（class template）。 class_name＜类型实在参数表＞是模板类（template class），object是该模板类的一个对象。 类模板是模板的定义，定义中使用通用类型参数。 模板类是实实在在的类定义，是由类模板生成的。编译系统在发现以类模板方式创建其实例（对象）时，匹配类型参数，生成模板类定义。该模板类创建的对象即类模板的实例。 对于具有各种参数类型，相同个数、相同顺序的同一函数（重载函数），如果用宏定义来写： 则它不能检查其数据类型，损害了类型安全性。这也是为什么要使用函数模板的一个原因。 函数模板可将许多重载函数简单地归为一个 #include&lt;iostream&gt; using namespace std; template&lt;class T&gt; T Max(T a, T b){ return a &gt; b ? a : b; } int main() { cout &lt;&lt; &quot;Max(3, 5) is &quot; &lt;&lt; Max(3, 5) &lt;&lt; endl; cout &lt;&lt; &quot;Max('3', '5') is &quot; &lt;&lt; Max('3', '5') &lt;&lt; endl; } #include&lt;iostream&gt; #include&lt;cstring&gt; using namespace std; template&lt;class T&gt; T max(T a, T b){ return a &gt; b ? a : b; } char* max(char* a, char* b){ return strcmp(a, b) &gt;= 0 ? a : b; } int main(){ cout &lt;&lt; &quot;Max(\\&quot;Hello\\&quot;, \\&quot;Gold\\&quot;) is &quot; &lt;&lt; max(&quot;Hello&quot;, &quot;Gold&quot;) &lt;&lt; endl; } 编译程序在处理这种情况时，首先匹配重载函数，然后再寻求模板的匹配。 用类模板来定义一个通用链表，此时该通用链表还不是一个类定义，只是类定义的一个框架，即类模板。 /* listtmp.h */ # ifndef LIST # define LIST # include&lt;iostream&gt; using namespace std; template&lt;class T&gt; struct Node{ Node* pNext; T tValue; }; template&lt;class T&gt; class List{ Node&lt;T&gt; * pFirst, * pivot; public: List(){ pFirst=0; } void Add(T&amp;); void Remove(T&amp;); Node&lt;T&gt; * Find(T&amp;); void PrintList(); ~List(); }; template&lt;class T&gt; void List&lt;T&gt;::Add(T&amp; t){ Node&lt;T&gt; * tmp = new Node&lt;T&gt;; tmp-&gt;tValue = t; tmp-&gt;pNext = pFirst; pFirst = tmp; } template&lt;class T&gt; void List&lt;T&gt;::Remove(T&amp; t){ Node&lt;T&gt; * q = Find(t); if(!q) return; if(q==pFirst) pFirst = pFirst-&gt;pNext; else pivot-&gt;pNext = q-&gt;pNext; delete q; } template&lt;class T&gt; Node&lt;T&gt; * List&lt;T&gt;::Find(T&amp; t){ if(pFirst-&gt;tValue==t) return pFirst; for(Node&lt;T&gt; * p = pFirst-&gt;pNext; p; pivot=p, p = p-&gt;pNext) if(p-&gt;tValue==t) return p; return 0; } template&lt;class T&gt; void List&lt;T&gt;::PrintList(){ for(Node&lt;T&gt; * p=pFirst; p; p = p-&gt;pNext) cout &lt;&lt; p-&gt;tValue &lt;&lt; &quot; &quot; &lt;&lt; endl; } template&lt;class T&gt; List&lt;T&gt;::~List(){ for(Node&lt;T&gt; * p; p=pFirst; delete p) pFirst = pFirst-&gt;pNext; } # endif #include &quot;listtmp.h&quot; int main(){ List&lt;float&gt; floatList; for(int i = 1; i &lt; 7; i++) floatList.Add(* new float(i + 0.6)); floatList.PrintList(); float b = 3.6; floatList.Remove(b); floatList.PrintList(); } 标准模板类库STL（Standard Template Library）是一个基于模板的容器类库，它包括向量、链表、队列和栈，还包括了一些通用的算法，如排序和查找等。它已经成为C++标准的组成部分。使用标准模板类库的好处是：可以避免自己在开发模板类库时，不同模板类之间的功能重复；最大限度的类库重用；作为C++标准，可移植性强是不言而喻的。 在C++中，一个发展趋势是使用标准模板类库（STL），VC和BC都把它作为编译器的一部分。STL是一个基于模板的包容类库，包括向量、链表和队列，还包括一些通用的排序和查找算法等。 第21章 异常处理 在大型软件开发中，最大的问题就是错误连篇的、不稳定的代码。而在设计与实现中，最大的开销是花在测试、查找和修改错误上。 程序的错误，一种是编译错误，即语法错误。如果使用了错误的语法、函数、结构和类，程序就无法被生成运行代码；另一种是在运行时发生的错误，它分为不可预料的逻辑错误和可以预料的运行异常 逻辑错误是由于不当的设计造成的，如，某个排序算法不合适，导致在边界条件下，不能正常完成排序任务。 运行异常，可以预料，但不能避免，它是由系统运行环境造成的。 异常是一种程序定义的错误，它对程序的逻辑错误进行设防，对运行异常加以控制。C++中，异常是对所能预料的运行错误进行处理的一套实现机制。 恢复的过程就是把产生异常所造成的恶劣影响去掉，中间可能要涉及一系列的函数调用链的退栈，对象的析构，资源的释放等 在C++中，异常是指从发生问题的代码区域传递到处理问题的代码区域的一个对象， 异常的基本思想是： （1）实际的资源分配（如内存申请或文件打开）通常在程序的低层进行，如图21-1中的k（）。 （2）当操作失败、无法分配内存或无法打开一个文件时，在逻辑上如何进行处理通常是在程序的高层，如图21-1中的f（），处理中间还可能有与用户的对话。 （3）异常为从分配资源的代码转向处理错误状态的代码提供了一种表达方式。如果还存在中间层次的函数，如图21-1中的g（），则为它们释放所分配的内存提供了机会，但这并不包括用于传递错误状态信息的代码。 使用异常的步骤是： （1）定义异常范围（try语句块）。将那些有可能产生错误的语句框定在try块中。 （2）定义异常处理（catch语句块）。将异常处理的语句放在catch块中，以便异常被传递过来时就处理它。 （3）抛掷异常（throw语句）。检测是否产生异常，若是，则抛掷异常。 当打开文件失败时，就执行“throw argv[1]；”语句，throw后面的表达式argv[1]的类型被称为所引发的异常之类型。 在try块之后必须紧跟一个或多个catch（）语句，目的是对发生的异常进行处理。catch（）括号中的声明只能容纳一个形参，当类型与抛掷异常的类型匹配时，该catch（）块便称捕获了一个异常而转到其块中进行异常处理。 可以将抛掷异常与处理异常放在不同的函数中。 应把异常处理catch块看作是函数分程序。跟在catch之后的圆括号中必须含有数据类型，捕获是利用数据类型匹配实现的。在数据类型之后放参数名是可选的。参数名使得被捕获的对象在异常处理程序中被引用。 捕获的原因是抛掷的数据类型与异常处理程序的数据类型相匹配。 如果一个函数抛掷一个异常，但在通往异常处理函数的调用链中找不到与之匹配的catch，则该程序通常以abort（）函数调用终止。 g（'w'）将能顺利地匹配函数g（int b），但是抛掷异常与异常处理程序之间，是按数据类型的严格匹配来捕获的。不允许类型转换 如果catch语句块执行完毕，则跟随最后catch语句块的代码（如果有的话）就被执行。 →在一个类定义的内部定义一个类，称为嵌套类。 嵌套类的成员函数和静态成员可以在包含该类的外部定义，但嵌套类的作用域在包含该类定义的内部。 值得注意的是，C++自带标准异常类定义及默认异常处理。它在头文件exception中。其中当申请内存空间的new操作失败时，将抛掷bad_alloc异常，它是except异常类的子类。 函数f（）中的catch（...）块，参数为省略号，定义一个“默认”的异常处理程序。通常这个处理程序应在所有异常处理块的最后，因为它与任何throw都匹配，目的是为避免定义的异常处理程序没能捕获抛掷的异常而使程序运行终止。 可以把多个异常组成族系。构成异常族系的一些示例有数学错误异常族系和文件处理错误异常族系。在C++代码中把异常组在一起有两种方式：异常枚举族系和异常派生层次结构。 异常捕获的规则除了前面所说的，必须严格匹配数据类型外，对于类的派生，下列情况可以捕获异常： （1）异常处理的数据类型是公有基类，抛掷异常的数据类型是其派生类； （2）异常处理的数据类型是指向公有基类的指针或引用，抛掷异常的数据类型是指向派生类的指针或引用。 →对于派生层次结构的异常处理，catch块组中的顺序是重要的。因为“catch（基类）”总能够捕获“throw派生类对象”，所以“catch（基类）”块总是放在“catch（派生类）”块的后面，以避免“catch（派生类）”永远不能捕获异常。 个人点评 点评:★★★★☆ 有一些代码错误，总体介绍挺全面。 ","link":"https://Angus1996.github.io/post/ccheng-xu-she-ji-jiao-cheng-di-3-ban-tong-yong-ban-qian-neng/"},{"title":"2020年春招实习上岸","content":"一场疫情，使得所有人的关注点在一二三月份，基本都在疫情的发展上。现在国内疫情基本稳定了，国外还在第一阶段爆发期。新年过后的三月份，实习生的招聘就陆续开始了。按照往年学长们的经验，是要先拿小厂刷面试经验的，然而因为疫情，那时候的小厂基本没有动静。只能硬着头皮投大厂了。 我是新年过后的二月中下旬开始刷了一遍剑指offer，然后看CS-note，准备简历。因为研究生期间的主要项目都是和机器学习相关的，趁着2019年末，也做了三场和图像有关的比赛，就是为了找实习或者找工作做准备。简历上项目经历主要写了自己本科一段实习（ionic app开发），三个在实验室做的项目。比赛经历包括本科时候数学建模华中赛三等奖、美赛一等奖，图像对抗样本攻防比赛、多人种人脸识别比赛和华为云图像分类比赛。科研成果是两篇在投一作论文，一篇四作论文。荣誉是国励、优秀毕业生、优秀毕业论文奖。 机器学习/计算机视觉/图像算法篇 一开始自己就是想投计算机视觉、机器学习、图像算法的岗位。 **腾讯：**一开始投的就是腾讯，结果第一面是QQ音乐部门做推荐的捞的我，因为不懂推荐所以挂了。后来做安卓开发的捞了我，可是我不会Java多线程编程，安卓开发也仅限《第一行代码》这本书，所以又挂了。后来应用开发亮了一次，没有面就灰了（实验室一个专硕学弟这个岗位拿到了offer）。应用研究也是亮了就灰了，然后亮了又灰了。直到笔试（数据分析与应用研究试卷，100%+100%+10%+30%+0%）。 **字节跳动：**投了字节跳动的教育部门，因为我挺喜欢教育行业的，面试过程比较难受，面试官全程关了摄像头，而且还时不时又汤匙敲击被子的声音。感觉回答得还可以。手撕代码：两个交叉单链表的第一个公共节点，只写出了普通做法，问优化，没写出来。挂了。第二志愿也是一直简历评估。（准确说是收到面试反馈调查问卷，填了之后就挂了） **蘑菇街：**投了蘑菇街（据说955）算法实习生（图像），一面QQ视频面试，问了机器学习SVM的损失函数、核的问题，还有优化算法（牛顿法和SGD）谁快，两个问题就把我问倒了，当然一面挂。 经过这三家，意识到自己太菜了，开始《百面机器学习》来回看，还有深度学习500问，机器学习面经来回刷。买了左程云大佬的《程序员代码面试指南》回来看（看了很少，，） **网易：**计算机视觉实习生，笔试挂。 **奇安信：**机器学习工程师，牛客网投的，唯一一次变化是从内推简历初选变成简历初选待处理。没有消息。。 **微软：**找了内推，投了机器学习，听说面试基本编程，胆怯了，hr小姐姐打电话来问我面试时间时，取消了面试。 **IBM：**官网投的青出于蓝计划的人工智能实习生，后来发现岗位没了？？（难道是本来不准备招了但是忘了取消岗位，看到我投了，为了不误导大家，直接取消了岗位？？）。 **招行卡中心：**投的IT方向算法实习生，笔试完，没有面试机会。牛客网看到一堆华五没有面试机会，内推群里一个南京大学的小姐姐也没有面试机会。不知道筛人标准到底是啥？（此处继续表扬我的学弟，又拿到了offer）。 **陌陌：**计算机视觉实习生，没有消息。 **海康威视：**目前过了第一个电话面，第一轮技术面，面了还不知道结果。 软件开发篇 学弟做后台拿offer很顺利，想着也要多了解Java虚拟机，GC算法等，就把《深入理解Java虚拟机》过了一遍。 **远景智能：**Java实习生，笔试完没了消息，挂了 **Thoughtworks：**软件开发实习生吧，没有面试机会。 数据分析篇 算法眼看着找不到实习机会了，后台开发没有开发经验也很难了，就想要转数据分析了，看了《深入浅出统计学》、《SQL必知必会》，《增长黑客》。 **快手：**数据分析实习生，做了笔试，后面复筛变不合适。 **微众银行：**数据分析，面试官团队偏业务，我想做偏数据研发的，然后说把我推个其他部门，没有了消息。 **美团：**数据研发，电话一开始问我面试时间，直接说了七八月，然后说他们希望更久实习，同样推给其他部门，没有了消息。 **银联云闪付：**数据挖掘实习生，按照要求发了视频，一周没消息，甚至感谢信都没有。 安全工程师篇 导师（机器学习，信息安全方向，有对抗样本、信息隐藏、生成对抗网络、安卓恶意软件等研究）推荐（应该是内内推人和我们导师在同一个学术交流群），媒体安全研究，本来对安全不太感冒。还是硬着头皮，在看了《媒体安全》的一个章节ppt后就硬着头皮面试了。 内推人先是打了一个电话，一起盘点了一些简历上的东西，问了有没有开发经验（写过ionic，写过简单安卓app）。最后叮嘱我看看媒体安全研究的东西，特别是数字水印。 可能因为没有媒体安全的项目经历，所以一面面试官主要还是问了简历上图像相关的项目和比赛，最后夸我这几年过得挺充实的。二面面试官从高考填报志愿问起，问得我中间几度怀疑人生。后来也穿插一些信号处理、数字水印传统方法的问题。最后甚至叫我不要灰心，面试只是对过往那个的总结。一度以为自己已经挂了，隔了八天又来一个面试。面试官连自我介绍环节都省了，让我一度以为阿里真的像网上传言拿我刷KPI了。结果反问环节才知道是交叉面了，已经走到倒数第二步了。隔了两天，hr面。第一次面到hr面，那叫一个激动，搜各种hr面经，准备好常问的各种问题。谁知阿里的hr不一样呢！！问我数字水印的技术难点有哪些？数字水印应该具备哪些特点？？还好依稀还记得一些。实习时间问题，果断回答七八两个月，九月要回学校准备毕设。面完hr才知道说两个月的很难过，大家都是面试说三到六个月，实际干两个月跑路。又以为自己要挂了，就给内推人隔三岔五发短信（此处发短信因为记错了面试时间，所以发错对象了，后来才发现发到一面面试官了，因为内推人和我打电话和一面面试官就隔了一天，，还好一面面试官人比较好，给我转达到了内推人，所以后面还是发内推人邮件了）发邮件问。五一前知道面试过了，等审批，网上又有好多说审批也会因为测评卡人，此时已经不记得测评做了啥了，，，。加了鱼塘群一起等。五一那叫一个煎熬。。五一过后再问，压根还没审批，hrg和媒体安全主管商量，想让我去移动安全。。勉强答应了。四天后就收到了意向书。从3.30号内推投递，到意向书，整整四十天！ 华为操作系统篇 学长给我推的武汉长沙地区领鹰计划，比勇敢星多一轮技术面。投的是操作系统工程师，把本科教材《操作系统》翻出来过了一遍，又把面经都写了一遍（后面两面竟然都不问，好气啊😞，白背了感觉）。目前两面都面完了。5.8号上午一面，5.9号上午二面。5.9号下午还面了海康威视，第一次遇到技术面是小姐姐（微众银行面试官可能已经有孩子了吧，不能叫小姐姐了吧？），聊得还挺开心了。聊完就收到阿里意向书了。 总结 一开始还是要找好定位（比如我专硕学弟定位找后台开发，在实验室就看了很多书，三月底的样子拿到了腾讯offer，后面又相继拿到快手和招行卡中心），像我这样真的是海投了，复习重点都不一样。不过最重要的一点，还是简历上的东西都是熟悉，都能从背景介绍、方法、效果等多个方面说清楚。决定去阿里集团安全部移动安全了。主管也是华科毕业，不过是计算机系的，他说他也是从图像处理转的移动安全。希望实习顺利入职、顺利转正吧。 ","link":"https://Angus1996.github.io/post/2020-nian-chun-zhao-shi-xi-shang-an/"},{"title":"小城的春天","content":"很久没有写过随笔了，以前还有每周在周记本上用钢笔记录每周发生的日常以及自己的想法的习惯。现在，疫情在家，周记本和钢笔墨水也都在学校。一场疫情，我相信会改变了很多人的生活方式和生活态度。 作为一个二年级研究生，明年就要毕业了。按照学长的规律经验，这个时候应该是在学校看书刷题找实习。可是这场疫情，让很多小的企业开始走向倒闭，大的企业也开始缩招甚至不招了。即使是现在看起来招了很多实习生的公司，在我看来，也只是疫情使得它们业务量剧增，需要人干活而已。疫情过后，实习生能够转正留下多少呢？都说这届毕业生是最难的一届毕业生，殊不知很多应届生其实在九月十月已经拿到了offer。秋招才是应届生求职的最佳时间。春招历年都是补录的，公司本来就少岗位也少。已经签了三方的公司，大部分是不会毁约的，毕竟对名声不好。对于应届生而言，可能最难的是毕业论文。比如我们研究生的毕业论文，写完之后还需要教育部盲审。今年学校为了毕业生考虑，出台了一系列措施保证毕业生能够毕业拿到学位。反观我们这届明年毕业的，受疫情影响，也许很多研究都中断了，但是明年毕业论文肯定是不会像今年这样这么多帮助措施的。我们的就业也变得压力山大。尤其是作为武汉人，找实习的时候，有的面试官听说我是武汉的，甚至笑了。也许在他们看来，招武汉人已经是一种风险了。国家确实出台了事业单位今明两年扩招应届生的举措。所以，感谢政府的作为。不过，如果不是想去事业单位的呢？事业单位相比于互联网名企，稳定的同时也意味着收入少，高额的房价令人生畏。 武汉解封以后，家里人偶尔出门逛一逛，爬爬山，骑骑车。春色已经把寒冷的冬季掩埋，路边的蔷薇顺着栅栏，有的含苞待放，有的娇艳欲滴。蓝天之下，白云看起来是那么飘逸、舒服。如果有可能，每天工作之余，陪陪家人，逛街、散步不好吗？我总是和我妈说，如果我找了一份互联网工作，大概率是要996的。有时候想一想，真的觉得很累，哪里还有个人的生活时间。 爸妈以前和我念叨村里的一个人，去了BD北京，年薪20万，它们也希望我能有一份高薪工作。现在静下心来想一想，适合自己的才是最重要的。也许996的加班并不适合我。我希望的是一份按时上下班的工作。下班之后可以自己看书、学习或者是娱乐放松，也可以是陪陪家人或者未来的女朋友。偶尔还可以写一下随笔，记录一下内心的一些想法。 一直在思考读了这么多年书是为了什么，有时候觉得是为了高薪好工作，有时候觉得是为了探索知识无穷的奥秘，有时候甚至觉得是为了改变世界。中国现在表面上经济繁荣、高速发展。可是还是有很多问题存在，贫富差距大，各个地方发展不平衡，这些问题都需要解决。我一直觉得“美丽中国”是一个很好的项目，致力于解决中国的教育不平衡问题，两年的支教相比那些短暂的暑期支教，也更有成效。我真的觉得这些在努力改变这个世界的人，尤其是年轻人，是有着极大的勇气的，我很佩服他们。 乱七八糟又说了很多，希望疫情快点结束，所有人的生活能够回归正常。 ","link":"https://Angus1996.github.io/post/xiao-cheng-de-chun-tian/"},{"title":"多媒体信息安全技术简介","content":"多媒体信息安全概述，信息保护策略、加密技术、信息隐藏技术的简单介绍。 1. 概述 对一个多媒体系统的攻击。最好通过观察正在提供信息的系统的功能来表征。 四种一般类型的攻击： 1️⃣ 中断：该系统的资产被破坏或变得不可利用或不能使用，这是对可用性的攻击； 2️⃣ 截获：一个未授权方获取了对某个资产的访问，这是对机密性攻击。该未授权方可以是一个人、一个程序或者一台计算机； 3️⃣ 篡改：未授权方不仅获得了访问，而且篡改了某些资产，这是对完整性的攻击； 4️⃣ 伪造：未授权方将伪造的对象插入系统，这是对真实性的攻击。 攻击还可以划分未被动攻击和主动攻击： 被动攻击： 本质上是在传输过程中的偷听或者监视，其目的是从传输中获得信息。可以分为消息内容分析和通信量分析两类。被动攻击难以检测，因为它们不会导致数据有任何变化。对付这种攻击的重点是防止而不是检测。 主动攻击： 涉及对某些数据流的篡改或一个虚假流的产生，可以分为伪装、重放、篡改信息和拒绝服务。主动攻击表现了与被动攻击相反的特点。完全防止主动攻击是相当困难的，防止主动攻击的目的是检测主动攻击，并从主动攻击引起的任何破坏或时延中予以恢复。 安全的几个特点： 机密性：信息不泄露给非授权的个人和实体，或供其利用的特性； 完整性：信息在存储或传输过程中保持不被修改、不被破坏、不被插入、不延迟、不乱序和不丢失的性质； 可用性：信息可被合法用户访问并按要求顺当使用的特性，即指当需要时可以取用所需信息。 可控性：指授权机构可以随时控制信息的机密性； 不可抵赖性：防止发送方或接收方抵赖所传输的信息。 2.多媒体信息保护策略 数据置乱：借助数学或者其他领域的技术，对数据的位置或数据内容作变换使之生成面目全非的杂乱数据，非法者无法从杂乱的数据中获得原始数据信息。该方法可逆，典型方法如幻方排列、Arnold变换、生命模型等。 数字信息隐藏（信息伪装）：将秘密信息密密地隐藏于另一非机密的信息之中。其形式可为任何一种数字媒体，如图像、声音、视频或一般的文档等等。 数字信息分存：将信息分为N份，这N份信息之间没有任何互相包含关系。只有拥有M（M&lt;=N）份信息后才可恢复原始信息，而任意少于M份信息就无法恢复原有的信息。该方法的优点是丢失若干份信息并不影响原始信息的恢复。 数据加密：将原始数据信息（明文）经过加密密钥及加密算法函数抓换变成无意义的密文，而合法接收方将此密文经过解密函数、解密密钥还原成明文。 防病毒：计算机病毒是指蓄意编制或在计算机程序中插入一组计算机指令或程序代码，旨在干扰计算机操作，记录、毁坏或删除数据，或自行传播到其他计算机和整个Internet。利用音频、视频或数据流等传播计算机病毒，是计算机病毒变化的一种新趋势。因此，多媒体信息保护的另一种策略就是病毒防护。 3.多媒体加密技术 现代密码体制由一个明文(P)和密钥(K)映射到密文(C)的操作构成：K[P]→CK[P]\\rightarrow CK[P]→C。通常存在一个逆操作，将密文和密钥K−1K^{-1}K−1映射回明文，K−1[C]→PK^{-1}[C]\\rightarrow PK−1[C]→P。 对称加密技术： 对信息进行明文 ↔\\leftrightarrow↔ 密文变换时，加密和解密使用相同密钥的密码体制。 非对称加密技术： 每个用户都具有一对密钥，一个用于加密，一个用于解密。其中加密密钥可以在网络服务器、报刊等场合公开，而解密密钥则属用户的私有秘密，只有用户一人知道。 完整性保护： 对于可以公开的多媒体信息，既要求对数据加密，也要求数据真实可靠，不受第三方篡改。 散列函数：一种单向函数，它将任何长度的信息作为输入，进行一系列模乘、移位等运算，输出固定长度的散列结果（信息摘要)。 单向性：由输入产生输出计算比较容易实现，由输出产生原有输入是计算上不可行的。 防抵赖服务： 通过为消息附上电子数字签名，使签名者对消息的内容负责，而不可以在事后进行抵赖。 数字签名： 基于公钥密码体制。为了对消息m进行数字签名，用户A必须就有密钥对&lt;K1,K2&gt;&lt;K_1, K_2&gt;&lt;K1​,K2​&gt;，其中K1K_1K1​为公开的加密密钥，K2K_2K2​为私有的解密密钥。 用户A对m进行签名：Sig=Dk2(m)Sig = D_{k_2}(m)Sig=Dk2​​(m) 对签名的认证：EK1(Sig)=Ek1(Dk2(m))=mE_{K_1}(Sig)=E_{k_1}(D_{k_2}(m))=mEK1​​(Sig)=Ek1​​(Dk2​​(m))=m 除了用户A之外，任何人都不能从m中计算出SigSigSig来，由此提供抗抵赖服务。 4.多媒体信息隐藏 将信息藏匿于一个宿主信号中，使不被察觉到或不易注意到，却不影响宿主信号的知觉效果和利用价值。 于数据加密的区别：1️⃣ 隐藏对象不同；2️⃣ 保护的有效范围不同；3️⃣ 需要保护的时间长短不同；4️⃣ 对数据失真的容许程度不同。 信息隐藏分为：隐蔽通道技术、隐藏术、匿名通信、版权标识。其中版权标识可分为鲁棒性水印和脆弱性水印。鲁棒性水印又可分为（可见/不可见）水印和指纹。 5.多媒体数字水印 数字水印是信息隐藏的一个重要分支，主要应用于多媒体版权保护。它将具有特定意义的标记，如数字作品的版权所有者信息、发行者信息、购买者信息、使用权限信息、公司标志等嵌入到多媒体作品中，并且不影响多媒体的使用价值。 数字水印的三个基本要求：1️⃣ 不可见性，不易被感知；2️⃣ 鲁棒性，要能经受各种正常的信号处理操作；3️⃣ 非法使用者可能通过各种手段来破坏和擦除水印，所以水印系统必须能抵制各种恶意攻击。 一个数字水印系统由三部分组成：水印生成、水印嵌入和水印检测。 水印生成： 为了提高水印信息的安全性，在水印嵌入之前利用加密或置乱技术对水印信息进行预处理。密钥是水印生成的一个重要组成部分，水印信息的加密或置乱都离不开密钥。 水印嵌入： 通过对多媒体嵌入载体的分析、水印嵌入点的选择、嵌入方法的设计、嵌入强度的控制等几个相关技术环节进行合理优化，寻求满足不可见性、鲁棒性、安全性等约束下的准最优化设计。 水印检测： 对可疑作品检测，判断是否含有水印。水印检测存在两种结果：一种是直接提出原始嵌入的水印信息，另一种是只能给出水印是否存在的二值决策，不能提取出原始水印信息。可以分为盲检测、半盲检测和非盲检测。水印检测一般采用对提取的水印信息W’W’W’和原始水印信息WWW的相关性检测。 盲检测：检测时只需要密钥，不需要原始载体数据和原始水印。 半盲检测：不需要原始载体数据，只需要原始水印。 非盲检测：既需要原始载体数据又需要原始水印信息。 数字水印的分类：1️⃣ 按水印嵌入载体划分：图像水印、视频水印、音频水印、图形水印、文档水印等。2️⃣ 按照水印作用划分：鲁棒水印、脆弱水印。3️⃣ 按照嵌入方法划分：空（时）域水印，变换域水印。 6.图像水印 从图像处理的角度看，图像水印嵌入相当于在强背景(载体图像)下叠加一个弱噪声信号(水印)。嵌入的水印信息可以是无意义的伪随机序列或有意义的二值图像、灰度图像甚至彩色图像等。 空间域水印：算法复杂度低，但是抗攻击能力差。 变换域水印：图像变换域数字水印算法通过修改频域（DFT域、DCT域等）系数，把水印能量扩散到代表图像的主要能量中，在水印不可见性和鲁棒性之间达到了很好的平衡，而且与图像压缩标准JPEG相兼容。 一个好的图像水印系统应该能够抵抗各种针对图像水印的攻击。如：JPEG压缩攻击、图像增强处理攻击、噪声攻击、几何变形攻击、打印扫描攻击、嵌入多重水印攻击等。 7.常见的图像水印算法 空域： 最低有效位算法（LSB）和基于统计的PatchWork算法。 LSB算法基本思想就是用水印信息位代替图像像素的最低有效位（LSB）。对一幅灰度图像进行位平面分解，可以得到8个位平面二值图像。位平面越高，位平面二值图像越接近原始灰度图像；位平面越低，位平面二值图像越接近噪声图像。因此高位平面图像集中了原始图像的主要能量，水印信息替代高位平面，图像失真会比较大。而较低位平面图像集中了原始图像的细节信息，水印信息替代低位平面图像，不会引起原始图像失真。 优点是简单；缺点是对信号处理和恶意攻击的稳健性很差，简单的滤波、加噪等处理后，就难正确提取水印了。 变换域： DCT域图像水印算法和小波域图像水印算法。 图像经过DCT变换并且频谱平移后，位于左上角的直流系数代替了图像的主要能量。由于在DCT直流系数中嵌入水印容易破坏图像质量，而在高频中嵌入水印，容易在图像压缩或滤波中去除，因此大部分DCT域图像水印算法都选择低频和中频系数，并结合人眼视觉特性进行水印嵌入。 ","link":"https://Angus1996.github.io/post/duo-mei-ti-xin-xi-an-quan-ji-zhu-jian-jie/"},{"title":"《操作系统》学习笔记","content":"操作系统（第3版）罗宇等编著 的学习笔记。 第一章：绪论 1.1 什么是操作系统 操作系统是一种系统软件，是软、硬资源的控制中心，它以尽量合理有效的方法组织单个或多个用户以多任务方式共享计算机的各种资源。 命令解释器都是必不可少的一个程序，用户通过它来使用计算机系统 其他的操作系统内核层之上的程序则是根据计算机的定位（服务器或工作站）而选择安装的。如果将计算机定位成程序开发用的工作站，那么用户必须安装编辑器进行程序编辑，并安装编译器进行程序编译。如果把计算机作为一个网络上的Web服务器，那么必须安装Web服务器程序。 它提供一组称为系统调用的接口，供上层程序调用，从而保证操作系统内核在特殊保护状态下运行的需求，并且满足上层程序对系统资源的申请、使用、释放以及进程的创建、结束等诸多功能的需求。 系统提供这些库程序是为了方便用户编程，用户不必为了实现一个通用的功能再重写上述库程序代码，而只要引用库程序中的函数即可。 系统调用与普通函数调用相似，可以看成是特殊的公共子程序，因为这些程序提供了一些可以被任意用户层程序调用的公共功能，所以用户不需要再编写实现这些功能的程序，只要调用操作系统内核提供的相应“系统调用”即可。 文件操作以操作系统内核系统调用形式实现。 处理机提供程序执行能力；主存、辅存提供程序和数据的存储能力；终端设备提供人机交互能力；网络设备提供机间通信能力。 操作系统要合理调度多用户任务使用处理机。 针对不同资源特点，资源管理包含两种资源共享使用的方法：“时分”和“空分”。 时分就是由多个用户进程分时地使用该资源 空分是针对存储资源而言，存储资源的空间可以被多个用户进程共同以分割的方式占用。 **独占式使用。**独占表示某用户任务占用该资源后，执行对资源的多个操作，使用一个完整的周期。 **分时式共享使用。**这种共享使用是指用户任务占用该资源无需使用一个逻辑上的完整周期。 进程是指运行当中的程序，也就是指程序针对于某一数据集合的执行过程。 操作系统为用户提供进程创建和结束等的系统调用功能，使用户能够创建新进程以运行新的程序。 1.2 操作系统的发展历史 所谓作业（Job），是用户在一次上机活动中要求计算机系统所做的一系列工作的集合。 人们将机器指令分为**“普通指令”和“特权指令”**，并且引入了“模式/态（Mode）”的概念。把有关I/O的指令、对特殊寄存器的访问等列为特权指令，并且规定只有监督程序才有权执行特权指令，用户程序则只能执行普通指令。 监督程序所在的存储空间称为**“系统空间”，用户程序所在的存储空间称为“用户空间”**。 用户程序执行时若碰到定时器中断，则无条件进入监督程序。监督程序根据当前作业说明（或规定）的“最大运行时间”值来判断该程序是否进入了“死循环”，从而可以有效地防止某个用户程序长期垄断系统处理机的现象。 通道是指专门用来控制I/O的硬件装置，可以实现外设与主存直接交换数据，在相当长的时间里不用打扰CPU 多道程序设计技术的基本思想是，在主存同时保持多道程序（作业），主机（对于单CPU系统，书中如没有特殊说明则都是单CPU系统）以交替方式同时处理多道程序。多道程序设计系统的出现标志着操作系统的形成。 操作系统的最基本特征如下： ① 并发（Concurrent）机制，用以支持多道程序设计技术。 ② 共享（Sharing）机制，控制各种并发活动正确共享系统软、硬资源。 将交互式系统与多道程序设计系统相结合便形成了分时系统。 分时系统中，一台计算机与多台终端相连接，用户通过各自的终端和终端命令以交互方式使用计算机系统。 系统规定一个被称为**“时间片”**的时间单位，所有终端用户轮流享用一个时间片的CPU时间 分时系统的基本特点如下： ① 并发性。系统能协调多个终端用户同时使用计算机系统（即系统内部具有并发机制），能控制多道程序同时运行。 ② 共享性。对资源而言，系统在宏观上使各终端用户共享计算机系统的各种资源，而在微观上它们则分时使用这些资源。 ③ 交互性。对系统和用户双方而言，人与计算机系统以对话方式进行工作。 ④ 独立性。对用户而言，系统能使用户有一种只有他自己在使用计算机的感觉。 计算机系统能对用户的服务请求及时做出回答，并能及时修改、处理系统中的数据。这类应用被称为**“实时事务处理”**。实时系统应能及时地响应外部事件的请求并在严格规定的时间内完成对该事件的处理，控制实时设备和实时任务协调一致地运行。 实时系统的主要特征和功能如下： ① 时钟分辨度高。有更高的时钟中断频度，可实现更精确计时，可以更加频繁地进入操作系统“处理机调度程序”运行，保证实时任务及时占用处理机，以此保证实时任务的快速响应。 ② 支持可剥夺任务调度。保证实时任务无条件剥夺非实时任务运行，不会让非实时任务耽误实时任务。 ③ 多级中断机制。保证实时任务对应的事件中断为高级 多机操作系统以支持并行多任务为其主要特征，充分发挥计算机中多处理机并行处理的优势，在科学计算及高端事务处理服务器领域占有重要地位。 1.3 主要操作系统介绍 自由软件可免费提供给任何用户使用，也包括用于商业目的；并且自由软件的所有源程序代码也是公开的，可免费得到。 引入SPOOLing技术的硬件基础是什么？ 通道 第二章：操作系统运行机制与用户界面 操作系统的主要功能就是管理CPU、主存、I/O设备及文件，并提供支持程序并发运行的机制。 2.1 中断和异常 CPU在运行上层程序时唯一能进入内核程序运行的途径就是通过中断或异常。 异常表示CPU执行指令时本身出现算术溢出、零做除数、取数时发生奇偶错、访存指令越界，或执行了一条所谓“陷入指令trap”等情况，这时也可以中断当前的执行流程，转到相应的错误处理程序或陷入处理程序。陷入指令（也称自陷指令或访管指令）的出现，是为了使得用户模式下运行的程序可以调用操作系统内核程序。异常只是一种特殊的程序调用，特殊在于处理机状态从“用户模式”变成了“监督模式”。 **中断（Interruption），也称外中断。**指来自CPU执行指令以外的事件发生。每个不同中断具有不同的中断优先级，表示事件的紧急程度。在处理高级中断时，低级中断可以被临时屏蔽。 异常（Exception），也称内中断、例外或陷入（Trap）。指源自CPU执行指令内部的事件。异常不能被屏蔽，一旦出现应立即处理。 为了区分和不丢失每个中断信号，通常用一些固定的触发器来寄存它们，并规定其值为1时表示有中断信号，其值为0时表示无中断信号。这些寄存中断的触发器称为**“中断寄存器”**。 把中断享有的高、低不同的响应权利称为中断优先级。 **“中断屏蔽”**通常是指禁止响应中断 CPU执行指令产生异常，如执行非法指令、自陷指令（Trap指令）时不能被屏蔽，必须马上响应处理。 2.2 中断/异常响应和处理 该机构能够在每条机器指令执行周期内的最后时刻扫描中断寄存器，“询问”是否有中断信号。若无中断信号或被屏蔽，CPU继续执行程序的后续指令，否则CPU停止执行当前程序的后续指令，无条件地转入操作系统内核的中断处理程序，这一过程称为中断响应。 异常是在执行指令的时候，由指令本身的原因发生的，指令的实现逻辑发现异常发生则转入操作系统内核的异常处理程序。 一般情况下，断点应为中断的那一瞬间程序计数器（PC寄存器）所指指令的前一条指令地址，即中断发生时正在执行的那一条指令的地址。中断时程序计数器所指的地址（即断点的逻辑后续指令）称为“恢复点”。 现场信息，是指中断那一时刻确保程序继续运行的有关信息，如程序计数器、通用寄存器及一些与程序运行相关的特殊寄存器中的内容。 中断和异常的处理程序是操作系统内核程序，都必须在一种特权状态下运行，因为这些程序需要访问外设等操作系统管理的资源或者涉及系统的管理表格。 因此，将CPU的运行状态分为核心态和用户态（等同于以前所述的监督模式和用户模式），操作系统内核程序在核心态下运行，允许在核心态下运行的程序执行所有的指令（包括特权指令）；而外层所有程序在用户态下运行，特权指令一般不允许在用户态下执行。 当用户程序需要操作系统为之服务时，绝对不能通过通常的程序调用方式来调用操作系统的相应程序，而必须设法通过执行自陷指令（系统调用）引起一次异常而转入操作系统内核的相应程序。 也有人把核心态称为管态、系统状态、监督方式，将用户态称为目态、用户状态或用户方式等。 Intel x86处理机运行状态有0，1，2，3环之分，不过Intel x86上运行的操作系统（如Linux和Windows）只用到0环和3环，0环表示核心态，3环表示用户态。 通常将这片存放中断/异常处理程序入口地址的主存单元称为中断/异常向量，或系统控制块。 PS(process state)寄存器描述CPU的执行状态，主要包含处理机当前运行态、处理机优先级、屏蔽外中断否等标志位。 当响应中断/异常时，硬件先把当前PS和PC(process counter)寄存器的内容作为程序现场保存起来，然后从中断/异常向量的相应单元取出新的PS和PC值，并装入到PS和PC寄存器。CPU便根据新装入的PC的内容转去进行中断/异常处理。 中断/异常处理中，一般包括保存现场、分析中断/异常原因、进入相应的中断/异常处理程序、重新选择程序（进程）运行、恢复现场等过程 中断/异常发生后，硬件机构自动地进入响应中断/异常的过程——交换PS和PC，具体步骤如下： ① 硬件机构自动将PS和PC寄存器的内容存入CPU的暂存寄存器中。 ② 根据发生的中断/异常，硬件从指定的中断/异常向量单元中取出新的PS和PC内容，分别装入PS和PC寄存器。 ③ 硬件将保留在内部寄存器中的原PS值和PC值的作为现场信息保存到与被中断程序相关的栈中，这里的栈用于保护原来运行程序的现场。 对于不同的中断，硬件将转入不同的中断入口程序。对于所有的异常则首先转入公共的入口程序。 高级中断能够打断低级中断的处理，待高级中断处理结束后，再返回低级中断处理。为了不丢失低级中断的现场信息，显然应该用栈结构保存现场。 用户态程序，则退出中断/异常以前应先考虑进行一次调度选择（运行进程调度程序），以挑选更适合在当前情况下运行的新程序（进程）。这是因为，原来被中断的用户程序在此次中断/异常处理过程中，可能由于其要等待的事件没有发生而不具备继续运行的条件；也可能被降低了运行的优先权；还可能由于此次中断/异常的处理使得其他程序获得了比其更高的运行优先权 2.3 操作系统运行模型 操作系统通常都包含进程管理、存储管理、外设管理、文件管理等主要功能模块，还需要提供支持用户使用计算机的命令解释程序。 进程管理模块包含有关进程的系统调用处理，如进程创建和结束、进程通信及进程同步等，也包含对处理机的分时使用程序，如进程调度和进程切换。 进程空间分配程序也划分到存储管理模块中 内核程序作为一个特殊进程运行，它的并发运行实现起来很困难。当一个I/O请求发给外设后，外设进行I/O需要一定的时间，内核因此而阻塞，处理机去运行别的进程，而别的进程就不可再激活内核程序了。 2.4 系统调用 系统调用是操作系统内核和用户态运行程序之间的接口。所谓系统调用，可以看成是用户程序（或用户态运行的系统程序）在程序一级请求操作系统为之服务的一种手段 大部分的机器都提供一条能产生异常的机器指令，称为**“自陷指令”，或陷入指令，或访管指令**。 为了方便高级语言程序使用系统调用，通常提供一个系统调用库，其中包含许多系统调用接口函数，这些函数看上去就是一些普通的子程序，但是这些函数往往是由为数不多的几条汇编指令实现的，而且必须要包含一条trap指令，这样才能保证在执行trap指令时将处理机控制转移至操作系统内核的相应程序。 用户只要按子程序调用格式写语句，编译器在编译子程序时，会将用户子程序调用语句中的参数放入约定好的寄存器中，生成指令并从约定好的寄存器或栈中取参数。 第三章：进程与处理机管理 用户希望一个作业步中的程序还能够同时在多个处理机上运行，因此进程的机制得到了进一步发展，即让一个进程同时拥有多个线程，让多个线程在不同处理机上同时运行。 如何把处理机合理有效地分配给各执行程序使用是处理机管理的主要内容。 引入线程的目的是为了支持进程中程序执行的并发。 3.1 进程描述 程序以进程方式使用系统资源，包括程序和数据所用的空间、系统外设、文件等程序运行所需的系统资源，并且以分时共享的方式使用处理机资源。 把操作系统看成支持进程并且对进程所用系统资源进行管理的系统。 进程是支持程序执行的机制。进程可以理解为程序对数据或请求的处理过程。 进程由以下4方面组成： ① 进程包括至少一个可执行程序，含有代码和初始数据，一般在进程创建时说明。注意，可执行程序可以被多个进程共享，换句话说，多个进程可能运行同一个可执行程序。 ② 进程包括一个独立的进程用户空间，在进程创建时由操作系统分配。 ③ 进程包括系统资源。这是指在进程创建及执行过程中，由操作系统分配给进程的系统资源，包括I/O设备、文件等。 ④ 进程包括一个执行栈区，包含运行现场信息，如子程序调用时所压栈帧，系统调用时所压的栈帧等，这是进程运行及进程调度进行处理机切换时所要涉及的数据结构。 在进程运行过程中，操作系统不断地将系统资源以独占方式或者与其他进程共享的方式分配给进程。 系统还会为进程在操作系统核心空间分配一个核心栈，用来保存中断/异常点现场，以及在进程运行核态程序后的转子现场。逻辑上，进程的用户栈和核心栈都属于一个执行栈区。 同一个程序可以由多个进程分别执行，当然，不同的进程虽然执行的是相同的程序，但是处理不同的数据，这种程序被称为共享程序。 任何一个程序，逻辑上都可以将其分为两部分：执行过程中不改变自身的不变部分和工作区、变量等可变部分。 我们把程序、数据、栈的集合称作进程映像（Process Image） 初始化进程空间是指将辅助存储器中的可执行程序文件中的程序加载到进程空间，并依照可执行程序文件中局部变量、全局变量的数据说明，分配进程的数据区空间并对其初始化，还要分配好栈区。 进程控制块（Process Control Block，PCB）。它描述进程标识、空间、运行状态、资源使用等信息。在进程控制块中存放的标识信息主要有本进程的标识、本进程的产生者标识（父进程标识）、进程所属的用户标识。逻辑上说，进程运行栈属于进程控制块。进程控制块一定要有栈的地址。 包含中断是否开放、处理机执行态等状态信息的寄存器，通常称为处理机状态字（PSW） 进程标识符是一个数字式的系统内码，通过它可以建立其他表格与进程控制块之间的联系。 同一用户的所有进程配合完成用户的上机意图。 进程控制块中的链接指针可以把有相同特性的进程控制块链接起来， 进程控制块是操作系统中最重要的数据结构，每个进程控制块都包含操作系统所需的进程信息。 进程控制块的集合定义了操作系统的状态。 对所有公共数据结构都存在这样一个问题，用户往往把对该公共数据结构的规范操作集中在一个例程中，这称为管程设计方法。 3.2 进程状态 要做到程序的并发执行，操作系统必须能使不同进程中的程序占用处理机运行，所以一个进程在从创建到结束的生命期内会占用处理机，也会从处理机上下来让别的进程去运行。 通过改变程序计数器PC的值来改变指令的执行次序。程序计数器可以从一个应用程序的代码段改变到另一个应用程序的代码段，这也是处理机进程切换所要做的事情。 一般的进程都要经历创建、断断续续运行、最后结束的过程。 在需要时，一个进程可以创建一个新的进程，被创建的进程称为子进程，创建者进程称为父进程。 进程结束处理主要是释放进程所占用的系统资源，进行有关信息的统计工作，理顺本进程结束后其他相关进程的关系，最后调用进程调度程序选取高优先级就绪进程来运行。 运行状态（Running）：一个进程正在处理机上运行。在单机环境下，每一时刻最多只有一个进程处于运行状态。 就绪状态（Ready）：一个进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行，称此进程处于就绪状态。 等待状态，又称阻塞状态（Blocked）：一个进程正在等待某一事件而暂停运行，如等待某一资源成为可用或等待I/O完成。 **系统按进程优先级数设立几个就绪进程队列，同一优先级进程在同一队列中。**系统先取最高优先级的队列队首进程占用处理机，当时间片到时往往重新计算优先级挂回相应就绪队列中。当要等事件时，将其挂到相应的事件等待队列中。如果某个事件发生，系统从相应等待队列中选取队首进程并重新计算优先级挂到就绪队列中。 为了能使处于等待状态的进程释放主存空间，系统将其交换到辅存上，这时进程便处在挂起状态。处于挂起状态的进程意味着没有占用任何主存。当等待并挂起的进程等待的事件发生时**，进程状态从等待挂起转化到就绪挂起。** 当操作系统选取进程进行交换时，一个高优先级的就绪挂起状态的进程可以被解挂，即将该进程映像从外部存储器调入主存，这时该进程从就绪挂起变成就绪状态。 3.3 进程控制与调度 特权态又称核心态、系统态或监督模式，操作系统内核程序在这种模式下运行。 如果操作系统提供某种手段能将指定物理空间映射到用户（虚存）空间，那么不但能实现用户态的I/O驱动程序，而且还能用高级语言实现I/O操作，这是因为I/O操作与一般读/写指令格式一致，所不同的只是地址范围不一样。 划分特权与非特权态的理由是，保护操作系统和操作系统的数据表格不被可能出错的用户程序破坏。 进程既为运行用户程序而创建，又会在用户自陷或外部中断时去运行操作系统内核程序。当进程运行系统内核程序时，系统只是保存了用户程序的运行现场，包括所有处理机状态、现场信息，保留原用户程序使用的栈不被核心态程序使用。当核心程序运行时，系统使用为该进程分配的核心栈空间，这样当核心程序调用子程序或被中断时，可以利用核心栈保存现场。 进程切换是指处理机从一个进程的运行转到另一个进程上运行。进程切换与处理机模式切换不同，当模式切换时，处理机逻辑上还在同一进程中运行。而进程切换指处理机转入另一个进程运行。 提高处理机的利用率及改善系统响应时间、吞吐率（单位时间完成的作业量），在很大程度上取决于进程调度性能的好坏。 调度就是选择。 必须按照一定的原则选择进程（或请求）来占用资源，这就是调度。选择进程占用处理机称为进程调度；选择磁盘请求进行磁盘I/O称为磁盘调度 作业一旦被高级调度选中，相应的进程及进程组才会产生，其他系统资源才有可能被占用。 中级调度可以控制进程对主存的使用。 低级调度决定处在就绪状态中的哪个进程将获得处理机。通常所说的进程调度就是指低级调度。 非剥夺方式。在这种方式下，一旦分派程序把处理机分配给某进程后，便让它一直运行下去，直到进程完成或发生某事件（如提出I/O请求）而阻塞时，才把处理机分配给另一进程。 剥夺方式。在这种方式下，某个进程正在运行时可以被系统以某种原则剥夺已分配给它的处理机，将处理机分配给其他进程。 进程调度和切换程序是操作系统内核程序。 进程在操作系统内核程序临界区中不应该被切换。在运行用户程序的进程自陷进入操作系统后，如果进入临界区，需要独占式访问共享数据，理论上必须加锁，以防其他并行程序进入。在加锁后到解锁前不应切换到其他进程运行，以加快该共享数据的释放。 其他需要完全屏敝中断的原子操作过程，像加锁、解锁、中断现场保护、恢复等原子操作。在原子操作过程中，连中断都要屏蔽，更不应该进行进程调度与切换。 进程调度就是选择进程占用处理机。 先来先服务调度算法属于不可剥夺算法。 按照进程的优先级大小来调度，使高优先级进程优先得到处理机的调度称为优先级调度算法。 一个进程的优先级不是固定的，往往随许多因素的变化而变化，尤其随进程的等待时间、已使用的处理机时间或其他资源的使用情况而定。 时间片轮转算法也多用于进程调度，采用此算法的系统其进程就绪队列往往按进程到达的时间来排序。 按照先来先服务原则调度，但进程占有处理机仅一个时间片，在使用完一个时间片后，进程还没有完成其运行，它也必须释放（被剥夺）处理机给下一个就绪的进程。 短进程优先调度算法从进程的就绪队列中挑选那些所需运行时间（估计时间）最短的进程进入主存运行。 当后续短进程过多时，大进程可能没有机会运行，导致饿死。 让“进程运行到完成时所需的运行时间最短”的进程优先得到处理 最短剩余时间优先算法允许被一个新进入系统的且其运行时间少于当前运行进程的剩余运行时间的进程所抢占。 按照此算法每个进程都有一个优先数，该优先数不但是要求的服务时间的函数，而且是该进程得到服务所花费的等待时间的函数。 可以看出，“等待时间＋要求的服务时间”是系统对作业的响应时间，所以优先数公式中，优先数值实际上也是响应时间与服务时间的比值，称为响应比。响应比高者得到优先调度。 优先级最高的第1级队列中的进程的时间片最小，随着队列级别的增加，其进程的优先级降低了，但时间片却增加了。通常下放一级，其时间片增加1倍。各级队列均按先来先服务原则排序。 当前面各级队列皆为空时，才调度最后第n级队列中的进程。第n级（最低级）队列中的进程采用时间片轮转算法进行调度。当比运行进程更高级别的队列到来一个新的进程时，它将抢占运行进程的处理机，而被抢占的进程回到原队列的末尾。 3.4 作业与进程的关系 进程是系统资源的使用者，系统的资源大部分都是以进程为单位分配的。 通常把用户要计算机完成的这一串任务称为作业。 作业是用户向计算机提交的相关任务的集合，而进程则是具体完成用户任务的运行实体，分配计算机资源的基本单位。 一个作业就动态地转换成了一组运行实体——进程族。 对于每一条终端命令，可以创建一个子进程去具体执行。 3.5 线程的引入 引入进程后，系统资源，特别是CPU的分配单位变成了进程，原来由一个作业完成的用户任务通过系统中多个进程来实现，一个进程代表了一个作业步，因为进程可以并发地占用CPU运行，因此实现了同一个作业中不同作业步的并发。 引入进程是为了实现作业步的并发执行 如果要进行进程间数据交换，则需要操作系统中系统调用的支持，操作系统必须提供相应的进程间通信的系统调用来完成进程间数据交换的任务，这样会给编程带来困难。 让完成同一作业的进程共享一片存储空间，但是进程独立作为CPU的调度单位占用处理机。 在一个进程中可以包含多个可以并发（并行）执行的线程。 系统按进程分配所有除CPU以外的系统资源（如主存、外设、文件等），而程序则依赖于线程运行，系统按线程分配CPU资源，引入线程后，进程概念内涵改变了，进程只作为除CPU以外系统资源的分配单位。 这些线程共享程序区和数据区，但是它们有各自的运行栈区，可以被独立地调度占用CPU并行或并发地运行。 当进程内所有的线程结束时，意味着进程结束，从而释放进程所占用的所有资源。 在进程内，每个线程可以运行进程程序区的不同子程序或相同的可再入子程序，它们处理着不同的用户原始数据，或处理着不同的外来请求。 3.6 小结 程序、数据、用户栈的集合称为进程映像（Process Image）。 为了实现进程间空间共享而引入轻权进程；为了实现进程内的程序并发（并行）运行而引入线程。 进程成为资源（除CPU以外）分配单位，线程则是处理机分配单位。 第四章：进程同步与通信、进程死锁 并发（分时占用处理机）或并行（同时占用不同处理机）运行的 访问共享资源或数据时会引发一种互斥关系，以满足各进程不同时使用共享资源或数据的要求。 一个进程需要向另一个进程传递数据，也就是说，后面的进程必须等待前面进程的数据到达才能继续运行，这是一种进程间的次序关系，我们又叫它同步。 对资源不加限制地分配可能导致进程间由于竞争资源而相互等待，以至无法继续运行，人们把这种局面称为死锁（Deadlock） 4.1 并发执行的实现 没有次序关系的子任务之间可以并发执行。 一般情况下，并发程序设计语言可以从顺序程序设计语言增加并发语句成分改造而来，但一些新的语言，在设计的时候就已经考虑了对并发程序设计的支持。 如果用户用并行程序设计语言编写并行程序，编译系统在对该程序进行编译时，会将程序中的并发语句转化为对操作系统相关系统调用函数的调用，动态地创建一组进程或线程来执行该程序。 4.2 进程的同步与互斥 同步关系（或称直接制约关系）。指为完成用户任务的伙伴进程间，因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。 互斥关系（或称间接制约关系）。即进程间因相互竞争使用独占型资源（互斥资源）所产生的制约关系，如进程间因争夺打印机设备而导致一方须待另一方使用结束后方可使用。 临界段（Critical Section）问题的实质是进程互斥使用资源问题。 因为同一个程序在相同数据上的多次执行可能产生不一样的结果，所以这两个进程的并发执行是不能保证确定性的。 让任一个进程在它需要进入的时候进入相应的临界段，而其间排斥另一个进程也进入相应的临界段，这样就可以避免临界段问题。 临界资源（Critical Resource，CR）：一次仅允许一个进程使用（必须互斥使用）的资源。如独占型硬件资源，可以由多进程访问的变量、表格、队列、栈、文件等软件资源。 临界段（Critical Section，CS）：是指各进程必须互斥执行的那种程序段，该程序段实施对临界资源的操作。 在一个多道程序的单处理机系统中，中断会引起多进程并发执行，因为中断处理结束会引起调度程序运行。如果某进程在临界段中发生中断，随着上下文切换，会保存被中断进程寄存器状态，然后调度另外的进程运行，另一个进程如果再进入相关临界段，会修改它们的共享数据，如果再次进行进程切换，原先进程重新执行时，使用了原来保存的寄存器中的不一致的数据，导致错误。如果程序员意识到中断引起的并发能够导致错误的结果，可考虑在程序执行临界段部分的处理时，屏蔽中断。 1965年，Dijkstra提出了一种称为信号量（Semaphore）的同步互斥工具，通常称为信号量机制。信号量机制是一种功能较强的机制，可用来解决互斥与同步问题。 信号量机制由“信号量”和“P操作、V操作”两部分组成。 原语（Primitive）是指完成某种功能且不被分割、不被中断执行的操作序列。有时也称原子操作 信号量机制能解决n个进程的临界段问题。n个进程共享一个公共信号量mutex，其初值为1。 “忙等待”（busy-waiting）现象。即如果某一个进程正在执行其临界段，其他欲进入临界段的进程均须在它们的entry code中连续地循环等待（如执行while(condition);语句等）。 某个进程执行P操作过程中，若发现信号量的状态不允许其立即进入临界段，则P操作应使该进程放弃CPU而进入约定的等待队列（调用系统函数block()）。当某个进程执行V操作时，如果在该信号量上有被阻塞的等待进程，则V操作负责将其唤醒（调用系统函数wakeup()）。 管程的互斥功能由编译器利用底层同步/互斥机制来实现。 把分散的临界段集中起来管理，并把共享资源用数据结构抽象地表示出来，由于临界段是访问共享资源的代码段，所以由一个“秘书”程序管理到来的访问。“秘书”每次只让一个进程来访，这样既便于对共享资源的管理，又能实现互斥访问。在后来的实现中，“秘书”程序更名为管程。 任一时刻管程中只能有一个活跃进程 对所有生产者和消费者进程来说，把缓冲池看成一个整体，因此缓冲池是临界资源，即任何一个进程在对池中某个缓冲区进行“存”或“取”操作时须和其他进程互斥执行。 在对这些计数变量操作时也要保证互斥操作 只需保证任何一个Writer进程能与其他进程互斥访问共享数据即可 “Reader优先” “Writer优先” 4.3 消息传递原理 进程之间交换信息被称为进程间通信。 要想让两个用户进程共享空间必须通过特殊的系统调用来实现，而进程内的线程是自然共享进程空间的。 消息传递（Message Passing）方法。消息传递的主要思想是：系统提供发送消息Send()与接收消息Receive()两个原语，进程间通过使用这两个原语进行数据交换。 一种方法是设立一个通信参与者共享的逻辑实体，如信箱，发送者只是向信箱发送消息，接收者从信箱取消息。这种方法又称为间接通信方法。 另一种方法是直接以接收者进程内部标识为目的地标识发送消息，这种方法又称为直接通信方法。 消息传递常常作为进程同步的手段。 管道实质上是一种空间有限信息流的缓冲机制，它连接发送进程与接收进程，以实现它们之间的数据通信。 管道不同于一般的消息缓冲机制，它以FIFO方式组织字节流数据的传输，并保证进程间同步执行，即当管道中无数据时，接收进程等待；当管道缓冲区满时，发送进程等待。 进程对通信机制的使用应该是互斥的。进程正在使用管道写入或读取数据时，另外的进程必须等待，等待锁被释放。 叫做write阻塞。反之，当读进程读空管道时，要出现read阻塞，读进程应睡眠，直到写进程唤醒它。 4.4 死锁 对资源不加限制地分配可能导致进程间由于竞争资源而相互制约以致无法继续运行，这就是死锁（Deadlock）。 进程是因相互竞争资源而导致死锁的 死锁定义：在一个进程集合中，若每个进程都在等待某些释放资源事件的发生，而这些事件又必须由这个进程集合中的某些进程来产生，就称该进程集合处于死锁状态。 条件1：互斥。在出现死锁的系统中，必须存在需要互斥使用的资源。 条件2：占有等待。在出现死锁的系统中，一定有已分配到了某些资源且在等待另外资源的进程。 条件3：非剥夺。在出现死锁的系统中，一定有不可剥夺使用的资源。 条件4：循环等待。 循环等待只是死锁的必要条件。 死锁的必要条件4（循环等待）与资源分配图中含有的圈是等价的。系统中出现死锁，则资源分配图中必有圈，但资源分配图中有圈并不一定有死锁。 资源分配图含圈而系统又不一定有死锁的原因是，同类资源数大于1，若系统中每类资源都只有1个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。 解决死锁问题一般采用两类方法：一类是设计无死锁的系统；另一类是允许系统出现死锁，并在发现死锁后排除。 锁主要研究死锁防止、死锁避免、死锁检测及死锁恢复。 只要有一个必要条件不成立，系统就能保证不出现死锁，这是死锁防止的理论基础。 方法一 使进程申请到了它所需要的所有资源后才能开始运行。在运行过程中进程只需要释放资源，不需要申请资源。这种方法又称资源预分配法。 方法二 在进程提出申请资源前，必须释放已占有的一切资源。 在进程主动释放占有的资源前允许资源管理者剥夺进程所占有的资源，也能保证系统不出现死锁。 采用资源顺序分配法可以破坏循环等待条件。 进程只能按序号由小到大顺序申请资源。 保证系统杜绝死锁的方法（被称为银行家算法） 死锁避免正是通过确保系统随时处于安全状态来防止死锁的。 设系统中有n个进程，若存在一个序列（P1，P2，…，Pn），使得Pi（i＝1，2，…，n）以后还需要的资源可以通过系统现有空闲资源加上所有Pj(j＜i)已占有的资源来满足，则称此时这个系统处于安全状态。序列（P1，P2，…，Pn）被称为安全序列。 银行家算法是以系统中只有一类资源为背景的死锁避免算法。1969年，Haberman将银行家算法推广到多类资源环境中，形成了现在的死锁避免算法。其数据结构如下所述： 可以采用化简资源分配图的方法来检测系统中有无进程处于死锁状态。资源分配图的简化过程如下： 系统中有死锁的充分必要条件是，资源分配图不可完全化简。经过化简后，非孤立点的进程处于死锁状态 将①，②，③，④类资源编号为1, 2, 3, 4，可按编号递增次序申请资源。对第1, 4两类资源采用预分配法；对第2类采用剥夺法；对第3类采用死锁避免法。而对那些哪种方法也不适合的资源，可用死锁检测程序定期对系统进行检测，发现死锁后再排除死锁。 4.5 小结 进程同步关系是指协调完成同一任务的进程之间需要在某些位置上相互等待的直接制约关系；进程互斥关系指进程间共享独占型资源而必须互斥执行的间接制约关系，互斥问题也称临界段问题。 信号量机制作为同步互斥工具是理想的，但它难以作为进程通信工具。消息传递是目前广泛采用的理想通信工具，它不仅能方便地用于传输消息，而且也能用于解决各种同步互斥问题。 出现死锁时，系统必然满足4个条件：互斥、占有等待、非剥夺和循环等待。 第五章 存储管理 当前计算机都是基于冯·偌依曼存储程序式的计算机，程序和数据在运行和使用时都需要存放在主存中。 “取”是研究该将哪个进程（或进程的某些部分）从辅存调入主存。调入进程占用主存或有资格占用主存是中级调度的工作。 “放”则是研究将“取”来的某进程（或进程的某部分）按何种方式放在主存的什么地方。 “替换”是研究将哪个进程（或进程的某部分）暂时从主存移到辅存，以腾出主存空间供其他进程（或进程的某部分）占用。 5.1 连续空间分配 应将用户程序的执行严格控制在用户区域中。这种存储保护的控制措施主要是通过硬件提供的界地址寄存器和越界检查机制来实现的。 经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要用的段放在覆盖区，其他段放在辅存，在需要调用前用户安排特定系统调用将其调入覆盖区，替换覆盖区中原有的段。 交换的基本思想是，把处于等待状态（或在CPU调度原则下被剥夺运行权利）的作业从主存移到辅存，这一过程叫做换出；把准备好竞争CPU运行的作业从辅存移到主存，这一过程称为换入。 一种是上、下界寄存器和地址检查机制；另一种是基址寄存器、长度寄存器和动态地址转换机制。 动态地址转换机制指当用户程序运行时，每访问一次主存，该机制将CPU提供的访存地址（相对地址）与长度寄存器中的值进行比较。若越界，则终止该程序；否则，与基地址寄存器中的值相加成为访问主存的绝对物理地址 在多道固定分区法下，存储调度（即中级调度）一般分为多队列法和单队列法。 这些未得到利用的空间称为存储碎片。 存储碎片分为内部碎片和外部碎片。 若存储块长度为n，该块存储的作业长度为m，则剩下的（长度为n-m）空间称为该块的内部碎片；若存储块长度为n，在该系统所采用的调度算法下，较长时间无法选出一道长度不超过该块的作业，即该块长时间得不到使用，则称该块为外部碎片。 分配策略：满足作业要求的可用块可能有很多块，那么应该选哪一块分给该作业呢？有下述三种选择方法： ① 首次满足法（First Fit）。搜索F时，选择所碰到的第一个满足作业存储量要求的块分配给用户。 ② 最佳满足法（Best Fit）。在F中选出所有满足作业要求的存储块中最小的一块分给用户。 ③ 最大满足法（Largest Fit）。在F中选出满足作业要求的最大块分给用户。 紧致空间管理。采用可变分区，没有内部碎片（一般不把小于基本存储分配单位的未利用的空间看成碎片） 紧致（Compact）空间的方法予以消除。紧致的基本思想是，通过移动主存中的作业位置，使可用空间连成一片。实现紧致必须要求作业代码是动态重定位的。 5.2 不连续空间分配 在页式系统中，将作业和主存都分成较小的块，可将作业的各块非连续地分配到可用块中。 用户程序目标代码所设想的空间和所用地址称为逻辑空间和逻辑地址。 占主存空间称为物理空间，对应的地址称为物理地址。 逻辑空间所划分出的每个区域称为页（Page）；物理空间所划分出的每个区域称为页帧（Page Frame）。 逻辑空间若有n页，页表就应该有n项。 线性逻辑地址可以分解成页号、页内位移，分别记为P，d。线性物理地址可以分解成页帧号、页帧内位移，记为f，d（例如，页面大小为512字节，地址539属于第1页，页内位移为27）。 由于计算机采用二进制编码，所以如果取页面大小为2的正整数次幂，乘、除法就变成了位移运算。例如，取页面大小为29（512）字节，则逻辑地址的低9位便为页内位移，高位为页号。这样，地址转换时所需要的乘、除法则可免去。在页式系统中有此原则：页面大小=2k（k是正整数）。 把页表中经常使用的页表项置于快速存储器（如快表，又有联想存储器之称），此矛盾就能得到较好的解决，页式管理法亦才得以付诸实用。 首先把页号送到快表中去匹配。若匹配成功，则形成物理地址，否则到主存页表中查找页表项来形成物理地址。如果快表不满，则将新页表项加入快表，否则从快表中淘汰一项后再加入新项 在段式系统中，空间不按等长而是根据程序的自然段来划分。 逻辑地址则由两部分组成：段号与段内位移，分别记做S，d。 首先需要一张逻辑空间与主存空间对照的段表，若作业被划分成n段，段表就应该有n项。段表项中的内容（如图5.23所示）包括本段在主存的起始地址、本段的长度及保护码等。 同样，要设置快表，将部分段表项放在快表中以提高转换速度。地址转换的过程是，将段号与快表中的各个关键字进行比较，若匹配成功，则检查段内位移d是否在该说明的长度内，同时检查保护码与本次操作的一致性，若这些比较结果都正常，则输出该段的起始物理地址，并与d相加得到物理地址。若在快表中匹配不成功，则将S与段表长度寄存器的内容进行比较。若没有越界，则将S与段表始地址相加，得到段表项的物理地址，查段表项，检查d是否越界，操作码是否与保护码一致。最后用该段起始地址与d相加得到物理地址，同时更换快表的内容。这一过程如图5.24所示。 地址转换的过程是，将段号与快表中的各个关键字进行比较，若匹配成功，则检查段内位移d是否在该说明的长度内，同时检查保护码与本次操作的一致性，若这些比较结果都正常，则输出该段的起始物理地址，并与d相加得到物理地址 段页式系统对物理空间的管理、安排与页式系统相同，而对逻辑空间则先进行段的划分，然后在每一段内再进行页的划分。 在段页式系统中，作业运行时同样需要动态地将逻辑地址转换成物理地址。地址转换所依赖的数据结构是段表和页表。每个作业均有一个段表，而每一段都有一个页表（都放在系统空间里）。 5.3 虚拟存储管理 虚拟存储管理，这种管理方法通过统一管理主、辅存，给用户造成一种仿佛系统内具有巨大主存供用户使用的假象。 因为它只把运行程序在最近一段时间里活跃的那一部分放进主存，而这一部分往往只占整个程序空间的少数，于是主存中能同时存在的进程道数明显增多，为提高系统的吞吐量奠定了基础。 程序在执行时，当访问的页不在主存时，根据页表项的指引，从辅存将其调入主存。如果这时已无可用的物理空间，则从主存淘汰若干页。 修改位是为了在将页面所占用的主存页帧释放回系统时，指明该页是否要回写到辅存块中。 专用的交换区（或Swap文件/页文件）用于存放那些可读写的进程页面。 若合法位未被置上，则马上产生一个页故障（Page Fault）或称为缺页异常。进入操作系统核心，马上进行页面调入处理。 如何选取被淘汰的页是由页面替换策略决定的，进程的合法页集合称为驻留集（或称工作集），是否允许进程驻留集大小可变也是页面替换策略的关键。 首先对页表按物理内存页帧大小进行分页，对它们编号并离散地存放于不同的物理页帧中；同时为离散存储的页表再建立一张页表，称为外层页表（Outer Page Table）或页目录表，以记录各页表对应的物理页帧号。 多级页表技术，不但突破了页表必须连续存放的限制，同时当有大片虚地址空间未使用时，可以不分配对应页表空间，因此可节省内存。另外，多级页表增加了访存次数，因此外层页表的页表项应该尽可能保持在快表中，以减少访存开销。 elady奇异是指替换策略不符合随着驻留集大小的增大，页故障数一定减少的规律。例 它淘汰下次访问距当前最远的那些页中序号最小的一页。 LRU策略淘汰上次使用距当前最远的页。 第六章 设备管理 管理和控制所有的外部设备（又称I/O设备），是操作系统的主要功能之一。 6.1 I/O硬件概念 之所以将设备区分成上述三种类型，主要是因为对它们的管理方法不同。 设备管理子系统屏蔽了对各类设备的控制细节，提供一个设备与操作系统其他部分之间的简单易用的接口，并且该接口应对所有设备尽可能地一致，这就是设备无关性。 电子部分称为I/O部件或设备控制器。在个人计算机中，它常常是一块可以插入主板扩展槽的印制电路板，机械部分则是设备本身 设备本身又发展成了拥有机械部分和部分控制电路的智能设备。 之所以区分控制器和设备本身是因为操作系统大多与控制器打交道，而非设备本身。 连接CPU、主存、设备控制器和设备的多总线模型 每个可编程设备控制器都有一些用来与CPU通信的寄存器。在某些计算机上，这些寄存器占用主存物理地址空间的一部分，这种方案称为主存映射I/O。 操作系统通过向控制器的寄存器写命令字来执行I/O功能。 PCI总线控制器不能算是设备控制器，它在初始化后，只是作为处理机/主存与外部设备之间数据交换的通路，控制总线的使用，没有直接控制设备I/O的逻辑。 在程序直接控制I/O时，CPU直接控制I/O操作过程，包括测试设备状态，发送读/写命令与数据。 CPU向设备控制器发出命令后，继续做其他有用的工作。当设备控制器准备好与CPU交换数据时，设备控制器中断CPU，要求服务。CPU被中断后，执行CPU寄存器与设备控制器之间的数据传输，然后恢复被中断的工作。 当大量的数据在外部设备与主存之间移动时，一种有效的技术就是DMA（Direct Memory Access）。 发出命令后，CPU继续进行其他的工作。它把这次I/O任务委托给了DMA部件，由它负责完成这次I/O操作。DMA部件每次一个字地将整个数据块直接读取或写入主存，而不需经过CPU的寄存器。当传送过程完成后，DMA部件向CPU发中断信号。因此，仅在数据块传送的开始及结束处涉及到CPU， 在DMA传送期间，CPU的执行速度会慢下来。无论如何，对于一次成块的多字节的I/O传送来说，DMA方式比中断驱动I/O要减少许多中断，减少许多CPU的I/O启动操作。 6.2 设备I/O子系统 独占式使用设备是指在申请设备时，如果设备空闲，就将其独占，不再允许其他进程申请使用，一直等到该设备被释放，才允许被其他进程申请使用。 对磁盘设备进行I/O操作时，也采用了分时式共享使用，就是说，把每一次对磁盘设备的I/O操作的数据都看成是逻辑上完整的，从而无需对设备进行独占式申请，保证设备的高效使用。 假脱机I/O技术。把这种技术用于对设备的使用，实质就是对I/O操作进行成批处理。 必须避免边生成输出数据边打印，可以将输出数据边生成边写入文件（或写到所谓的磁盘输出井中），文件相当于虚拟打印设备，待到全部输出完成，再独占打印机把文件（或输出井）内容从打印机上打印出来。 每个打印机建立一个打印服务（Daemon）进程，和一个打印队列（该队列的每个表项对应一个输出文件副本）。打印服务进程循环地获取打印队列中的表项，顺序地从每个文件副本中读取出数据，再成批地调用写打印机的系统调用将该文件的数据打印在纸上。 用户层I/O是提供给用户进程使用I/O设备进行I/O操作的接口，它运行在用户态。系统调用接口，设备无关的操作系统软件、设备驱动及中断处理则在核心态运行，属于操作系统内核程序。 这些库函数在用户态运行，它们往往没有做太多的事情，而只转调操作系统的I/O相关的系统调用。 块设备和字符设备都需要缓冲技术 设备驱动程序包括所有与设备相关的代码。每个设备驱动程序只处理一种设备或者一类紧密相关的设备。 笼统地说，设备驱动程序的功能，是从与设备无关的软件中接收抽象的I/O请求并执行。 缓冲技术实际上是在计算机各个层次使用的一种通用技术，缓冲区比目标存储访问速度要快，当然缓冲区只能存放目标存储的部分数据，设立缓冲区的目的是减少访问目标存储部件的次数，提高I/O速度。 在用户进程从一个系统缓冲区移走（填入）数据的同时，操作系统可往另一系统缓冲区填入（移走）数据。 引入缓冲可有效地改善CPU与I/O设备之间速度不匹配的矛盾。 无论开辟多少缓冲区，都无法使I/O操作的速度跟上进程的运行。当所有的缓冲区渐渐地被填满后，缓冲区的作用随即减弱，进程将不得不在处理完一批数据后等待I/O。 6.3 存储设备 根据磁头的当前位置，首先选择请求队列中距磁头最短的请求，再为之服务。 即让磁头固定地从外向内然后从内向外逐柱面运动，如此往复。磁头固定在水平的两个端点来回扫描。 这种调度算法使磁头从盘面上的一端（逐柱面地）向另一端移动来服务请求，返回时直接快速移至起始端而不服务任何请求。如此往复单向地扫描并平均地为各种请求服务。 一个磁盘的失效不会导致数据丢失。这种磁盘组织技术，统称为冗余廉价磁盘阵列（RAID，Redundant Arrays of Inexpensive Disks），通常用于解决性能和可靠性问题。 可靠性问题的解决是引入冗余。除了原始信息以外还存储额外数据，虽然它们不被经常使用，但可以用来在磁盘失效时重建丢失的信息。这样，即使磁盘失效，数据也可以恢复。 最简单（但最贵）的冗余方法是复制所有的磁盘，这种技术称为镜像。 6.4 小结 设备控制器中常常包含三类寄存器，它们分别用于：① 存放控制命令；② 存放状态信息；③ 存放数据。软件通过读/写这三类寄存器完成相应的I/O操作。 第七章 文件系统 早期人们就引入了辅助存储器（也称文件存储器）用于保存大量的永久性信息（如系统库程序、编译程序等实用程序及操作系统自身的部分程序和数据等）和临时性信息（用户的程序、数据、系统临时数据等）。 7.1 文件结构 辅助存储器用来存放各种程序和数据，这些存放在辅助存储器中的程序和数据称为文件 操作系统抛开存储设备的物理特性，定义了逻辑存储实体，即文件，并负责将文件映射到物理设备上。这是操作系统文件管理所要完成的基本功能之一。 文件根据其用途必须有确定的结构 若将解释文件结构信息的工作赋予操作系统外层的软件（如文本编辑程序等），那么在操作系统这一级则将文件视为无结构（或只涉及简单的逻辑结构）、无解释的信息集合，如UNIX操作系统只简单地把所有文件看成是一组8位字节的信息流，不对文件的信息项做任何解释。 指用户随机地访问文件中的某段信息。 文件必须存放于可以支持快速定位的随机访问存储设备中。文件中的记录（或逻辑字节）被顺序编号，文件被允许随机读/写任意的记录（或逻辑字节），无任何限制。 光盘设备的特点是定位速度快、可直接访问，但其上的文件往往是一次性写入，不可以删除和重写文件。 文件存储器的信息存储、读/写均以块为单位，这种物理块也称为物理记录。 解决逻辑记录到物理记录的映射 若一个文件在辅存中是散布在辅存非连续的若干物理块中，且用向前指针把每个记录依次链接起来（如用每个记录的最后一个字作为指针，指向下一个记录的物理位置），这种组织形式称为链接结构 可将文件的全部逻辑记录都散存在辅存的各物理块中，为文件建立一张索引表，登记相应逻辑记录的长度及其辅存的物理位置 文件应包括文件控制块（FCB，File Control Block）和文件体。后者是文件的有效信息部分；前者则是一张用于存放文件标识、定位、说明和控制等信息的表格。 7.2 文件目录结构 一级目录结构又叫平面（Flat）文件结构。 将记录文件的目录分成主文件目录（主目录）和由其主管的若干子目录，且各子目录的物理位置由主目录中的目录项指出，这种结构即为二级目录结构。 二级目录结构可视为根结点是MFD的二级树结构，MFD的子结点是UFD，UFD的孩子结点则是文件树的叶结点。 树形目录结构也称为多级目录结构。 树中的每个文件具有唯一的路径名。路径名为根结点与经子目录的各级结点直至文件的结点名的顺序组合。 用户可指定某级目录作为用户“当前目录”，当前目录的FCB事先已读入并保存在主存。 人们因此而引入一种无环图目录结构 可建立一个称为链的新目录项，由此链指向共享文件或子目录。 7.3 文件存储器空间布局与管理 在系统运行过程中，文件频繁地被创建和删除，文件系统对磁盘空间的分配保持一个称为“自由空间表”的数据结构。 第八章：并行与分布式操作系统 8.1 并行操作系统 对称多处理机，这是目前并行处理机中最常见的一种结构，在此结构上的操作系统应该同时调度多进程（或线程）在多处理机上运行，甚至让多个处理机对称地同时响应不同的中断。 现代进程概念，将进程控制块中与资源相关的部分和与执行相关的部分部分分离，这种分离引出了线程结构。 由多个中央处理机组成，它们共享主存并且每个处理机都可以响应中断，具有完全的对称结构，称为对称多处理机（SMP） 共享主存系统。顾名思义，是所有处理机共享同一个物理主存，所有处理机可以平等地访问同一个物理存储器。 分布存储系统。每个处理机都有自己的存储器，每个处理机通过互联网络连接起来。当需要时，可以通过网络交换各自存储器中的数据。 并行程序段能够在多处理机结构下实现真正并行，而不是单机的分时并发执行，对资源互斥访问有新的要求 现代操作系统有意地把这两部分特性分离，并在进程里可以定义多个执行对象，使并行任务能在进程内并行，这种执行对象称为线程。 把进程看做除了处理机资源外的其他资源分配单位，但线程总是隶属于进程的，而且进程至少要包含一个线程。 进程在创建时一般同时创建第一个线程，其他线程按需要由用户程序发出请求创建。 与一个线程关联的私有存储区。每个线程有一个存放与线程相对应的局部变量区。该区与执行栈的区别是，栈区间用于存放调用点现场、函数内局部变量，一般由编译系统安排使用，而该私有存储区空间可由用户程序指定申请，存放长效局部变量，可以在同一个线程中跨函数使用。 进程拥有一个虚地址空间，一个用户栈用于执行用户程序，一个核心栈用于执行内核程序。 用户栈存放于进程用户虚空间中，核心栈存放于系统空间中。 一个进程中的所有线程可共享进程空间及对系统其他资源的使用。 对处理机的占用以线程为单位，调度及处理机切换则必须利用线程的数据结构。 由于进程用户空间分立，进程间同步、通信必须通过操作系统的系统调用来实现。 对于线程间通信与同步，若涉及不同进程的线程，实际就是进程间通信。对于同一进程内的线程间通信与同步，由于线程共享同一片用户进程空间，线程之间的通信与同步就变得很容易，通信完全可以在共享变量间进行。 多线库支持的线程称为用户级线程，内核支持的线程称为内核级线程或轻权进程LWP。 由于对线程的所有操作都不涉及内核，因此用户级线程的创建、结束、调度、现场保护与切换开销非常少 在对多处理机线程调度和处理分配问题的研究中，以下5个方案在现代操作系统线程调度设计中影响很大： ① 负载共享。线程不被指定到任何特别的处理机。系统维护一个全局的就绪线程队列，任何处理机在空闲时都可以到该队列上获得一个就绪线程来运行。 ② 负载绑定。指定运行线程的处理机，线程只能在指定的处理机上运行。 ③ 组调度。将一组相关的线程同时调度到一组处理机上运行。 ④ 独占处理机调度。这与负载共享恰恰相反，将一组处理机分配给指定并行程序中的线程运行，等到并行程序运行结束，处理机才被系统收回，以利系统分配给其他并行程序。 ⑤ 多级动态调度。允许并行程序中的线程数目在运行过程中动态改变，利用多级线程支持实现多级调度。 8.2 分布式系统 分布式系统是由独立计算机（又称节点）组成的集合，并给用户一个单一系统的映像。 构建分布式系统主要有如下几个好处：实现分布资源位置透明，方式共享；提高系统计算能力；提高系统的可靠性和健壮性。 如果能将用户任务分解成可以并行运行的子任务，那么可以将这些能并行运行的子任务分布到分布式系统的各台计算机上并行运行，从而提高系统的计算能力。 客户/服务器模型又称工作站/服务器模型（Workstation/Server Model） 在对等模型中，系统中的每台计算机具有高度自治性，可以采用工作站或多用户计算机充当节点计算机，每个节点机都运行一组完整的标准软件，既可以作为客户机运行用户应用程序，又可以充当服务器为其他节点机提供服务。 集群定义为一组由相同功能的计算机互连而成的系统，它们作为统一的计算资源一起发挥作用，给客户一台机器的感觉。 IP（网际协议）。IP是面向无连接的报文交换协议，负责寻址和路由的选择。 ARP负责由IP地址到硬件地址（MAC地址）的转换。 RARP负责完成由硬件地址到IP地址的转换 第九章：保护与安全 9.1 安全威胁 蠕虫是一个独立的程序，利用网络连接寻找攻击目标。蠕虫通常由两部分程序组成：粘连（或钩子）程序和主程序。 特洛伊木马是一个独立的程序，表面上在执行合法任务，实际上却具有用户不曾料到的非法功能。 9.2 安全机制 数据加密标准（DES，Data Encryption Standard）是使用最广泛的对称加密算法， 若以公钥作为加密密钥，以私钥作为解密密钥，则可实现多个用户加密的信息只能由一个用户解读；反之，以私钥作为加密密钥而以公钥作为解密密钥，则可实现一个用户加密的信息能由多个用户解读。前者可用于数据加密，后者可用于数字签名。 数字签名是指用户使用自己的私钥对原始数据的数字摘要进行加密所得的数据。 ","link":"https://Angus1996.github.io/post/lesslesscao-zuo-xi-tong-xue-xi-bi-ji-greatergreater/"},{"title":"验证中心极限定理（python实现）","content":"中心极限定理 从一个非正态总体中取出一个样本，且样本很大（比如大于30），则样本均值的分布近似服从正态分布。 换句话说，每次取出的样本的样本均值是一个随机变量，重复多组实验，观察得到这个随机变量近似服从正态分布。 实验 import numpy as np import matplotlib.pyplot as plt # 模拟投掷硬币，0为正面，1为反面，总体服从二项分布 sample_mean=[] for i in range(100000): # 进行100000组实验，每组抛掷50次 sample=[] #每组一个列表 for j in range(50): #模拟抛50次 sample.append(np.random.randint(0,2)) sample = np.array(sample) #转化为array数组，便于处理 sample_mean.append(sample.mean()) sample_mean_np = np.array(sample_mean) print(sample_mean_np) [0.6 0.44 0.62 ... 0.54 0.5 0.6 ] # 验证每组实验抛硬币的均值服从正态分布 plt.figure(figsize=(20,10),dpi=80) d =0.001 num_bins = int((max(sample_mean_np)-min(sample_mean_np))/d) plt.hist(sample_mean_np,num_bins) #绘制频率分布图 观察上图，有明显的近似于均值为0.5的正态分布。 ","link":"https://Angus1996.github.io/post/yan-zheng-zhong-xin-ji-xian-ding-li-python-shi-xian/"},{"title":"《算法 4th edition》学习笔记","content":"chapter 1 基础 1.1 基础编程模型 数组名表示的是整个数组——如果我们将一个数组变量赋予另一个变量，那么两个变量将会指向同一个数组。 int[] a = new int[N]; ... a[i] = 1234; ... int[] b = a; ... b[i] = 5678; //a[i]也会变成5678 这种情况叫做 起别名 ，有时可能会导致难以察觉的问题。如果你想将数组复制一份，应该声明、创建并初始化一个新的数组，然后将原数组中的元素挨个复制到新的数组。 1.2 数组抽象 数据类型 指的是一组值和一组对这些值的操作的集合。 Java编程的基础主要是使用class 关键字构造被称为引用类型的数据类型。 对象 是能够承载数据类型的值的实体。所有对象都有三大重要特性：状态、标识和行为 。对象的状态即数据类型中的值。对象的标识就是它在内存中的位置。对象的行为就是数据类型的操作。 引用是访问对象的一种方式。Java使用术语引用类型以示和原始数据类型（变量和值相关联）的区别。不同的Java实现中引用的实现细节也各不同，但可以认为引用就是内存地址。 构造函数没有返回值，因为它总是返回它的数据类型的对象的引用。 每当用例调用了new()，系统都会：1️⃣ 为新的对象分配内存空间； 2️⃣ 调用构造函数初始化对象中的值； 3️⃣ 返回该对象的一个引用。 静态方法 的主要作用是实现函数；非静态（实例）方法的主要 作用是实现数据类型的操作。静态方法调用的开头是类名（按习惯为大写），而非静态方法调用的开头总是对象名（按习惯为小写）。 使用引用类型的赋值语句将会创建该引用的一个副本。赋值语句不会创建新的对象，而只是创建另一个指向某个已经存在的对象的引用。这种情况叫做别名。 创建一个对象的数组需要一下两个步骤： 1️⃣ 使用方括号语法调用数组的构造函数创建数组； 2️⃣ 对于每个数组元素调用它的构造函数创建相应的对象。 1.3 背包、栈、队列 集合类的抽象数据类型的一个关键特性是我们应该可以用它们存储任意类型的数据。一种特别的Java机制能够做到这一点，被称为泛型，也叫做 参数化类型。 背包是一种不支持从中删除元素的集合数据类型——他的目的是帮助用例收集元素并迭代遍历所有收集到的元素。迭代的顺序不确定且与用例无关。 先进先出队列（简称队列）是一种基于先进先出（FIFO）策略的集合类型。 下压栈（简称栈）是一种基于后进先出（LIFO）策略的集合类型。 典型用例：用两个栈解决未省略括号的算术表达式求值： 将操作数压入操作数栈； 将运算符压入运算符栈； 忽略左括号； 在遇到右括号时，弹出一个运算符，弹出所需数量的操作数，并将运算符和操作数的运算结果压入操作数栈。 链表是一种递归的数据结构，它或者为空(null)，或者是指向一个节点(node)的引用。该结点含有一个泛型的元素和一个指向另一条链表的引用。 private class Node{ Item item; Node next; } 两个实例变量：Item(参数类型)和Node；Item是一个占位符，表示任意数据类型； Node first = new Node() #first是指向一个Node对象的引用，使用first.item和first.next访问它的实例变量。 访问链表中所有元素： 将循环的索引变量 x 初始化为链表的首结点。然后通过 x.item 访问和 x 相关联的元素，并将 x 设为 x.next 来访问链表中的下一个结点，如此反复直到 x 为null为止（已经到达了链表的尾部）。 for(Node x = first; x != null; x = x.next){ //处理x.item } 数组和链表常常被称为顺序存储和链式存储。 在泛型中，如果将错误类型的对象压入栈中，会发生 编译时报错 。 问：为什么将Node声明为嵌套类？为什么使用private? 答：将Node声明为私有的嵌套类之后，我们可以将Node的方法和实例变量的访问范围限制在包含他的类中。私有嵌套类的一个特点是只有包含他的类能够直接访问它的实例变量，因此无需将它的实例变量声明为public或者private。非静态的嵌套类也被称为内部类。（在写链表结点的定义时，注意是否为嵌套类定义） 编写一个函数，接受一条链表的首结点作为参数，（破坏性地）将链表反转并返回结果链表的首结点。 迭代方式的解答：记录链表中的三个连续的结点：reverse、first和second。在每轮迭代中，我们从原链表中提取结点first并将它插入逆链表的开头。我们需要一直保持first指向原链表的所有剩余结点的首结点，second指向原链表中所有剩余结点的第二个结点，reverse指向结果链表的首结点。 public Node reverse(Node x){ Node first = x; Node reverse = null; while(first != null){ Node second = first.next; first.next = reverse; reverse = first; first = second; } return reverse } 递归解答： 假设链表含有N个结点，我们先递归颠倒最后N-1个结点，然后小心地将原链表中的首结点插入到结果链表的末端。 public Node reverse(Node first){ if (first == null) return null; if (first.next == null) return first; Node second = first.next; Node rest = reverse(second); second.next = first; first.next = null; return rest; } 1.4 算法分析 一个程序运行的总时间主要和两点有关：1️⃣ ​执行每条语句的耗时；2️⃣ 执行每条语句的频率。前者取决于计算机、Java编译器和操作系统，后者取决于程序本身和输入。 执行最频繁的指令决定了程序执行的总时间——我们将这些指令称之为程序的内循环。许多程序的运行时间都只取决于其中的一小部分指令。 统计一个文件中所有和为的三整数元组的数量（ThreeSum问题） // 暴力破解法 public class ThreeSum{ public static int count(int[] a){ int N = a.length; int cnt = 0; for (int i = 0;i &lt; N; i++) for (int j = i+1; j &lt; N; j++) for (int k = j+1; k &lt; N; k++) if (a[i]+a[j]+a[k] == 0) cnt++; return cnt; } public static void main(String[] args){ int[] a = In.readInts(args[0]); StdOut.println(count(a)); } } ThreeSum 的运行时间的增行数量级是 N3N^3N3 ，这与它是由Java实现或是它运行在哪台电脑上无关。使用的算法决定了增长的数量级。（可以使用数学归纳法证明从NNN 个数中取三个整数的不同组合的总数为 N(N−1)(N−2)/6N(N-1)(N-2)/6N(N−1)(N−2)/6 对于大多数程序，得到其运行时间的数学模型所需的步骤如下： 1️⃣ 确定输入模型，定义问题的规模； 2️⃣ 识别内循环； 3️⃣ 根据内循环中的操作确定成本模型； 4️⃣ 对于给定的输入，判断这些操作的执行频率。 for (int i = 1; i &lt; N; i++) for (int j = i+1;j &lt; N; j++) for (int k = j+1; k &lt; N; k++) if (a[i] + a[j] + a[k] == 0) cnt++; 对增长数量级的常见假设的总结 描述 增长的数量级 典型的代码 说明 举例 常数级别 1 a = a + b 普通语句 将两个数相加 对数级别 logNlog NlogN 二分查找 二分策略 二分查找 线性级别 NNN double max = a[0];for (int i = 1; i &lt; N; i++) if (a[i] &gt; max) max = a[i]; 循环 找出最大元素 线性对数级别 NlogNNlogNNlogN 归并排序 分治 归并排序 平方级别 N2N^2N2 for (int i = 1; i &lt; N; i++) for (int j = i+1;j &lt; N; j++) if (a[i] + a[j] == 0) cnt++; 双层循环 检查所有元素对 立方级别 N3N^3N3 for (int i = 1; i &lt; N; i++) for (int j = i+1;j &lt; N; j++) for (int k = j+1; k &lt; N; k++) if (a[i] + a[j] + a[k] == 0) cnt++; 三层循环 检查所有三元组 指数级别 2N2^N2N ch6 穷举查找 检查所有子集 平方级别、立方级别和指数级别的算法对于大规模的问题是不可用的。许多重要问题的直观解法是平方级别的，但我们也可以找到它们线性对数级别的算法。 2-sum问题的线性对数级别的解法 首先对数组排序（为二分查找做准备）， 然后对于数组中的每个 a[i] ，使用 BinarySearch 的**rank()**方法对 **-a[i]**进行二分查找。归并排序所需时间和NlogNNlogNNlogN 成正比，二分查找所需的时间和 logNlogNlogN 成正比，因此整个算法的运行时间和 NlogNNlogNNlogN 成正比。 import java.util.Arrays; public class TwoSumFast{ public static int count(int[] a){ Arrays.sort(a); //归并排序 int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++){ if (BinarySearch.rank(-a[i]， a) &gt; i) cnt++; } return cnt; } public static void main(String[] args){ int[] a = In.readInts(args[0]); Stdout.println(count(a)); } } 3-sum问题的快速算法 对数组排序并进行 N(N−1)/2N(N-1)/2N(N−1)/2 次二分查找，每次查找所需的时间都和 logNlogNlogN 成正比。因此总运行时间和 N2logNN^2 logNN2logN 成正比。 import java.util.Arrays; public class ThreeSumFast{ public static int count(int[] a){ Arrays.sort(a); //归并排序 int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++){ for (int j = i+1; j &lt; N; j++) if (BinarySearch.rank(-a[i]-a[j]， a) &gt; j) cnt++; } return cnt; } public static void main(String[] args){ int[] a = In.readInts(args[0]); Stdout.println(count(a)); } } 调用 substring() 方法时，就创建了一个新的 string 对象（40字节），但是它仍重用了相同的 value[] 数组，因此该字符串的子字符串只会使用40字节的内存。 程序调用一个方法时，系统会从内存中的一个特定区域为方法分配所需的内存（用于保存局部变量），这个区域叫做 栈 （Java系统的下压栈）。当方法返回时，它所占用的内存也被返回给了系统栈。因此，在递归程序中创建数组或是其他大型对象是很危险的，因为这意味着每一次递归调用都会使用大量的内存。 当通过 new 创建对象时，系统会从 堆内存 的另一块特定区域为该对象分配所需的内存。 1.5 union-find算法 union-find算法也就是经典的并查集算法，用于解决动态连通性问题.通过对这个算法的一步步更新可以体会到算法优化的思想和好处. 基本思想:对于给定的两个触点，判断它们所在的连通分量是否相同，将查找连通分量称为find.如果未连通，则将这两个触点以及分别与它们连通的触点连通，将连通称为union. 基础实现:使用一个id数组，保证在同一连通分量中的所有触点在id数组中的值是全部相同的. find:返回触点在id数组中对应的值. union:分别对p和q进行find操作，如果对应值相等不做操作，不相等则遍历id数组，将所有与p的对应值相等的id值改为q的id值. quick-union:改变id数组的定义，每个触点所对应的id元素都是同一个分量中另一个触点的名称，这种联系称为链接.由一个触点的链接一直跟随下去一定会到达根触点，即链接指向子集的触点.当且仅当两个触点的根触点相同时它们存在于同一个连通分量中. find:返回一个触点链接的根触点. union:分别对p和q进行find操作，如果对应值相等不做操作，不相等则将p的根触点链接到q的根触点上. 加权quick-union:为了防止树极度不均衡，记录每一棵树的大小并总是将较小的树连接到较大的树上.在程序中引入size数组记录各个触点的根节点所对应的分量的大小. find:返回一个触点链接的根触点. union:分别对p和q进行find操作，如果对应值相等不做操作，不相等则判断对应值的根节点分量的大小，将小树的根触点链接到大树的根触点上. 路径压缩:为find函数添加一个循环，将在路径上遇到的所有节点都直接链接到根节点. 关于并查集，可以参考这篇文章. chapter 2 排序 2.1 初级排序算法 排序算法类的模板 less() 方法对元素进行比较，exch() 方法将元素交换位置。 public class Example{ public static void sort(Comparable[] a){ /* 排序算法 */ } private static boolean less(Comparable v， Comparable w) { return (v.compareTo(w) &lt; 0); } private static void exch(Comparable[] a， int i， int j) { Comparable swap = a[i]; a[i] = a[j]; a[j] = swap; } private static void show(Comparable[] a){ for (int i = 0; i &lt; a.length; i++) StdOut.println(a[i] + &quot; &quot;); StdOut.println(); } public static boolean isSorted(Comparable[] a){ // 测试数组元素是否有序 for (int i = 1; i &lt; a.length; i++) if (less(a[i]， a[i-1])) return false; return true; } public static void main(String[] args){ String[] a = In.readStrings(); sort(a); isSorted(a); show(a); } } 排序算法可以分为两类：1️⃣ 除了函数调用所需的栈和固定数目的实例变量之外无需额外内存的原地排序算法；2️⃣ 需要额外内存空间来存储另一份数组副本的其他排序算法。 选择排序： 首先找到数组中最小的元素，其次，将它和数组的第一个元素交换位置（如果第一个元素就是最小元素那么就和他自己交换）。再次，在剩下的元素中找到最小的元素，将它和数组的第二个元素交换位置。如此往复，直到将整个数组排序。 public Selection() { public static void sort(Comparable[] a) { int n = a.length; //数组长度 for (int i = 0; i &lt; n; i++) { // 将a[i]和a[i+1..N]中最小的元素交换 int min = i; for (int j = i+1; j &lt; n; j++) { if (less(a[j]， a[min])) min = j; } exch(a， i， min); } } } 对于长度为N的数组，选择排序需要大约N2/2N^2/2N2/2 次比较和NNN 次交换。 插入排序： 将每一张元素插入到其他已经有序的元素中的适当位置。在计算机的实现中，为了给要插入的元素腾出空间，我们需要将其余所有元素在插入之前都向右移动一位。 public class Insertion { public static void sort(Comparable[] a) { int n = a.length; for (int i = 1; i &lt; n; i++) { //左边已经有序，通过比较将元素找个位置插入 /*例如i=5时，a[0]到a[4]是有序的，比较a[5]和a[4]，如果a[5]比a[4]大，循环终止；如果a[5]比a[4]小，进入for循环，交换a[5]和a[4]；继续，j--，即比较a[4]和a[3]，以此类推；最后将原始的a[5]插入到合适位置；等效于比a[5]大的元素都会向右移动一位*/ for (int j = i; j &gt; 0 &amp;&amp; less(a[j]， a[j-1]); j--) { exch(a， j， j-1); } assert isSorted(a， 0， i); } assert isSorted(a); } } 对于随机排列的长度为NNN 且主键不重复的数组，平均情况下插入排序需要∼N2/4\\sim N^2/4∼N2/4 次比较以及∼N2/4\\sim N^2/4∼N2/4次交换。最坏情况下需要∼N2/2\\sim N^2/2∼N2/2次比较和∼N2/2\\sim N^2/2∼N2/2次交换，最好情况下需要N−1N-1N−1次比较和000次交换。 倒置指的是数组中的两个顺序颠倒的元素。比如 EXAMPLEEXAMPLEEXAMPLE 中有11对倒置：E−A、X−A、X−M、X−P、X−L、X−E、M−L、M−E、P−L、P−EE-A、X-A、X-M、X-P、X-L、X-E、M-L、M-E、P-L、P-EE−A、X−A、X−M、X−P、X−L、X−E、M−L、M−E、P−L、P−E以及L−EL-EL−E 。如果数组中倒置的数量小于数组大小的某个倍数，那么我们说这个数组是部分有序的。 几种典型的部分有序的数组：1️⃣ 数组中每个元素距离它们的最终位置都不远；2️⃣ 一个有序的大数组借一个小数组；3️⃣ 数组中只有几个元素的位置不正确。 插入排序需要的交换操作和数组中倒置的数量相同，需要的比较次数大于等于倒置的数量，小于等于倒置的数量加上数组的大小再减一。 要大幅提高插入排序的速度，只需要在内循环中将较大的元素都向右移动而不总是交换两个元素（这样访问数组的次数就能减半）。 希尔排序 的思想是使数组中间隔为hhh 的元素都是有序的。这样的数组被称为h有序数组。在进行排序时，如果hhh很大，就能将元素移动到很远的地方，为实现更小的hhh有序创造方便。用这种方式，对于任意以1结尾的hhh序列，就能够将数组排序，这就是希尔排序。 public class Shell { /** * Rearranges the array in ascending order， using the natural order. * @param a the array to be sorted */ public static void sort(Comparable[] a) { int n = a.length; int h = 1; /* 3x+1 increment sequence: 1， 4， 13， 40， 121， 364， 1093， ... */ while (h &lt; n/3) h = 3*h + 1; while (h &gt;= 1) { // h-sort the array for (int i = h; i &lt; n; i++) { for (int j = i; j &gt;= h &amp;&amp; less(a[j]， a[j-h]); j -= h) { exch(a， j， j-h); } } assert isHsorted(a， h); h /= 3; } assert isSorted(a); } } 需要解决一个排序问题而有没有系统排序函数可用时，可以先用希尔排序，然后再考虑是否值得将它替换为更加复杂的排序算法。对于中等大小的数组，它的运行时间是可以接受的，而且代码量小又不需要额外的内存空间。而更加复杂的代码对于很大的NNN ，可能只会比希尔排序快两倍（可能还达不到）。 2.2 归并排序 **归并：**将两个有序的数组归并成一个更大的有序数组。 归并排序：要将一个数组排序，可以先（递归地）将它分成两半分别排序，然后将结果归并起来。归并排序可以保证将任意长度为NNN 的数组排序所需时间和NlogNNlogNNlogN 成正比，重要缺点是它所需的额外内存空间和NNN成正比。 原地归并的抽象方法 private static void merge(Comparable[] a， Comparable[] aux， int lo， int mid， int hi) { // precondition: a[lo .. mid] and a[mid+1 .. hi] are sorted subarrays assert isSorted(a， lo， mid); assert isSorted(a， mid+1， hi); // copy to aux[] for (int k = lo; k &lt;= hi; k++) { aux[k] = a[k]; } // merge back to a[] int i = lo， j = mid+1; for (int k = lo; k &lt;= hi; k++) { if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j]， aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; } 自顶向下的归并排序：分治思想的最典型例子。如果它能够将两个子数组排序，他就能够通过归并两个子数组来将整个数组排序。 public class Merge{ private static Comparable[] aux; // 归并所需的辅助数组 public static void sort(Comparable[] a) { aux = new Comparable[a.length]; sort(a， aux， 0， a.length-1); assert isSorted(a); } private static void sort(Comparable[] a， Comparable[] aux， int lo， int hi) { if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a， aux， lo， mid); //将左半边排序 sort(a， aux， mid + 1， hi); //将右半边排序 merge(a， aux， lo， mid， hi); //归并结果（“原地归并的抽象方法”） } } 对于长度为NNN的任意数组，自顶向下的归并排序需要1/2NlgN1/2NlgN1/2NlgN 至NlgNNlgNNlgN 次比较，最多需要访问数组6NlgN6NlgN6NlgN 次。 自底向上的归并排序：首先我们进行的是两两归并（把每个元素想象成一个大小为1的数组），然后是四四归并（将两个大小为2的数组归并成一个有4个元素的数组），然后是八八的归并，一直下去。在每一轮归并中，最后一次归并的第二个子数组可能比第一子数组要小（但这对merge() 方法不是问题） public class MergeBU { public static void sort(Comparable[] a) { int n = a.length; Comparable[] aux = new Comparable[n]; for (int len = 1; len &lt; n; len *= 2) { for (int lo = 0; lo &lt; n-len; lo += len+len) { int mid = lo+len-1; int hi = Math.min(lo+len+len-1， n-1); merge(a， aux， lo， mid， hi); } } assert isSorted(a); } } 对于长度为NNN的任意数组，自顶向下的归并排序需要1/2NlgN1/2NlgN1/2NlgN 至NlgNNlgNNlgN 次比较，最多需要访问数组6NlgN6NlgN6NlgN 次。 当数组长度为2的幂次时，自顶向下和自底向上的归并排序所用的比较次数和数组访问次数正好相同，只是顺序不同。 自底向上的归并排序比较适合用链表组织的数据。将链表先按大小为1的子链表进行排序，然后时大小为2的子链表，然后是大小为4的子链表等。这种方法只需要重新组织链表链接就能将链表原地排序（不需要创建任何新的链表结点）。 问：当数组中存在重复的元素时归并排序的表现如何？ 答：如果所有的元素都相同，那么归并排序的运行时间将是线性的（需要一个额外的测试避免归并已经有序的数组）。但如果有多个不同的重复值，这样做的性能收益就不是很明显了。例如，假设输入数组的NNN个技术位上的元素都是同一个值，另外NNN个偶数位上的元素都是另一个值，此时算法的运行时间就是线性对数的（这样的数组和所有元素都不重复的数组满足了相同的循环条件），而非线性的。 2.3 快速排序 快速排序:时间复杂度为O(NlogN)。将一个数组随机打乱(防止出现最坏情况)，然后通过切分变为两个子数组，将两部分独立地排序，使得切分点左边的所有元素都不大于它，右边的所有元素都不小于它。递归地进行这一过程。 public class Quick { /** * Rearranges the array in ascending order， using the natural order. * @param a the array to be sorted */ public static void sort(Comparable[] a) { StdRandom.shuffle(a); sort(a， 0， a.length - 1); assert isSorted(a); } // quicksort the subarray from a[lo] to a[hi] private static void sort(Comparable[] a， int lo， int hi) { if (hi &lt;= lo) return; int j = partition(a， lo， hi); sort(a， lo， j-1); sort(a， j+1， hi); assert isSorted(a， lo， hi); } } 切分:一般策略是随意取a[low]作为切分元素，然后从数组的左端向右扫描，找到一个大于等于它的元素，再从数组的右端向左扫描，找到一个小于等于它的元素，交换它们的位置。如此继续，直到两个指针相遇时，将切分元素**a[low]和左子数组最右侧的元素a[j]**交换然后返回 j。 // partition the subarray a[lo..hi] so that a[lo..j-1] &lt;= a[j] &lt;= a[j+1..hi] private static int partition(Comparable[] a， int lo， int hi) { int i = lo， j = hi + 1; Comparable v = a[lo]; while (true) { // find item on lo to swap while (less(a[++i]， v)) if (i == hi) break; // find item on hi to swap while (less(v， a[--j])) if (j == lo) break; // check if pointers cross if (i &gt;= j) break; exch(a， i， j); } // put partitioning item v at a[j] exch(a， lo， j); // now， a[lo .. j-1] &lt;= a[j] &lt;= a[j+1 .. hi] return j; } 改进: 当子数组较小时(比如长度小于15)使用插入排序 if (hi &lt;= lo + M) {Insertion.sort(a， lo， hi); return;} 取子数组的一小部分元素(比如3个)的中位数来切分数组，还可以将切分元素放在数组末尾作为哨兵来去掉数组边界测试. 如果数组含有大量重复元素，可以采用三向切分的办法，将数组分为小于切分元素，等于切分元素和大于切分元素三部分，它将排序时间降到了线性级别. public class Quick3way { // quicksort the subarray a[lo .. hi] using 3-way partitioning private static void sort(Comparable[] a， int lo， int hi) { if (hi &lt;= lo) return; int lt = lo， gt = hi; Comparable v = a[lo]; int i = lo + 1; while (i &lt;= gt) { int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a， lt++， i++); else if (cmp &gt; 0) exch(a， i， gt--); else i++; } // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a， lo， lt-1); sort(a， gt+1， hi); assert isSorted(a， lo， hi); } } 2.4 优先队列 优先队列：一种支持删除最大元素和插入元素的数据结构。 从N个输入中找到最大的M个元素所需成本呢 增长的数量级 时间 空间 排序算法的用例 NlogNNlog NNlogN NNN 调用初级实现的优先队列 NMNMNM MMM 调用基于堆实现的优先队列 NlogMNlog MNlogM MMM 优先队列的各种实现在最坏情况下运行时间的增长数量级 数据结构 插入元素 删除最大元素 有序数组 NNN 111 无序数组 111 NNN 堆 logNlogNlogN logNlog NlogN 理想情况 111 111 当一颗二叉树的每个结点都大于等于它的两个子结点时，它被称为堆有序。根结点时堆有序的二叉树的最大结点。 二叉堆 是一组能够用堆有序的完全二叉树排序的元素，并在数组中按照层级存储（为了方便，不使用数组中的第一个位置）。 在一个堆中，位置 kkk 的结点的父结点的位置为 ⌊k/2⌋\\lfloor k/2 \\rfloor⌊k/2⌋ ，而它的两个子结点的位置则分别为 2k2k2k 和 2k+12k+12k+1。这样就可以通过计算数组的索引在树中上下移动：从 a[k] 向上一层就令 kkk 等于 k/2k/2k/2，向下一层则令 kkk 等于 2k2k2k 或 2k+12k+12k+1。 一颗大小为N的完全二叉树的高度为 ⌊lgN⌋\\lfloor lgN \\rfloor⌊lgN⌋。 堆的操作会进行一些简单的改动，打破堆的状态，然后再遍历堆并按照要求将堆的状态恢复。我们称为堆的有序化。 由下至上的堆有序化(上浮) ：如果堆的有序状态因为某个结点变得比它的父结点更大而被打破，就需要交换它和它的父结点。位置k的结点的父结点的位置是⌊k/2⌋\\lfloor \\bold{k/2} \\rfloor⌊k/2⌋。重复这个过程直到它不再大于它的父结点为止。 private void swim(int k){ while (k &gt; 1 &amp;&amp; less(k/2， k)){ exch(k/2， k); k = k/2; } } 由上至下的堆有序化(下沉):如果堆的有序状态因为某个结点变得比它的父结点更小而被打破，可以通过交换它和它的两个子结点中的较大者来恢复堆。位置k的结点的子结点为2k和2k+1。重复这个过程直到它的子结点都比它更小或是到达了堆的底部为止。 private void sink(int k){ while (2*k &lt;= N){ int j = 2*k; if (j &lt; N &amp;&amp; less(j， j+1)) j++; if (!less(k， j)) break; exch(k， j); k = j; } } 插入元素:将新元素加到末尾，增加堆的大小并让新元素上浮到合适的位置. 删除最大元素:从堆顶删去最大的元素，并将最后一个元素放到顶端，减小堆的大小并让这个元素下沉到合适的位置。 对于一个含有N个元素的基于堆的优先队列，插入元素操作只需不超过(lgN+1)(lgN+1)(lgN+1)次比较。删除最大元素的操作需要不超过2lgN2lgN2lgN次比较。 使用基于堆的优先队列，将所有元素插入一个查找最小元素的优先队列，然后在重复调用删除最小元素的操作来将它们按照顺序删去，即为堆排序。 堆排序: 1️⃣ 构造:从数组的中间元素开始，从右到左地对每个元素用下沉方法构造子堆。2️⃣ 排序:将最大的元素a[1]和末尾元素a[N]交换，将堆的大小-1，并对交换到堆顶的末尾元素使用下沉来修复堆，直到堆变空，此时数组中的元素已经有序。 public static void sort(Comparable[] a){ int N = a.length; for (int k = N/2; K &gt;= 1; k--) sink(a， k， N); while (N &gt; 1){ exch(a， 1， N--); sink(a， 1， N); } } 用下沉操作由 NNN 个元素构造堆只需要少于 2N2N2N 次比较和少于 NNN 次交换。而用上浮操作，从左到右遍历数组的时间复杂度是O(NlogN)O(NlogN)O(NlogN)。 因为大多数在下沉排序期间重新插入堆的元素会被直接加入到堆底，所以可以使用先下沉后上浮的方法优化，即直接提升较大的子结点直至到达堆底，然后再使元素上浮到正确的位置。 2.5 应用 插入排序和归并排序是稳定的，即不会改变重复元素的相对位置。选择排序、希尔排序、快速排序和堆排序则不是稳定的. 快速排序是最快的通用排序算法。 各种排序算法性能特点 算法 稳定性 是否原地排序 时间复杂度 空间复杂度 备注 选择排序 不稳定 是 $ N^2 $ 111 插入排序 稳定 是 介于NNN和N2N^2N2 111 取决于输入元素的排列情况 希尔排序 不稳定 是 $NlogN? $ N6/5?N^{6/5}?N6/5? 1 快速排序 不稳定 是 NlogNN logNNlogN lgNlg NlgN 运行效率由概率提供保证 三向快速排序 不稳定 是 介于NNN和NlogNN logNNlogN lgNlg NlgN 运行效率由概率提供保证，同时取决于输入元素的分布情况。 归并排序 稳定 否 NlogNNlogNNlogN NNN 堆排序 不稳定 是 NlogNNlogNNlogN 111 归约:为解决某个问题而发明的算法正好可以用来解决另一种问题 找出重复元素:首先将数组排序，然后遍历有序的数组，记录连续出现的重复元素即可. 排名:求两组数列的Kendall tau距离，即在两组排列中相对顺序不同的数字组数.某个排列和标准排列的Kendall tau距离就是其中逆序数对的数量.可以由其中一个排列确定一个标准索引，然后以这个标准索引为标准对两组数列进行归并排序，移动的次数即为Kendall tau距离. 查找中位数:使用快速排序的分割算法，当切分点j小于N/2时只用切分右数组，切分点j大于2/N时只用切分左数组，切分点j=N/2时a[j]即为中位数.如果是海量数据，则可以将数据用二进制表示，根据最大位是0或1划分为两个文件，然后不断对包含中位数的那个文件做此操作，直到可以将剩余的数全部读进内存时再使用快速排序. chapter 3 查找 3.1 符号表 符号表 是一种存储键值对的数据结构，有时也被称为字典 或索引。支持两种操作：插入(put)，即将一组新的键值对存入表中；查找(get)，即根据给定的键得到相应的值。 符号表的实现遵循的规则：1️⃣ 每个键只对应着一个值（表中不允许存在重复的键）。2️⃣ 当用例代码向表中存入的键值对和表中已有的键（及关联的值）冲突时，新的值会替代旧的值。 在符号表中，删除的实现有两种方式：1️⃣ 延时删除，就是将键对应的值置为空(null)，然后在某个时候删去所有值为空的键；2️⃣ 即时删除，就是立刻从表中删除指定的键。 对于符号表的简单实现（无序），用例的输出中键的顺序是不确定的；对于有序符号表，用例应该就键按顺序打印出来，这是一种索引用例。 符号表中使用的数据结构的一个简单选择是链表，每个结点存储一个键值对。在查找中我们一个一个地顺序遍历符号表中的所有键并使用equals()方法来寻找与被查找的键匹配的值，这叫顺序查找。 public class SequentialSearchST&lt;Key， Value&gt;{ private Node first; //链表首结点 private class Node{ Key key; Value val; Node next; public Node(Key key， Value val， Node next){ this.key = key; this.val = val; this.next = next; } } public Value get(Key key){ for (Node x = first; x != null; x = x.next) if (key.equals(x.key)) return x.val; return null; } public void put(Key key， Value val){ for (Node x = first; x != null; x = x.next) if (key.equals(x.key)){ x.val = val; return; //命中，更新 } first = new Node(key， val， first); // 未命中，新建结点 } } 在含有NNN对键值的基于（无序）链表的符号表中，未命中的查找和插入操作都需要NNN次比较。命中的查找在最坏情况下需要NNN次比较，特别地，向一个空表中插入NNN个不同的键需要∼N2/2\\sim N^2/2∼N2/2次比较。 有序符号表使用的数据结构是一对平行的数组，一个存储键一个存储值。核心是**rank()**方法，**rank()**方法能够精确地告诉我们到哪里去更新它的值，以及当键不在表中时将键存储到表的何处。 递归的二分查找rank()方法： public int rank(Key key， int lo， int hi){ if (hi &lt; lo) return lo; // 未查到到，返回插入的位置 int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(Keys[mid]); if (cmp &lt; 0) return rank(key， lo， mid-1); else if (cmp &gt; 0) return rank(key， mid+1， hi); else return mid; } 迭代的二分查找rank()方法： public int rank(Key key){ int lo = 0， hi = N - 1; while (lo &lt; hi){ int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) hi = mid - 1; else if (cmp &gt; 0) lo = mid + 1; else return mid; } return lo; } 二分查找(基于有序数组) public class BinarySearchST&lt;Key extends Comparable&lt;Key&gt;， Value&gt; { private Key[] keys; private Value[] vals; private int N; public BinarySearchST(int capacity) { keys = (Key[]) new Comparable[capacity]; vals = (Value[]) new Object[capacity]; } public int size() { return N; } public Value get(Key key) { if (key == null) throw new IllegalArgumentException(&quot;argument to get() is null&quot;); if (isEmpty()) return null; int i = rank(key); if (i &lt; n &amp;&amp; keys[i].compareTo(key) == 0) return vals[i]; return null; } public int rank(Key key) { } public void put(Key key， Value val) { if (key == null) throw new IllegalArgumentException(&quot;first argument to put() is null&quot;); int i = rank(key); // key is already in table if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) { vals[i] = val; return; } for (int j = N; j &gt; i; j--) { //将所有更大的键向后移动一格来腾出位置 keys[j] = keys[j-1]; vals[j] = vals[j-1]; } keys[i] = key; //并将给定的键值对分别插入到各自的合适位置 vals[i] = val; n++; } } 在NNN个键的有序数组中进行二分查找最多需要(lgN+1)(lgN+1)(lgN+1)次比较（无论是否成功）； 二分查找虽然减少了比较的次数但无法减少运行的时间，因为：在键时随机排列的情况下，构造一个基于有序数组的符号表所需要访问数组的次数是数组长度的平方级别。 符号表的各种实现的优缺点： 使用的数据结构 实现 优点 缺点 链表（顺序查找） SequentialSearchST 适用于小型问题 对于大型符号表很慢 有序数组二分查找 BinarySearchST 最优的查找效率和空间需求，能够进行有序性相关的操作 插入操作很慢 二叉查找树 BST 实现简单，能够进行有序性相关的操作 没有性能上界的保证，链接需要额外的空间 平衡二叉查找树 RedBlackBST 最优的查找和插入效率，能够及逆行有序性相关的操作 链接需要额外的空间 散列表 SeparateChainHashST LInearProbingHashST 能够快速的查找和插入常见类型的数据 需要计算每种类型的数据的散列，无法进行相关性相关的操作，链接和空结点需要额外的空间 3.2 二叉查找树 一棵二叉查找树(BST)是一棵二叉树，其中每个结点都含有一个Comparable的键以及值，且每个结点的键都大于其左子树中的任意结点的键而小于其右子树的任意结点的键。 每个结点还会有一个结点计数器，它给出了以该结点为根的子树的结点总数size(x)=size(x.left)+size(x.right)+1\\bold{size(x)=size(x.left)+size(x.right)+1}size(x)=size(x.left)+size(x.right)+1 一棵二叉查找树代表了一组键的集合，而同一个集合可以用多颗不同的二叉查找树表示。如果将一棵二叉查找树的所有键按从左到右的顺序投影到一条直线上，那么会得到一条有序的键列。 public class BST&lt;Key extends Comparable&lt;Key&gt;， Value&gt;{ private Node root; //二叉查找树的根结点 private class Node{ private Key key; private Value val; private Node left， right; private int N; public Node(Key key， Value val， int N){ this.key = key; this.val = val; this.N = N; } } public int size(){ return size(root); } private int size(Node x){ if (x == null) return 0; else return x.N; } public Value get(Key key){} public void put(Key key， Value val){} } 用递归的方法查找: 1️⃣ 如果树是空的，则查找未命中；2️⃣ 如果被查找的键和根结点的键相等，查找命中； 3️⃣ 如果被查找的键小于根结点的键，我们就递归地在左子树中查找；4️⃣ 如果被查找的键大于根结点的键，我们就递归地在右子树中查找。 插入：如果树是空的，就返回一个含有该键值对的新结点；如果被查找的键小于根结点的键，我们就继续在左子数中插入该键，否则在右子树中插入该键。 public Value get(Key key){ return get(root， key); } private Value get(Node x， Key key){ if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left， key); else if (cmp &gt; 0) return get(x.right， key); else return x.val; } public void put(Key key， Value val){ root = put(rppt， key， val); } private Node put(Node x， Key key， Value val){ // 如果key存在于以x为根结点的子树中则更新它的值；否则以key和val为键值对的新结点插入到该子树中 if (x == null) return new Node(key， val， 1); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left， key， val); if (cmp &gt; 0) x.right = put(x.right， key， val); else x.val = val; x.N = size(x.left) + size(x.right) + 1; return x; } 递归调用前的代码想象成沿着树向下走，递归调用后的代码想象成沿着数上爬。 在由NNN个随机键构造的二叉查找树中，查找命中平均所需的比较次数为∼2lnN\\sim 2lnN∼2lnN(约1.39lgN1.39lgN1.39lgN)；插入操作和查找为未命中平均所需的比较次数为∼2lnN\\sim 2lnN∼2lnN(约1.39lgN1.39lgN1.39lgN)。 如果根结点的左链接为空，那么一颗二叉查找树中最小的键就是根结点；如果根结点的左链接非空，那么树中的最小键就是左子树中的最小键；最大键类似。 如果给定的键key小于二叉查找树的根结点的键，那么小于等于key的最大键floor(key)一定在根结点的左子树中；如果给定的键key大于二叉查找树的根结点，那么只有当根结点右子树中存在小于等于key的结点时，小于等于key的最大键才会出现在右子树中，否则根结点就是小于等于key的最大键。大于等于key的最小键ceiling(key类似)。 public Key min(){ return min(root).key; } private Node min(Node x){ if (x.left == null) return x; return min(x.left); } public Key floor(Key key){ Node x = floor(root， key); if (x == null) return null; return x.key; } private Node floor(Node x， Key key){ if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x; if (cmp &lt; 0) return floor(x.left， key); Node t = floor(x.right， key); if (t != null) return t; else return x; } 排名也是递归实现的: 1️⃣ 如果给定的键和根结点的键相等，返回左子树的结点总数t；2️⃣ 如果给定的键小于根结点，返回该键在左子树中的排名；3️⃣ 如果给定的键大于根结点，返回t+1加上它在右子树中的排名。 /*二叉查找树中select()和rank()方法的实现*/ public Key select(int k){ return select(root， k).key; } private Node select(Node x， int k){ // 返回排名为K的结点 if (x == null) return null; int t = size(x.left); if (t &gt; k) return select(x.left， k); else if (t &lt; k) return select(x.right， k-t-1); else return x; } public int rank(Key key){ return rank（key， root); } private int rank(Key key， Node x){ // 返回以x为根结点的子树中小于x.key的键的数量 if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key， x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key， x.right); else return size(x.left); } 删除操作通过将x替换为它的后继结点(其右子树中的最小结点)完成。1️⃣ 将指向即将被删除结点的链接保存为t; 2️⃣ 将x指向它的后继结点min(t.right); 3️⃣ 将x的右链接指向删掉后继结点的原右子树; 4️⃣ 将x的左链接设为t.left; 5️⃣修改结点计数器的值。 public void deleteMin() { root = deleteMin(root); } private Node deleteMin(Node x) { if (x.left == null) return x.right; x.left = deleteMin(x.left); x.size = size(x.left) + size(x.right) + 1; return x; } public void deleteMax() { root = deleteMax(root); } private Node deleteMax(Node x) { if (x.right == null) return x.left; x.right = deleteMax(x.right); x.size = size(x.left) + size(x.right) + 1; return x; } public void delete(Key key) { root = delete(root， key); } private Node delete(Node x， Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left， key); else if (cmp &gt; 0) x.right = delete(x.right， key); else { if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; } x.N = size(x.left) + size(x.right) + 1; return x; } 使用中序遍历来进行范围查找，将符合条件的键放入一个队列，跳过不可能符合条件的子树。 public Iterable&lt;Key&gt; keys(){ return keys(min()， max()); } public Iterable&lt;Key&gt; keys(Key lo， Key hi){ Queue&lt;Key&gt; queue = new Queue&lt;Key&gt;(); keys(root， queue， lo， hi); return queue; } private void keys(Node x， Queue&lt;Key&gt; queue， Key lo， Key hi){ if (x == null) return; int cmplo = lo.compareTo(x.key); int cmphi = hi.compareTo(x.key); if (cmplo &lt; 0) keys(x.left， queue， lo， hi); if (cmplo &lt;= 0 &amp;&amp; cmphi &gt;= 0) queue.enqueue(x.key); if (cmphi &gt; 0) keys(x.right， queue， lo， hi); } 在一棵二叉查找树中，所有操作在最坏情况下所需的时间都和树的高度成正比。因此在某些场景下二叉查找树是不可接受的。 3.3 平衡查找树 2-3查找树:一棵2-3查找树或为一棵空树，或由以下结点组成：1️⃣ 2-结点:含有一个键和两条链接，左链接指向的2-3树中的键都小于该结点，右链接指向的2-3树中的键都大于该结点。3️⃣ 3-结点:含有两个键和三条链接，左链接指向的2-3树中的键都小于该结点，中链接指向的2-3树中的键都位于该结点的两个键之间，右链接指向的2-3树中的键都大于该结点。 一棵完美平衡的2-3查找树中的所有空链接到根结点的距离都应该是相同的。 2-3树的查找：先将键和根结点中的键比较，如果它和其中任意一个相等，查找命中，否则根据比较的结果找到指向相应区间的链接，并在其指向的子树中递归地继续查找，如果是空链接则查找未命中. 2-3树的插入：2-3树应该在插入后继续保持平衡.我们先进行一次未命中的查找，1️⃣ 如果结束于2-结点，就将要插入的键保存在其中，把这个2结点替换为一个3结点；2️⃣ 如果结束于根3-结点，就临时将新键存入该结点，使之成为4-结点，再把中键变为根结点，最小键变为它的左子树，最大键变为它的右子树，树高加一；3️⃣ 如果结束于父结点为2-结点的3-结点，先使其成为4-结点，再把中键移动到父结点中，最小键变为它的左子树，最大键变为它的右子树；4️⃣ 如果结束于父结点为3-结点的3-结点，先使其成为4-结点，再把中间键插入到它的父结点中，此时父结点也为一个4-结点，在这个结点上进行相同的变换，一直向上直到遇到2-结点或根结点。 在一颗2-3树中分解一个4-结点的情况汇总： 2-3树是由下向上生长的，因为插入后始终保持平衡，所以即使在最坏情况下插入和查找的时间复杂度也为O(lgN)。2-3树的缺点是具有两种类型的结点，因此需要大量代码实现和维护，额外开销很大 **红黑二叉查找树(红黑树)**是用来实现2-3树的一种简单的数据结构。它的基本思想是用标准的二叉查找树和一些额外的信息来表示2-3树。树中的链接被分为两种类型：黑链接是普通链接，红链接将两个2-结点连接起来构成一个3结点。 将红链接画平时，一颗红黑树就是一颗2-3树。 红黑树的另一种定义是含有红黑链接并满足下列条件的二叉查找树，满足这样定义的红黑树和相应的2-3树是一一对应的：1️⃣ 红链接均为左链接；2️⃣ 没有任何一个结点同时和两条红链接相连；3️⃣ 该树是完美黑色平衡的，即任意空链接到根结点的路径上的黑链接数量相同。 红黑树既是二叉查找树，也是2-3树(将由红链接相连的结点合并)，所以能够同时实现二叉查找树中简洁高效的查找方法和2-3树中高效的平衡插入算法。 旋转：如果出现了红色右链接或两条连续的红链接，就需要旋。.左旋转右链接也就是将两个键中较大者的左结点变为较小者的右结点，并将较大者作为根结点，较小者作为它的左结点。右旋转只需将左旋转中的左右对调即可。 /*左旋转h的右链接*/ Node rotateLeft(Node h){ Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } /*右旋转h的左链接*/ Node rotateRight(Node h){ Node x = h.left; h.left = x.right; x.right = h; x.color = h.color; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } 插入新键的几种情况： 1️⃣ 向单个2-结点或树底部的2-结点插入新键：如果新键小于老键，新增一个红链接的结点即可。如果新键大于老键，新增的结点会产生一条红色的右链接，将其左旋转。 2️⃣ 向3-结点插入大于两个键的新键：新键被连接到3-结点的右链接，直接将3-结点的两条链接都由红变黑，就得到了一棵由3个结点组成的平衡树。 3️⃣ 向3-结点插入小于两个键的新键：新键被连接到最左边的空链接，即产生了两条连续的红链接，只需将上层的红链接右旋转即可变为情况2。 4️⃣ 向3-结点插入介于两个键之间的新键：此时产生一左一右两条连续的红链接，只需将下层的红链接左旋转即可变为情况3。 颜色转换：用于将子结点的颜色由红变黑，父结点的颜色由黑变红。 void flipColors(Node h){ h.color =RED; h.left.color = BLACK; h.right.color = BLACK; } 每次插入后都要将根结点设为黑色， 当根结点由红变黑时树的黑链接高度加1。 插入: 如果右子结点是红色的而左子结点是黑色的，进行左旋转 如果左子结点是红色的且它的左子结点也是红色的，进行右旋转 如果左右子结点均为红色，进行颜色转换 不断地将红链接由中间键传递给父结点，直至遇到一个2-结点或根结点时，插入就完成了 public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;， Value&gt;{ private Node root; public void put(Key key， Value val){ root = put(root， key， val); root.color = BLACK; } private Node put(Node h， Key key， Value val){ if (h==null){return new Node(key， val， 1， RED);} int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left， key， val); else if (cmp &gt; 0) h.right = put(h.right， key， val); else h.val = val; if (isRed(h.right) &amp;&amp; ! isRed(h.left)) h = rotateLeft(h); if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); h.N = size(h.left) + size(h.right) + 1; retrun h; } } 红黑树查找，插入，删除和范围查询的时间复杂度在最坏情况下都为O(lgN) 3.4散列表 使用散列表的查找算法分为两步。第一步是用散列函数将被查找的键转化为数组的一个索引，第二步是处理碰撞冲突(多个键散列到相同索引值的情况)。 常用散列方法：1️⃣ 正整数：散列最常用的方法是除留余数法。选择大小为素数M的数组，对于任意正整数k，计算k除以M的余数；2️⃣ 浮点数：表示为二进制数然后再使用除留余数法；3️⃣ 字符串：将每位字符表示为一个整数，然后一个比任何字符的值都大的数R来将字符串转化为一个R进制值，再在每一步用除留余数法； 4️⃣ 组合键:类似于字符串，将组合值用R进制表示并在每一步用除留余数法。 Java 令所有数据类型都继承了一个能够返回一个32比特整数的hashCode( )方法。如果两个对象的hashCode( )方法返回值不同，那么这两个对象是不同的。但如果两个对象的hashCode( ) 方法返回值相同，这两个对象也可能不同，还需要用**equals( )**方法判断。 拉链法：将大小为M的数组中的每个元素指向一条链表，链表中的每个结点都存储了散列值为该元素的索引的键值对。基本思想是选择足够大的M，使得所有链表都尽可能短。查找分两步：1️⃣ 根据散列值找到对应的链表；2️⃣ 沿着链表顺序查找相应的键。 public class SeparateChainingHashST&lt;Key， Value&gt;{ private int N; //键值对总数 private int M; //散列表大小 private SequentialSearchST&lt;Key， Value&gt;[] st; //存放链表对象的数组； public SeparateChainingHashST(){ this(997); } public SeparateChainingHashST(int M){ this.M = M; //创建M条链表； st = (SequentialSearchST&lt;Key，Value&gt;[]) new SequentialSearchST[M]; for (int i = 0; i &lt; M; i++) st[i] = new SequentialSearchST(); } private int hash(Key key){ return (key.hashCode() &amp; 0x7fffffff) % M;)//屏蔽符号位，32位整数变为32位非负整数 } public Value get(Key key){ return (Value) st[hash(key)].get(key); } public void put(Key key， Value val){ st[hash(key)].put(key， val); } } 在一张含有M条链表和N个键的散列表中，未命中查找和插入的时间复杂度是O(N/M)。 散列后键的顺序信息丢失了。所以散列表不适合用来寻找最值或范围查找。 依靠数组中的空位解决碰撞冲突的方法叫开放地址散列表。其中最简单的是线性探测法：当碰撞发生时，检查散列表中的下一个位置，直到命中或遇到空元素为止。 public class LinearProbingHashST&lt;Key， Value&gt;{ private int N; //符号表中键值对的总数 private int M = 16; //线性探测表的大小； private Key[] keys; //键 private Value[] vals; //值 public LinearProbingHashST(){ keys = (Key[]) new Object[M]; vals = (Value[]) new Object[M]; } private int hash(Key key){ return (key.hashCode() &amp; 0x7fffffff) % M; // 去除符号位 } public void put(key key， Value val){ if (N &gt;= M/2) resize(2*M); int i; for (i = hash(key); keys[i] != null; i = (i+1)%M) if (keys[i].equals(keys=)) {vals[i] = val; return;} //存在就更新 keys[i] = key; vals[i] = val; //不存在就插入 N++; } public Value get(Key key){ for (int i = hash(key); keys[i] != null; i=(i+1) % M){ if (keys[i].equals(key)) return vals[i]; return null; } } } 当散列表快满时查找所需的探测次数是巨大的，但当使用率 α\\alphaα 小于 1/2 时探测的预计次数只在1.5到2.5之间。 开放地址散列表的删除除了将该键所在位置置为null，还需要将被删除键右侧的所有键重新插入散列表，以防之后的元素无法被查找。 public void delete(Key key){ if (!contains(key)) return; int i = hash(key); while (!key.equals(keys[i])) i = (i+1) % M; keys[i] = null; vals[i] = null; i = (i+1) % M; while (keys[i] != null){ Key keyToRedo = keys[i]; Value valToRedo = vals[i]; keys[i] = null; vals[i] = null; N--; put(keyToRedo， valToRedo); i = (i+1) % M; } N--; if (N &gt; 0 &amp;&amp; N == M/8) resize(M/2); } 元素在数组中聚集成的一组连续的条目叫键簇，为了保证性能，应该使键簇尽可能短小。可以证明数组的使用率应该在1/8~1/2之间，所以在每次插入元素前和删除元素后都需动态调整大小。 问：为什么不将 hash(x) 实现为 x.hashCode( ) % M ? 答：散列值必须在0到M-1之间，而在Java中，取余(%)的结果可能是负数；如果用 **Math.abs( )**对于最大的整数会返回一个负值。 3.5 应用 各种符号表实现的渐进性能的总结 相对于二叉查找树，散列表的优点是代码更简单，且查找时间最优。二叉查找树相对于散列表的优点在于抽象结构更简单，红黑树可以保证最坏情况下的性能且支持的操作更多（如排名、选择、排序和范围查找）。 使用put操作构造一张符号表以备get查询，这种应用叫做字典 一个键和多个值相关联的符号表叫做索引。用值来查找键的操作叫做反向索引. 使用散列表表示稀疏矩阵可以大大提高矩阵与向量相乘的效率。它所需的时间和N+非零元素成正比，而用数组表示的话则为$N^2 $ ，N为矩阵的尺寸。 chapter 4 图 4.1 无向图 图是由一组顶点和一组能够将两个顶点相连的边组成的，一般用0至V-1表示一张含有V个顶点的图中的各个顶点，用v-w或w-v表示连接v和w的边。边仅仅是两个顶点之间的连接的图称为无向图。 一条连接一个顶点和其自身的边称为自环。连接同一对顶点的两条边称为平行边。一般将含有平行边的图称为多重图，将没有平行边或自环的图称为简单图。 某个顶点的度数即为依附于它的边的总数。子图是由一幅图的所有边的一个子集组成的图。 路径是由边顺序连接的一系列顶点。简单路径是一条没有重复顶点的路径。 环是一条至少含有一条边且起点和终点相同的路径。简单环是一条不含有重复顶点和边的环。 如果从任意一个顶点都存在一条路径到达另一个任意顶点，那么这幅图是连通图。 图的密度是指已经连接的顶点对斩所有可能被连接的顶点对的比例，由此分出稀疏图和稠密图。 二分图是一种能够将所有结点分为两部分的图，其中图的每条边所连接的两个顶点都分别属于不同的部分。 一般采用邻接表数组来表示图。它将每个顶点的所有相邻顶点都保存在该顶点对应的元素所指向的一张链表中。它使用的空间和V+E成正比。添加一条边所需的时间为常数。遍历顶点v的所有相邻顶点所需的时间和v的度数成正比。 深度优先搜索(DFS)是搜索连通图的经典递归算法，所需的时间和顶点的度数之和成正比。使用的是栈: 在访问其中一个顶点时将它标记为已访问 递归地访问该顶点的所有没有被标记过的邻居顶点 广度优先搜索(BFS)是解决单点最短路径的经典算法，它所需的时间在最坏情况下和V+E成正比。使用的是队列，先将起点加入队列，重复以下步骤直到队列为空: 将与v相邻的所有未被标记过的顶点加入队列，删除v 取队列中的下一个顶点v并标记它 DFS和BFS的区别在于DFS总是获取最晚加入的顶点，而BFS总是获取最早加入的结点。 DFS更适合实现图的抽象数据类型，因为它能更有效地利用已有的数据结构。而union-find算法适合于只需要判断连通性的任务。 利用一个符号表保存字符和索引，一个数组保存反向索引和一张图就可以实现符号图。 4.2 有向图 一幅有向图是由一组顶点和一组有方向的边组成的，每条有方向的边都连接着有序的一对顶点。在有向图中，一个顶点的出度为由该顶点指出的边的总数;一个顶点的入度为指向该顶点的边的总数。用v→w表示有向图中一条由v指向w的边。 有向路径由一系列顶点组成，对于其中的每个顶点都存在一条有向边从它指向序列中的下一个顶点。有向环为一条至少含有一条边且起点和终点相同的有向路径。简单有向环是一条不含有重复的顶点和边的环。 和无向图类似，一般使用邻接表来表示有向图，用顶点v所对应的邻接链表中包含一个w顶点来表示边v→w。每条边都只会在其中出现一次。DFS和BFS同样可用于有向图。 拓扑排序:给定一幅有向图，将所有的顶点排序，使得所有的有向边均从排在前面的元素指向排在后面的元素。即有优先级限制下的调度问题。当且仅当一幅有向图是无环图时它才能进行拓扑排序。 有向无环图(DAG)是一幅不含有环的有向图。想要进行有向环检测，可以基于DFS，一旦找到一条边v→w且w已经存在于栈中，就找到了一个环。 DFS遍历一幅图以后，有以下三种排列顺序: 前序:在递归调用之前将顶点加入队列，即dfs()的调用顺序 后序:在递归调用之后将顶点加入队列，即顶点遍历完成的顺序 逆后序:在递归调用之后将顶点压入栈，即这幅图的拓扑排序(如果是有向无环图) 如果两个顶点v和w是互相可达的，则称它们为强连通的。如果一幅有向图中的任意两个顶点都是强连通的，则称这幅有向图也是强连通的。两个顶点是强连通的当且仅当它们都在一个普通的有向环中。 通常用Kosaraju算法来计算强连通分量: 在给定的一幅有向图G中，计算它的反向图的逆后序排列 在G中进行DFS，但是要按照1得到的顺序来访问所有未被标记的顶点 所有在同一个递归DFS调用中被访问到的顶点都在同一个强连通分量中 4.3 最小生成树 加权图是一种为每条边关联一个权值或是成本的图模型。 图的生成树是它的一棵含有其所有顶点的无环连通子图。一幅加权无向图的**最小生成树(MST)**是它的一棵权值最小的生成树。 在计算最小生成树时，做以下约定: 只考虑连通图 边的权重不一定表示距离 边的权重可能是0或者负数 所有边的权重都各不相同 树的两个重要性质: 用一条边连接树中的任意两个顶点都会产生一个新的环 从树中删去一条边将会得到两颗独立的树 图的一种切分是将图的所有顶点分为两个非空且不重复的两个集合。横切边是一条连接两个属于不同集合的顶点的边。 切分定理:在一幅加权图中，给定任意的切分，它的横切边中的权重最小者必然属于图的最小生成树。 切分定理是解决最小生成树问题的所有算法的基础。这些算法都是一种贪心算法的特殊情况。即找到一种切分，它产生的横切边均不为黑色，将它权重最小的横切边标记为黑色，直到标记了V-1条黑色边为止。不同之处在于保存切分和判定权重最小的横切边的方式。 同样可以使用邻接表来表示加权无向图，只需要增加一个权重域。 Prim算法: 一开始最小生成树只有一个顶点，然后会向它添加V-1条边。每次总是将下一条连接树顶点与非树顶点且权重最小的边加入树中。每一步总是为一棵树添加一条边。 使用优先队列来根据权重比较所有边 分为延时实现和即时实现。区别在于是否立即删除失效的横切边(即连接新加入的顶点和树中已有顶点之间的边)。 延时实现所需空间与E成正比，所需时间与ElogE成正比。 即时实现不仅删除失效的边，而是仅保存非树顶点到树顶点的边中权重最小的那条，并在每次加入新顶点后检查是否需要更新。所需空间与V成正比，时间与ElogV成正比。 Kruskal算法: 按照边的权重顺序处理它们，将边加入最小生成树中，加入的边不会与已经加入的边构成环，直到树中含有V-1条边为止。每一步总是连接森林中的两棵树(包括单顶点树)。 在实现中，使用优先队列来将边按照权重排序，使用union-find来识别会形成环的边，以及一条队列来保存最小生成树的所有边。 所需空间与E成正比，所需时间与ElogE成正比。 4.4 最短路径 在一幅加权有向图中，从顶点s到顶点t的最短路径是所有从s到t的路径中的权重最小者。 **最短路径树(SPT)**包含了顶点s到所有可达的顶点的最短路径 边v-&gt;w的松弛是指检查从顶点s到w的最短路径是否是先从s到v，然后再由v到w，即。如果是，则更新，如果不是，则称这条边失效了。 顶点的松弛是指对该顶点指出的所有边进行松弛。 最优性条件:当且仅当对于从v到w的任意一条边e，这些值都满足distTo[w]&lt;=distTo[v]+e。weight()时它们是最短路径的长度。这证明了判断是否为最短路径的全局条件与松弛时检测的局部条件是等价的。 通用最短路径算法:放松图中的任意边，直到不存在有效边为止。 Dijkstra算法(注意只能解决正权重的加权有向图中的最短路径问题): 首先将distTo[s]初始化为0，distTo[]中的其他元素初始化为起点s到该顶点的距离，注意如果不相邻则为正无穷。 然后将distTo[]最小的非树顶点松弛并加入树中 重复2，直到所有的顶点都在树中或者所有的非树顶点的distTo[]值均为无穷大。 按照拓扑顺序放松顶点，就能在和E+V成正比的时间内解决无环加权有向图的单点最短路径问题。同理，要解决无环加权有向图的最长路径问题，只需将原图中所有边的权重变为负值，再求最短路径即可。 当且仅当加权有向图中至少存在一条从s到v的有向路径且该路径上的任意顶点都不存在于任何负权重环中时，s到v的最短路径才是存在的。 数据结构--Dijkstra算法最清楚的讲解 https://blog.csdn.net/heroacool/article/details/51014824 它的主要特点是以起始点为中心向外层层扩展(广度优先搜索思想)，直到扩展到终点为止 基本思想 通过Dijkstra计算图G中的最短路径时，需要指定起点s(即从顶点s开始计算)。此外，引进两个集合S和U。S的作用是记录已求出最短路径的顶点(以及相应的最短路径长度)，而U则是记录还未求出最短路径的顶点(以及该顶点到起点s的距离)。 初始时，S中只有起点s；U中是除s之外的顶点，并且U中顶点的路径是”起点s到该顶点的路径”。然后，从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 然后，再从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 … 重复该操作，直到遍历完所有顶点。 操作步骤：1️⃣ 初始时，S只包含起点s；U包含除s外的其他顶点，且U中顶点的距离为”起点s到该顶点的距离”[例如，U中顶点v的距离为(s,v)的长度，然后s和v不相邻，则v的距离为∞]。2️⃣ 从U中选出”距离最短的顶点k”，并将顶点k加入到S中；同时，从U中移除顶点k。3️⃣ 更新U中各个顶点到起点s的距离。之所以更新U中顶点的距离，是由于上一步中确定了k是求出最短路径的顶点，从而可以利用k来更新其它顶点的距离；例如，(s,v)的距离可能大于(s,k)+(k,v)的距离。4️⃣ 重复步骤(2)和(3)，直到遍历完所有顶点。 #dijkstra算法实现，有向图和路由的源点作为函数的输入，最短路径最为输出 def dijkstra(graph,src): # 判断图是否为空，如果为空直接退出 if graph is None: return None nodes = [i for i in range(len(graph))] # 获取图中所有节点 visited=[] # 表示已经路由到最短路径的节点集合 if src in nodes: visited.append(src) nodes.remove(src) else: return None distance={src:0} # 记录源节点到各个节点的距离 for i in nodes: distance[i]=graph[src][i] # 初始化 # print(distance) path={src:{src:[]}} # 记录源节点到每个节点的路径 k=pre=src while nodes: mid_distance=float('inf') for v in visited: for d in nodes: new_distance = graph[src][v]+graph[v][d] if new_distance &lt; mid_distance: mid_distance=new_distance graph[src][d]=new_distance # 进行距离更新 k=d pre=v distance[k]=mid_distance # 最短路径 path[src][k]=[i for i in path[src][pre]] path[src][k].append(k) # 更新两个节点集合 visited.append(k) nodes.remove(k) print(visited,nodes) # 输出节点的添加过程 return distance,path if __name__ == '__main__': graph_list = [ [0, 2, 1, 4, 5, 1], [1, 0, 4, 2, 3, 4], [2, 1, 0, 1, 2, 4], [3, 5, 2, 0, 3, 3], [2, 4, 3, 4, 0, 1], [3, 4, 7, 3, 1, 0]] distance,path= dijkstra(graph_list, 0) # 查找从源点0开始带其他节点的最短路径 print(distance,path) Bellman-Ford算法: 在任意含有V个顶点的加权有向图中给定起点s，从s无法到达任何负权重环，可以解决其中的单点最短路径问题 将distTo[s]初始化为0，其他distTo[]元素初始化为无穷大，以任意顺序放松有向图的所有边，重复V-1轮 算法所需的时间和EV成正比，空间和V成正比。 套汇问题等价于加权有向图中的负权重环的检测问题。 chapter 5 字符串 5.1 字符串排序 在Java中，String类型的**length( )**方法实现了获取字符串的长度的操作。**substring( )**方法实现了提取特定的子字符串的操作。 字符串排序方法可以分为从右到左检查键中的字符的低位优先(LSD)和从左到右检查键中字符的高位优先(MSD)。 键索引计数法是一种适用于小整数键的简单排序方法，它要求数组a[]中的每个元素都保存一个字符串和一个组号，原来元素是依据字符串排列的，现在希望按组号排列，在组内保持原顺序.键索引计数法排序N个键为0到R-1之间的整数的元素需要访问数组11N+4R+1次。 键索引计数法步骤：1️⃣ 频率统计：使用一个数组count[]计算每个键出现的频率。如果键为r，就将count[r+1]加1。2️⃣ 将频率转换为索引：任意给定的键的起始索引均为所有较小的键所对应的出现频率之和，只需循环count[r+1]+=count[r]这个语句即可转换出一张索引表。3️⃣ 数据分类：有了索引表后，将所有元素移动到一个辅助数组aux[]中进行排序。每次移动后将count[]中对应元素的值加1，这保证了这种排序的稳定性。4️⃣ 回写：将排序结果复制回原数组中。 int N = a.length; String[] aux = new String[N]; int[] count = new int[R+1]; // 计算出现频率 for (int i = 0; i &lt; N; i++) count[a[i].key() + 1]++; //将频率转换为索引 for (int r = 0; r &lt; R; r++) count[r+1] += count[r]; //将元素分类 for (int i = 0; i &lt; N; i++) aux[count[a[i].key()]++] = a[i]; //回写 for (int i = 0; i &lt; N; i++) a[i] = aux[i]; 低位优先的字符串排序(LSD)：将等长字符串(假设长度为W)排序可以通过从右向左以每个位置的字符作为键，用键索引计数法将字符串排序W次实现。这依赖于键索引计数法的稳定性。对于基于R个字符的字母表的N个以长为W的字符串为键的元素，LSD需要访问~7WN+3WR次数组。因为实际中R&lt;&lt;N，因此LSD算法的时间是O(WN)。 public class LSD{ public static void sort(String[] a, int w){ // 通过前W个字符将a[]排序 int N = a.length; int R = 256; String[] aux = new String[N]; for (int d = w-1; d &gt;= 0; d--){ int[] count = new int[R+1]; //根据第d个字符用键索引计数法排序 for (int i = 0; i &lt; N; i++) count[a[i].charAt(d) + 1]++; // 计算出现频率 for (int r = 0; r &lt; R; r++) count[r+1] += count[r]; //将频率转换为索引 for (int i = 0; i &lt; N; i++) aux[count[a[i].charAt(d)]++] = a[i]; //将元素分类 for (int i = 0; i &lt; N; i++) a[i] = aux[i]; //回写 } } } 高位优先的字符串排序(MSD)：首先用键索引计数法将所有字符串按照首字母排序，然后再递归地将每个首字母所对应的子数组排序(忽略首字母)。对于MSD来说，将小数组切换到插入排序对于高位优先的字符串排序算法是必须的，另外它无法很好的处理等值键。对于基于R个字符的字母表的N个平均长度为w的字符串，MSD需要访问8N+3R到7wN+3wR之间次数组。 public class MSD{ private static int R = 256; private static final int M = 15; //小数组的切换阈值 private static String[] aux; private static int charAt(String s,int d){ if (d &lt; s.lengtg()) return s.charAt(d);else return -1; } public static void sort(String[] a){ int N = a.length; aux = new String[N]; sort(a, 0, N-1, 0); } private static void sort(String[] a, int lo, int hi, int d){ //以第d个字符为键将a[lo]至a[hi]排序 if (hi &lt;= lo + M){ Insertion.sort(a, lo, hi, d); return; } int[] count = new int[R+2]; for (int i = lo; i &lt;= hi; i++) count[charAt(a[i], d) + 2]++; for (int r = 0; r &lt; R+1; r++) count[r+1] += count[r]; for (int i = lo; i &lt;= hi; i++) aux[count[charAt(a[i], d) + 1]++] = a[i]; for (int i = lo; i &lt;= hi; i++) a[i] = aux[i - lo]; for (int r = 0; r &lt; R; r++) sort(a, lo+count[r], lo+count[r+1]-1, d+1); } } 三向字符串快速排序:根据键的首字母进行三向切分，仅在中间子数组的中的下一个字符继续递归排序.它能够很好地处理等值键，有较长公共前缀的键，取值范围较小的键和小数组.另外它不需要额外的空间. 5.2 单词查找树 单词查找树(trie树)的每个结点都有R条链接，R为字母表的大小。但是一般其中都含有大量的空链接，可以被忽略。每条链接都对应着一个字符，每个键所关联的值保存在该键的最后一个字母所对应的结点中。 查找给定字符串键所对应的值的方式就是从根结点开始检查某条路径上的所有结点，这意味着到达树中表示尾字符的结点或者一个空链接。插入之前需要先进行一次查找，如果遇到了空链接则为键中还未被检查的每个字符创建一个对应结点，如果到达了尾字符结点则将该结点的值设为要插入的键所对应的值。 单词查找树的结点是一个值和大小为R的数组构成的。将基于含有R个字符的字母表的单词查找树称为R向单词查找树。 可以用递归的方法查找所有键，方法的参数是结点和该结点关联的字符串。如果一个结点的值非空，就将它相关联的字符串加入队列，然后递归访问它的链接数组所指向的所有可能的字符结点。 要删除一个键值对，先找到键所对应的结点并将它的值设为空，如果它有指向子结点的非空链接则删除结束，如果它的所有链接均为空就从数据结构中删去这个结点，再检查它的父结点的所有链接是否为空。 对于任意给定的一组键，单词查找树都是唯一的。查找需要访问数组的次数最多是键的长度加1。未命中查找平均所需检查的结点数量为(logR)N。树中的链接总数在RN到RNw之间。 三向单词查找树:用来避免R向单词查找树过度的空间消耗.每个结点都含有一个字符，三条链接和一个值。三条链接对应着当前字母小于，等于和大于结点字母的所有键。所需的空间在3N到3Nw之间。查找未命中平均需要比较字符~lnN次。 5.3 子字符串查找 子字符串查找问题：给定一段长度为N的文本和一个长度为M的模式字符串，在文本中找到一个和该模式相符的子字符串。一般来说M相对于N是很小的。 暴力子字符串查找算法就是遍历文本字符串，如果某字符和模式的第一个字符匹配则移动指向模式的指针，否则移动指向文本的指针。这种方法在最坏情况下需要**~NM**次字符比较(例如二进制文本)。 KMP子字符串查找算法(注:书中用确定有限状态自动机DFA的思想来讲解，个人感觉不好理解，本文用了大一学数据结构时的解释方法): 基本思想:当出现不匹配时，就能知晓一部分文本的内容，可以利用这些信息避免将指针回退到所有已知字符之前。 预处理:根据模式计算出一个转移数组next[].其中next[0]=-1，next[1]=0，next[j]表示模式字符串中第0位到第j-1位中相同的最长前缀和最长后缀的长度。next数组可以用模式匹配的思想编程得到。 发生不匹配:目标串的指针不变，若next[j]&gt;=0，则将模式字符串右移j-next[j]位个字符，用模式的第next[j]个字符与文本的第i个字符比较.若next[j]=-1，则将模式字符串右移j+1个字符，用第0个字符与文本的第i+1个字符比较。 优化:如果根据next数组回退之后的位置的字符和现有字符相同，则必定是不匹配，仍要继续回退，因此建立nextval数组，将重复字符的回退位置都设为第一个该字符的回退位置. KMP算法适用于在重复性很高的文本中查找重复性很高的模式，它访问的字符不会超过M+N个. Boyer-Morre字符串查找算法: 使用数组right[]记录字母表中的每个字符在模式中出现的最靠右的地方，不存在则为-1.含义是如果该字符出现在文本中且在查找时造成了一次匹配失败，模式应该向右跳跃多远. 如果造成匹配失败的字符不包含在模式中，则将模式字符串向右移动j+1个位置 如果包含在模式字符串中，则将模式向右移动j-right['char'] 如果这种方式无法增大i，就将i加1 一般情况下，Boyer-Moore需要**~N/M**次字符比较. Rabin-Karp指纹字符串查找算法: 基本思想:这是一种基于散列的算法.长度为M的字符串对应着一个R进制的M位数，将该数除以一个随机的素数Q并取余就可以将它保存在大小为Q的散列表中. 计算散列函数:在文本中将子字符串右移一位，对应的M位数操作就是将它减去第一个数字的值，乘上R，再加上最后一个数字的值.又因为在每次算数操作之后取余等价于在所有算数操作完成后取余，因此只需对上述操作的每一步先取余就可以得到下一位的子字符串的散列值. 技巧:为了避免有多个子字符串有相同散列值，可以将Q设为一个大于1020的值，这样冲突的概率将小于10-20. 5.4 正则表达式 正则表达式就是按照某种模式进行字符匹配的表达式。书中使用语言指代一个字符串的集合.模式的描述由连接，或(|)，**闭包(*)**三种基本操作构成。 字符集描述集用于简化正则表达式 闭包的简写 .|*()是用来构造正则表达式的元字符，因此要用\\开头的转义字符来表示 正则表达式模拟匹配程序的总体结构是:构造和给定正则表达式相对应的非确定有限状态自动机(NFA)，模拟NFA在给定文本上的运行轨迹. NFA有以下特点: 长度为M的正则表达式中的每个字符在对应NFA中有且只有一个对应状态，NFA起始状态为0，并有一个虚拟的接受状态M 字母表中的字符所对应的状态都有一条指向模式中的下一个字符对应状态的黑边. 元字符所对应的状态至少有一条指出的红边，可能指向任意状态 NFA的状态转换: 匹配转换:如果文本中的当前字符和当前字母表中的字符匹配，NFA可以扫过文本中的字符并由黑边转换到下一个状态 ε转换:NFA可以通过红边转换到另一个状态而不扫描文本中的字符 使用长度为M+1的数组来保存正则表达式本身，这个数组也表示了匹配转换.使用有向图来表示ε转换.首先查找所有从状态0通过ε转换可达的状态来初始化可达性集合，然后如果有字符匹配了集合中的状态，就将集合改为这个字符通过匹配转换后到达的状态，再加上这些状态通过ε转换可达的状态. 判定一个长度为M的正则表达式所对应的NFA能否识别一段长度为N的文本所需的时间在最坏情况下和NM成正比.构造对应的NFA所需的时间和空间在最坏情况下与M成正比 5.5 数据压缩 现代计算机系统中的所有类型的数据都是用二进制表示的.用比特流表示比特的序列，用字节流表示可以看作固定大小的字节序列的比特序列. 数据压缩的基础模型由压缩盒(将比特流B转化为压缩版本C(B))和展开盒(将C(B)转化回B)组成，用|B|表示比特流中比特的数量，则C(B)/|B||称为压缩率.这种模型叫做无损压缩模型.常用于数值数据或可执行代码的压缩. 不存在能够压缩任意比特流的算法，因此无损压缩算法必须尽量利用被压缩的数据流中的已知结构(小规模字母表，较长的连续相同的位或字符，频繁使用的字符，较长的连续重复的位或字符). **游程编码(RLE)**的基本原理是用长度代替具有相同值的连续符号，连续符号构成了一段连续&quot;游程&quot;.适用于含有较长游程的数据，比如高分辨率的位图. 霍夫曼压缩的思想是用较少的比特表示出现较频繁的字符，它是一种前缀码(所有字符编码都不会成为其他字符编码的前缀).构造霍夫曼树的过程是:先找到频率最小的两个结点，然后创造一个以两者为子结点且频率为两者之和的新结点，不断重复这个过程知道所有结点被合并为一棵单词查找树. LZW压缩算法是为变长模式生成一张定长的符号表: 找出未处理的输入在符号表中最长的前缀字符串s 输出s的编码 继续扫描s之后的一个字符c 在符号表中将s+c的值设为下一个编码值 ","link":"https://Angus1996.github.io/post/lesslesssuan-fa-4th-editiongreatergreater-xue-xi-bi-ji/"},{"title":"CCF BDCI 2019 多人种人脸识别比赛总结","content":"✨ 背景介绍 CCF大数据与计算智能大赛（CCF Big Data &amp; Computing Intelligence Contest，简称CCF BDCI）是由中国计算机学会大数据专家委员会于2013年创办的国际化智能算法、创新应用和大数据系统大型挑战赛事，是全球大数据与人工智能领域最具影响力的活动之一。2019 CCF大数据与计算智能大赛由教育部高等学校计算机类专业教学指导委员会、国家自然科学基金委员会信息科学部及郑州市人民政府指导，中国计算机学会主办，郑州市郑东新区管理委员会、教育部易班发展中心、CCF大数据专家委员会、大洋洲计算机研究与教育协会、数联众创承办。 人脸识别已经在生活中快速的普及开来， 但是人脸识别技术在实际应用中遇到的一个广为人知的问题是它在不同人种的性能有差异。 如何快速的提升人脸识别系统在不同人种的性能， 是一个实用的人脸识别算法应该考虑的问题。 😄赛题任务：本次比赛目标是提高人脸识别模型在不同人种上面的性能。以人脸1：1 比对为场景， 参赛队需要同时优化人脸识别模型在不同人种上的性能，提高在低误识率情况下不同人种的通过率。 ⭐️ Our method 虽然比赛提供了训练数据，但是也是允许参赛队伍使用额外公开数据集和预训练模型的。只是使用的时候要在讨论群里艾特所有管理员告知所使用的数据集和预训练模型，并附上链接。 在此次比赛中，尝试过训练模型，奈何显卡不行，而实验室的服务器也是满负荷在跑实验，所以自然是很难重新训练模型了。 所以我们的主要工作就是使用预训练模型并且对图像进行预处理来提高识别准确率🙈。 预训练模型 我们在比赛中用的预训练模型和大多数队伍使用的预训练模型一样，是insightface，模型的Github仓库 http://insightface.ai/ ，主页 http://insightface.ai/ 。这应该目前人脸识别准确率最高的开源模型了。在主页中也提供了一些简单的Demo。 预处理方法 此次比赛有四种人种，而人种的差别主要在肤色在一块。我首先使用了自动gamma校正，然后使用了图像锐化，最后将图像送了预训练的 Insightface 模型获取特征向量。 🐶 值得注意和参考的小trick： 1️⃣ 优先使用 insightface.app.FaceAnalysis() 的分析人脸方法，这个会将人脸关键点提取校正，还会有一些预处理。而 insightface.model_zoo.get_model('arcface_r100_v1') 则是直接对图像获取特征向量了。比如我就是优先使用前者，而对于测试集中无法识别人脸的图像才使用后者。 2️⃣ 一个在讨论区公开分享的trick。先是获取两张图像比较a-b的相似度sim1，然后或者水平翻转后的图像flipa-flipb的相似度sim2，最后计算sim1和sim2的平均值也可以提高得分。 ⚡️具体的代码： generate_mat.py # -*- coding: utf-8 -*- # @Time :2019/10/31 9:30 # @Author :AngusCai import os import cv2 import numpy as np import time import scipy.io as sio from tqdm import tqdm import math import insightface from PIL import Image, ImageEnhance model1 = insightface.app.FaceAnalysis() model1.prepare(ctx_id=0, nms=0.4) model2 = insightface.model_zoo.get_model('arcface_r100_v1') model2.prepare(ctx_id=0) def gamma_trans(img, gamma): # gamma函数处理 &quot;&quot;&quot; :param img: 待处理图像 :param gamma: 伽马变换的幂 :return: 经过伽马变换的图像 &quot;&quot;&quot; gamma_table = [np.power(x / 255.0, gamma) * 255.0 for x in range(256)] # 建立映射表 gamma_table = np.round(np.array(gamma_table)).astype(np.uint8) # 颜色值为整数 return cv2.LUT(img, gamma_table) # 图片颜色查表。另外可以根据光强（颜色）均匀化原则设计自适应算法。 def get_features(test_list, flip=False): &quot;&quot;&quot; :param test_list: 测试图像路径列表 :param flip: 是否水平翻转图像的flag :return: 测试图像的特征矩阵 &quot;&quot;&quot; progress_bar = tqdm(total=len(test_list)) for idx, img_path in enumerate(test_list): progress_bar.update(1) # 自动gamma校正 img_gray = cv2.imread(img_path, 0) # 灰度图读取，用于计算gamma值 img = cv2.imread(img_path) # 原图读取 mean = np.mean(img_gray) gamma_val = math.log10(0.5) / math.log10(mean / 255) # 公式计算gamma image_gamma_correct = gamma_trans(img, gamma_val) # gamma变换 if flip: tmp_result = cv2.flip(image_gamma_correct, 1, dst=None) else: tmp_result = image_gamma_correct # 图像锐化 image = Image.fromarray(cv2.cvtColor(tmp_result, cv2.COLOR_BGR2RGB)) im_30 = ImageEnhance.Sharpness(image).enhance(3.0) result = cv2.cvtColor(np.asarray(im_30), cv2.COLOR_RGB2BGR) # 尝试获取预处理图像中的人脸，检测到人脸，用model1获取特征编码向量；没有检测到人脸就用model2 获取特征编码向量 try: face = model1.get(result) # insightface.app.FaceAnalysis有比较好的人脸对齐实现 if idx == 0: feature = face[0].embedding.reshape(1, 512) features = feature else: feature = face[0].embedding.reshape(1, 512) features = np.concatenate((features, feature), axis=0) except: print(img_path) image = cv2.resize(result, (112, 112)) feature = model2.get_embedding(image) features = np.concatenate((features, feature), axis=0) return features def get_feature_dict(test_list, features): &quot;&quot;&quot; :param test_list: 测试图像路径列表 :param features: 测试图像的特征矩阵 :return: 测试图像路径与特征的字典， key=path, value=feature &quot;&quot;&quot; fe_dict = {} for i, each in enumerate(test_list): fe_dict[each] = features[i] return fe_dict data_dir = '../Baseline/test/' # test_set dir name_list = [name for name in os.listdir(data_dir)] img_paths = [data_dir + name for name in os.listdir(data_dir)] print('Images number:', len(img_paths)) # 生成没有水平翻转的图像向量mat s = time.time() features = get_features(img_paths, flip=False) t = time.time() - s print(features.shape) print('total time is {}, average time is {}'.format(t, t / len(img_paths))) fe_dict = get_feature_dict(name_list, features) print('Output number:', len(fe_dict)) sio.savemat('gamma_sharp3_arcface_app_embedding_test.mat', fe_dict) # 生成水平翻转后图像的向量mat s = time.time() features2 = get_features(img_paths, flip=True) t = time.time() - s print(features2.shape) print('total time is {}, average time is {}'.format(t, t / len(img_paths))) fe_dict2 = get_feature_dict(name_list, features2) print('Output number:', len(fe_dict2)) sio.savemat('gamma_flip_sharp3_arcface_app_embedding_test.mat', fe_dict2) generate_csv.py # -*- coding: utf-8 -*- # @Time :2019/10/31 9:30 # @Author :AngusCai import numpy as np import scipy.io as sio from tqdm import tqdm def cosine_metric(x1, x2): return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2)) def get_sim(x1, x2): return np.dot(x1, x2.T) gamma_sharp3_features = sio.loadmat('gamma_sharp3_arcface_app_embedding_test.mat') print('Loaded gamma_sharp3_features mat') gamma_flip_sharp3_features = sio.loadmat('gamma_flip_sharp3_arcface_app_embedding_test.mat') print('Loaded gamma_flip_sharp3_features mat') sample_sub = open('./submission_template.csv', 'r') # sample submission file dir sub = open('[angusaha]_results.csv', 'w', encoding='utf-8') print('Loaded CSV') lines = sample_sub.readlines() # 获取提交示例中的所有行 progress_bar = tqdm(total=len(lines)) for line in lines: pair = line.split(',')[0] # 获取逗号分隔的要比较的图像对 sub.write(pair + ',') # 将要比较的图像对写入结果文件 a, b = pair.split(':') # 图像对用冒号分隔，获取单独两个的img_name sim1 = cosine_metric(gamma_sharp3_features[a][0], gamma_sharp3_features[b][0]) # a和b的特征向量的余弦相似度 sim2 = cosine_metric(gamma_flip_sharp3_features[a][0], gamma_flip_sharp3_features[b][0]) # flip-a和flip-b的特征向量的余弦相似度 sim = (sim1 + sim2) / 2. # 计算两个相似度之间的平均值 score = '%.5f' % sim # 结果保留5位小数 sub.write(score + '\\n') progress_bar.update(1) sample_sub.close() sub.close() 🏆 名次 这是第一次自己完全参与、正规参加算法比赛。能进入复赛拿到现在的名次还是很开心的。初赛A榜24/897，初赛B榜26/897，复赛A榜23/39，复赛B榜26/39。 🎆 可能有用的思路 在复赛开始后的几天，无意间搜索多人种人脸识别的时候，发现了一篇发表在ICCV 2019的多人种人脸识别方法。作者是北邮的一位老师，他们研究团队还构建了一份用于公平比较各种算法在多人种人脸识别领域的准确度的多人种数据集RFW👍 。 数据集主页 http://www.whdeng.cn/RFW/index.html 。论文 [1] Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, Yaohai Huang. Racial Faces in-the-Wild: Reducing Racial Bias by Information Maximization Adaptation Network. ICCV 2019 。 论文中所使用的迁移学习，在多人种人脸识别这一块确实是表现出色，论文中比较对象也包括了此次比赛被广泛使用的Insightface模型。 或许迁移学习可能就是解决这个赛题的最佳方法，这篇论文的方法值得参考，只是还貌似没有开源代码和训练好的模型。 ","link":"https://Angus1996.github.io/post/ccf-bdci-2019-duo-ren-chong-ren-lian-shi-bie-bi-sai-zong-jie/"},{"title":"pretrained_models库使用","content":"pretrainedmodels 库使用 prtrainedmodels 是一个基于pytorch框架构建的预训练模型使用的库，比官方torchvision中的预训练模型更加丰富。 github项目地址：https://github.com/Cadene/pretrained-models.pytorch 安装 pip install pretrainedmodels 获取所有预训练模型名称 import pretrainedmodels print(pretrainedmodels.model_names) # result &gt; ['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetalarge', 'nasnetamobile', 'cafferesnet101', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'polynet', 'pnasnet5large'] 加载基于imagenet的预训练模型 model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2 model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet') model.eval() 或者 from pretrainedmodels.models.senet import senet154 model = senet154(num_classes=1000) # 自己根据预训练模型路径进行加载 model.load_state_dict(torch.load('../pre-trained_model/senet154-c7b49a05.pth')) 预测 import torch import pretrainedmodels.utils as utils load_img = utils.LoadImage() # transformations depending on the model # rescale, center crop, normalize, and others (ex: ToBGR, ToRange255) tf_img = utils.TransformImage(model) path_img = 'data/cat.jpg' input_img = load_img(path_img) input_tensor = tf_img(input_img) # 3x400x225 -&gt; 3x299x299 size may differ input_tensor = input_tensor.unsqueeze(0) # 3x299x299 -&gt; 1x3x299x299 input = torch.autograd.Variable(input_tensor, requires_grad=False) output_logits = model(input) # 1x1000 微调模型 # fine tuning dim_feats = model.last_linear.in_features nb_classes = 4 model.last_linear = nn.Linear(dim_feats, nb_classes) 直接使用结构 不使用预训练模型的话，也可以直接使用这个模型的结构，根据分类数设置自己最后一层的神经元个数。 model = pretrainedmodels.__dict__['nasnetalarge'](num_classes=54, pretrained=None) ","link":"https://Angus1996.github.io/post/pretrained-models库使用/"},{"title":"Markdown里面的Emoji表情","content":"Markdown里面的Emoji表情 以下复制一些我觉得比较常用的Emoji表情，可以增加博客的趣味性和可观赏性。这些Markdown里支持的表情在Github里面也是支持的😄。 更多可以去 https://www.webfx.com/tools/emoji-cheat-sheet/ 寻找。 markdown里面的Emoji语法是 :name:， 将name替换成Emoji的名字就可以了，旁边是两个英文状态输入的冒号。 Emoji name Emoji name 😄 smile 😃 smiley 😏 smirk 😉 wink 😭 sob 😂 joy 😎 sunglasses 😋 yum 😈 smiling_imp ❤️ heart ✨ sparkles ⭐️ star 👍 thumbsup​ 🙈 see_no_evil 🙊 speak_no_evil 👀 eyes 1️⃣ one 2️⃣ two 3️⃣ three 4️⃣ four 🐶 dog 🐱 cat 🌚 new_moon_with_face​ ☀️ sunny ⚡️ zap 🎆 fireworks 🔔 bell 🏆 trophy​ 💥 boom​ 🔥 fire ","link":"https://Angus1996.github.io/post/Markdown里面的Emoji表情/"},{"title":"opencv自动伽马校正图像","content":"python+cv2实现自动gamma校正 简单介绍 Gamma变换是对输入图像灰度值进行的非线性操作，使输出图像灰度值与输入图像灰度值呈指数关系： Vout=AVinγV_{out}=AV_{in}^{\\gamma} Vout​=AVinγ​ Gamma变换就是用来图像增强，其提升了暗部细节，简单来说就是通过非线性变换，让图像从曝光强度的线性响应变得更接近人眼感受的响应，即将漂白（相机曝光）或过暗（曝光不足）的图片，进行矫正。 大于1时，对图像的灰度分布直方图具有拉伸作用（使灰度向高灰度值延展），而小于1时，对图像的灰度分布直方图具有收缩作用（是使灰度向低灰度值方向靠拢）。 公式：gamma=log(y/range)/log(x/range)gamma = log(y/range)/ log(x/range)gamma=log(y/range)/log(x/range)，x是整幅图像像素的平均值，y是像素值最大范围的一半。 代码实现 import numpy as np import cv2 def gamma_trans(img, gamma): # gamma函数处理 gamma_table = [np.power(x / 255.0, gamma) * 255.0 for x in range(256)] # 建立映射表 gamma_table = np.round(np.array(gamma_table)).astype(np.uint8) # 颜色值为整数 return cv2.LUT(img, gamma_table) # 图片颜色查表。另外可以根据光强（颜色）均匀化原则设计自适应算法。 img_gray=cv2.imread(img_path,0) # 灰度图读取，用于计算gamma值 img = cv2.imread(img_path) # 原图读取 mean = np.mean(img_gray) gamma_val = math.log10(0.5)/math.log10(mean/255) # 公式计算gamma image_gamma_correct = gamma_trans(img, gamma_val) # gamma变换 实验结果 原图： 校正后的图： ","link":"https://Angus1996.github.io/post/opencv自动伽马校正图像/"},{"title":"aria2 介绍与使用","content":"aria2 介绍与使用 之前一直使用迅雷极速版，即使跳出了提示升级到迅雷X，还是关掉了弹窗提示。可是今天使用的时候，直接强制给我升级了，升级窗口只能最小化，不能关掉。感觉迅雷相当的流氓，以后都不想用迅雷了。以前用过一些基于aria2 的软件，比如Motrix，现在想直接用aria2。 简介 aria2是一个轻量级的多进程和多源地址的命令行工具，支持HTTP/HTTPS，FTP，SFTP，BitTorrent和Metalink。 官网地址：https://aria2.github.io 下载地址：https://github.com/aria2/aria2/releases/tag/release-1.34.0 简单使用示例 从网络下载： $ aria2c http://example.org/mylinux.iso 从两个源地址下载 $ aria2c http://a/f.iso ftp://b/f.iso 每个主机使用2个连接 $ aria2c -x2 http://a/f.iso BitTorrent下载 $ aria2c http://example.org/mylinux.torrent 磁链下载 $ aria2c 'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C' 元链接 $ aria2c http://example.org/mylinux.metalink 从文本文件中的URLs下载 $ aria2c -i uris.txt ","link":"https://Angus1996.github.io/post/aria2-介绍与使用/"},{"title":"基于pygame的打字速度练习游戏","content":"基于pygame的打字速度练习游戏 实现的功能 利用gthub开源的输入模块text-input，并做了相应修改来实现英文文字的输入； 利用faker模块来实现指定长度范围内的随机英文语句生成；对于过长字符串，拆分字符串分别渲染； 输入过程中，敲击键盘速度越快，屏幕颜色越偏向绿色，最绿是RGB(0,255,0)； 越慢越偏向红色，最红是RGB(150,100,0)，屏幕初始背景颜色也是这种颜色。 一分钟到就自动结束，不可再输入；敲击过程中也可以按F1键提前结束，不用等一分钟到； 提前结束或者一分钟到之后，提示时间到，并提示打字的正确度；此时可以按F2键再次开始。 面向对象设计 设计三个类，一个是text_input类实现文本的输入；一个是faker_text类实现随机虚假语句的生成；一个Type_Practice类，组合前面两个类实现整个打字游戏。 实现效果 仓库链接与参考链接 text-input模块：https://github.com/Nearoo/pygame-text-input faker模块：https://faker.readthedocs.io/en/master/ pygame参考手册：https://www.pygame.org/docs/ ","link":"https://Angus1996.github.io/post/基于pygame的打字速度练习游戏/"},{"title":"error:Microsoft Visual C++ 14.0 is required","content":"error: Microsoft Visual C++ 14.0 is required 这种问题比较常见，我是在用cython准备加速python程序的运行时遇到的，错误提示中给出的网址已经404挂了。网上也有很多人给出其他地址，其实微软官网就有。不过是最新的2019版本，但是细心地找的话，也可以发现。解决这个error的具体步骤如下： 1.下载Build Tools for Visual Studio 2019 下载链接：https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft&amp;utm_source=docs.microsoft.com&amp;utm_campaign=navigation+cta&amp;utm_content=download+vs2017 下载完后安装 2.打开Visual Studio Installer 点击Visual Studio 生成工具 2019（Build Tools for Visual Studio 2019）的修改选项； 工作负载(workload)勾选C++生成工具； 安装详细信息中勾选MSVC v140 - VS 2015 C++ 生成工具(v14.00)。 完成修改，等待安装完成即可。 ","link":"https://Angus1996.github.io/post/error-Microsoft-Visual-C-14-0-is-required/"},{"title":"使用Battery Historian工具进行Android耗电分析","content":"使用Battery Historian工具进行Android耗电分析 Battery Historian 安装 Battery Historian作为google提供的一项工具，其github官方文档是很全面的。文档里介绍了两种安装方法，一种是使用Docker，一种是从源码进行编译。 使用Docker的麻烦之处在于Docker的安装使用，在windows 10 专业版的操作系统平台上，使用Docker Destop一直未能进行 docker build 工作。一直报错：“二进制流“0”不包含有效的 BinaryHeader。这可能是由于无效流，或由于在序列化和反序列化之间的对象版本更改。”也并没有找到合适的解决方案。 故此，本人只能使用从源码编译的第二种方法了。第二种方法虽然需要配置一些环境变量，但作为一个开发者，像java、python这样要求的环境变量一直都有，所以，也没有那么麻烦。 在“run Battery Historian”中的“# Compile Javascript files using the Closure compiler”时，可能会遇到如下报错： Generating optimized JS runfiles... failed to run command &quot;java -jar C:\\\\go-work\\\\src\\\\github.com\\\\google\\\\battery-historian/third_party/closure-compiler/closure-compiler-v20170409.jar --closure_entry_point historian.upload --js js/*.js --js C:\\\\go-work\\\\src\\\\github.com\\\\google\\\\battery-historian/third_party/closure-library/closure/goog/base.js --js C:\\\\go-work\\\\src\\\\github.com\\\\google\\\\battery-historian/third_party/closure-library/closure/goog/**/*.js --only_closure_dependencies --generate_exports --js_output_file C:\\\\go-work\\\\src\\\\github.com\\\\google\\\\battery-historian/compiled/historian-optimized.js --output_manifest C:\\\\go-work\\\\src\\\\github.com\\\\google\\\\battery-historian/compiled/manifest.MF --compilation_level SIMPLE_OPTIMIZATIONS&quot;: exit status 1 C:/go-work/src/github.com/google/battery-historian/third_party/closure-library/closure/goog/base.js:2136: WARNING - Parse error. unknown @suppress parameter: strictMissingProperties * @suppress {strictMissingProperties} superClass_ and base is not defined on ^ C:/go-work/src/github.com/google/battery-historian/third_party/closure-library/closure/goog/cssom/cssom.js:86: WARNING - Parse error. unknown @suppress parameter: strictMissingProperties ... 上述错误产生原因不明，但是在github仓库的Issue 中提供了一种切实可行的解决方案： I find one work around way in former issues go run setup.go (this fails) cd third_party/closure-library/ git reset --hard v20170409 cd - go run setup.go (this passes) 我也是用这种解决方案解决了我的问题。启动后默认是在http://localhost:9999界面。 Battery Historian使用 将安卓SDK中的adb工具加入操作系统环境变量。连接上手机，开启USB调试选项。 运行以下命令，便会在当前目录生成bugreport.zip文件： $ adb bugreport bugreport.zip 在http://localhost:9999界面选择浏览上传后就会得到具体的分析结果。 ","link":"https://Angus1996.github.io/post/使用Battery-Historian工具进行Android耗电分析/"},{"title":"我的第一款微信小程序","content":"我的第一款微信小程序 很久之前就一直想要写一个微信小程序，大三暑假的时候写ionic应用的时候，还有一个同学是用微信小程序来和我开发几乎一样的功能。最后我自我感觉他的微信小程序做的比我好看且适用。 前不久在Google paly store上看到一款找数字规律猜谜的游戏，界面简洁，挺好玩的。最近有些同学找实习找工作也会碰到一些找数字规律的题目。所以我想以数字猜谜为切入点，做一款微信小程序。 虽然已经很久没有写过前端的代码了，CSS等内容没有很熟练了。但是微信小程序的工具还是很好用的，看看官方文档，了解一下布局以及各种组件的使用，一个简单的微信小程序并不是很难。 整个项目，我大概做了两个版本。第一个版本只是想要把这个“东西”做出来，包括levels可以直接进入各个关卡，也可以一关一关地玩下去。程序也会记住玩家已经通过的关卡。，但是由于没有数据库和本地存储之类的，“记”只是没有清后台的情况下。一共设置了36个关卡，很多也是直接从知乎、百度文库之类的找到的有规律的题目。在这一款微信小程序里，我也设置了一个彩蛋，也是和数字相关的。因为当时看那题的解答的时候，那个数字让我想起了一个人，所以这个彩蛋便产生了。不知道会不会有人留意到。第一个版本诞生大概花了15个小时。第二个版本，我在第一个的版本基础上加上了提示。第一个版本出来的时候，给实验室同学测试。她觉得太难了，所以第二个版本就加上了提示。不过提示的内容比较明显。整个小程序除了背景图片需要联网获取，其他功能均不需要联网，所以很多知识点其实没有用到。 有时候，有兴趣做一件事，其实并没有那么困难。最后附上小程序码，也可以直接搜索Numeral Riddle，希望大家可以尝试一下！！也可以留言提一些意见，后续有精力的话，会继续更新加入一些其他功能。 ","link":"https://Angus1996.github.io/post/我的第一款微信小程序/"},{"title":"让代码在服务器后台运行","content":"让代码在服务器后台运行 之前使用服务器进行深度学习训练的时候，如果中途断网，就与服务器失去了连接，跑了一半的代码也就会停止下来。同时在ssh连接会话中，如果不新建一个连接会话，就无法再做其他事情了。这些问题让人头疼，让人思考将代码放到服务器后台运行。 1. nohup 最直接简单的做法是: $nohup python test.py 这样，代码就会在服务器后台执行。终端无法看到运行过程以及结果输出。期间运行的结果会生成一个nohup.out的文件中保存。使用文本编辑器打开就能看到。 2. screen 安装screen: $sudo apt install screen 用这个可以为不同的任务开不同的窗口，窗口之间是可以切换的，同时，窗口和会话连接基本上没有任何区别，这样就可以在开一个连接的时候同时干多件事情，并且在终端看得到运行过程的同时而不会由于断网而导致代码停止运行。 新建窗口： $screen -S name # 创建一个名字为name的窗口 新建完就会自动跳到新建的窗口，可以在这个窗口执行训练命令。 当你不想呆在这个窗口时，你可以通过快捷键Ctrl+a+D断开这个窗口的连接而回到连接会话界面（如果新建的窗口什么都没做，Ctrl+A+D即为退出结束窗口）。 查看存在的窗口： $screen -S ls #可以查看已创建的所有窗口 执行上述指令后可以看到窗口的名字和id，Detached说明窗口是断开的，再次强调这里的断开是指没有让他显示，其对应的任务是在后台执行的。 如果想看其中一个窗口任务的执行状态，可以通过如下指令： $screen -r test #重新连接到test窗口，显示其运行过程,如果只有一个窗口，可以screen -r即可 如果想直接停止某个窗口任务的运行，可以直接通过杀死id的方式 $kill 28475 #终止ssd窗口对应任务的运行，同时杀死该窗口 Ctrl + A，D #暂离当前会话 Ctrl + A，C #在当前screen会话中创建一个子会话 Ctrl + A，W #子会话列表 Ctrl + A，P #上一个子会话 Ctrl + A，N #下一个子会话 Ctrl + A，0-9 #在第0窗口至第9子会话间切换 总结一下，screen可以实现代码在后台运行时的可视化，同时，能在开一个会话连接时创建多个窗口处理不同的任务。用起来也很方便。 ","link":"https://Angus1996.github.io/post/让代码在服务器后台运行/"},{"title":"python实现下载文件的方式","content":"python下载文件的方式 参考大佬的页面：https://www.cnblogs.com/alex-bn-lee/p/9284625.html 1.wget import wget, os # 设置下载路径 os.chdir(r&quot;D:/tmp&quot;) url=&quot;https://files.cnblogs.com/files/alex-bn-lee/ESRI_01.zip&quot; # 获取下载文件名称 filename = wget.detect_filename(url) # 文件下载 wget.download(url) 2.urllib.request import urllib.request url = 'https://files.cnblogs.com/files/alex-bn-lee/ESRI_01.zip' # 需要自定义文件名称 urllib.request.urlretrieve(url, &quot;demo.zip&quot;) 3.浏览器自动下载 import pynput, webbrowser, time from pynput.mouse import Button from pynput.keyboard import Key mouse = pynput.mouse.Controller() keyboard = pynput.keyboard.Controller() url = 'https://files.cnblogs.com/files/alex-bn-lee/ESRI_01.zip' # 打开网页 webbrowser.open(url) # 反应时间 time.sleep(2) keyboard.press(Key.enter) keyboard.release(Key.enter) time.sleep(1) mouse.click(Button.left) # 通过 Ctrl+w 快捷键删除当前页面 with keyboard.pressed(Key.ctrl): keyboard.press('w') keyboard.release('w') ","link":"https://Angus1996.github.io/post/python实现下载文件的方式/"},{"title":"python实现m3u8链接播放","content":"python实现m3u8链接文件播放 m3u8文件格式简单说明 维基百科定义：M3U8 是 Unicode 版本的 M3U，用 UTF-8 编码。&quot;M3U&quot; 和 &quot;M3U8&quot; 文件都是苹果公司使用的 HTTP Live Streaming（HLS） 协议格式的基础，这种协议格式可以在 iPhone 和 Macbook 等设备播放。 m3u8 文件实质是一个播放列表（playlist），其可能是一个媒体播放列表（Media Playlist），或者是一个主列表（Master Playlist）。但无论是哪种播放列表，其内部文字使用的都是 utf-8 编码。 当 m3u8 文件作为媒体播放列表（Meida Playlist）时，其内部信息记录的是一系列媒体片段资源，顺序播放该片段资源，即可完整展示多媒体资源。CCTV6直播其格式如下所示： #EXTM3U #EXT-X-VERSION:3 #EXT-X-MEDIA-SEQUENCE:35232 #EXT-X-TARGETDURATION:10 #EXTINF:10.000, cctv6hd-1549272376000.ts #EXTINF:10.000, cctv6hd-1549272386000.ts #EXTINF:10.000, cctv6hd-1549272396000.ts #EXTINF:10.000, cctv6hd-1549272406000.ts #EXTINF:10.000, cctv6hd-1549272416000.ts #EXTINF:10.000, cctv6hd-1549272426000.ts 对于点播来说，客户端只需按顺序下载上述片段资源，依次进行播放即可。而对于直播来说，客户端需要定时重新请求该 m3u8 文件，看下是否有新的片段数据需要进行下载并播放。 下载ts文件并播放 opencv可以直接解析ts文件，所以基本思想就是不断下载新的ts片段文件，并保存。然后用opencv解析读取视频。 ''' @Author: Angus Cai @Date: 2019-05-21 20:35:01 @LastEditors: Angus Cai @LastEditTime: 2019-05-21 21:56:07 @Description: 不断请求下载M3U8文件里的所有片段并播放 ''' # -*- coding: utf-8 -*- # Created on 2018/3/22 import requests import os,re import time import urllib.request import cv2 header = { 'User-Agent': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0);' } play_list = [] #记录播放列表 def play(url): download_path = os.getcwd() + &quot;\\download&quot; if not os.path.exists(download_path): os.mkdir(download_path) while True: all_content = requests.get(url).text # print(all_content) file_line = all_content.splitlines() # print(file_line) if file_line[0] != &quot;#EXTM3U&quot;: raise BaseException(u&quot;非M3U8的链接&quot;) else: unknow = True for index, line in enumerate(file_line): if &quot;EXTINF&quot; in line: unknow = False print(file_line[index + 1]) request = urllib.request.Request(file_line[index + 1],headers=header) response = urllib.request.urlopen(request) print(response) html = response.read() file_name = file_line[index+1].split('/')[-1] file_name = file_name.split('-')[-1] print(file_name) if file_name==&quot;404_0.ts&quot;: print(&quot;设备离线！！！！&quot;) continue with open(download_path + &quot;\\\\&quot; + file_name, 'wb') as f: f.write(html) print(len(html)) # f.flush() if file_name not in play_list: play_list.append(file_name) cap = cv2.VideoCapture(download_path + &quot;\\\\&quot; + file_name) while True: ret, frame = cap.read() if not ret: break cv2.imshow(&quot;Test&quot;, frame) time.sleep(1/30) k = cv2.waitKey(1) &amp; 0xff if k == 27 : break cap.release() # os.remove(download_path + &quot;\\\\&quot; + file_name) else: # os.remove(download_path + &quot;\\\\&quot; + file_name) continue # cap.release cv2.destroyAllWindows() if __name__ == '__main__': play(&quot;http://ivi.bupt.edu.cn/hls/cctv6hd.m3u8&quot;) 多线程操作实现流畅播放 通过多进程与队列，一个进程下载ts文件并存在本地，同时将文件名放入队列；另一个进程从队列中取出文件名并进行读取。 ''' @Author: Angus Cai @Date: 2019-05-22 08:23:34 @LastEditors: Angus Cai @LastEditTime: 2019-05-22 09:49:29 @Description: ''' import multiprocessing as mp import cv2 import time import subprocess as sp import numpy import requests import os,re import time import urllib.request def queue_img_put(q, HD_VIDEO_URL, header, play_list): download_path = os.getcwd() + &quot;\\download&quot; if not os.path.exists(download_path): os.mkdir(download_path) while True: if q.qsize() &lt;= 100: all_content = requests.get(HD_VIDEO_URL).text # print(all_content) file_line = all_content.splitlines() # print(file_line) if file_line[0] != &quot;#EXTM3U&quot;: raise BaseException(u&quot;非M3U8的链接&quot;) else: unknow = True for index, line in enumerate(file_line): if &quot;EXTINF&quot; in line: unknow = False # pd_url = url.rsplit(&quot;/&quot;, 1)[0] + &quot;/&quot; + file_line[index + 1] # print(file_line[index + 1]) print(&quot;http://ivi.bupt.edu.cn/hls/&quot;+file_line[index + 1]) request = urllib.request.Request(&quot;http://ivi.bupt.edu.cn/hls/&quot;+file_line[index + 1],headers=header) # request = urllib.request.Request(file_line[index + 1],headers=header) response = urllib.request.urlopen(request) # print(response) html = response.read() file_name = file_line[index+1].split('/')[-1] file_name = file_name.split('-')[-1] print(file_name) if file_name==&quot;404_0.ts&quot;: print(&quot;设备离线！！！！&quot;) continue # result_file_name= url_list[i][length:][-10:-3] # result_file_name= patt.findall(file_name)[0] # print(&quot;正在处理%s&quot;%result_file_name+&quot;.ts&quot;,&quot;共%s/%s项&quot;%(i+1,url_length)) with open(download_path + &quot;\\\\&quot; + file_name, 'wb') as f: f.write(html) print(len(html)) f.flush() if file_name not in play_list: play_list.append(file_name) q.put(download_path + &quot;\\\\&quot; + file_name) else: # os.remove(download_path + &quot;\\\\&quot; + file_name) continue else: play_list = [] continue def queue_img_get(q, window_name): cv2.namedWindow(window_name, flags=cv2.WINDOW_FREERATIO) # image = cv2.imread(&quot;./404.PNG&quot;) while True: # print(&quot;播放。。&quot;) if q.qsize() &gt; 0: file_name = q.get() cap = cv2.VideoCapture(file_name) while True: ret,frame = cap.read() if not ret: break # detected_image_array, detections = Detector(frame) cv2.imshow(window_name, frame) time.sleep(1/30) k = cv2.waitKey(1) &amp; 0xff if k == 27 : break cap.release() os.remove(file_name) else: # print(&quot;等待中。。。&quot;) # cv2.imshow(window_name, image) # k = cv2.waitKey(1) &amp; 0xff # if k == 27 : break continue cv2.destroyAllWindows() def run(): # single camera HD_VIDEO_URL = &quot;http://ivi.bupt.edu.cn/hls/cctv6hd.m3u8&quot; window_name = &quot;CCTV6&quot; header = { 'User-Agent': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0);' } play_list = [] mp.set_start_method(method='spawn') # init queue = mp.Queue(maxsize=100) processes = [mp.Process(target=queue_img_put, args=(queue, HD_VIDEO_URL, header, play_list)), mp.Process(target=queue_img_get, args=(queue, window_name))] [setattr(process, &quot;daemon&quot;, True) for process in processes] # process.daemon = True [process.start() for process in processes] [process.join() for process in processes] if __name__ == '__main__': run() ","link":"https://Angus1996.github.io/post/python实现m3u8链接播放/"},{"title":"Dikstra算法思想及python实现","content":"Dijkstra算法思想及实现 算法思想 Dijkstra算法包含四个步骤： 找出“最便宜”的节点，即可在最短时间内到达的节点。 更新该节点的邻居的开销。 重复上述过程，直到对图中的每个节点都这样操作了。 计算最终路径。 注意：Dijkstra算法只适用于正加权有向无环图(directed acyclic graph, DAG) Dijkstraa算法关键理念：找出图中最便宜的节点，并确保没有到该节点的最便宜的路径。 算法实现 如下图的Graph: python算法实现如下： ''' @Author: Angus Cai @Date: 2019-05-13 15:06:14 @LastEditors: Angus Cai @LastEditTime: 2019-05-17 09:25:27 @Description: Dijkstra算法实现 ''' graph = { 'start': {'A':3, 'B':1}, 'A': {'B':4, 'C':6}, 'B': {'C':5, 'D':7}, 'C': {'D':9, 'end':5}, 'D': {'end':8}, 'end': {}} infinity = float(&quot;inf&quot;) costs = {} costs['A'] = 3 costs['B'] = 2 costs['C'] = infinity costs['D'] = infinity costs['end'] = infinity parents = {} parents['A'] = 'start' parents['B'] = 'start' parents['C'] = None parents['D'] = None parents['end'] = None processed = [] def find_lowest_cost_node(costs): lowest_cost = float(&quot;inf&quot;) lowest_cost_node = None for node in costs: cost = costs[node] if cost &lt; lowest_cost and node not in processed: lowest_cost = cost lowest_cost_node = node return lowest_cost_node node = find_lowest_cost_node(costs) while node is not None: cost = costs[node] neighbors = graph[node] for n in neighbors.keys(): new_cost = cost + neighbors[n] if new_cost &lt; costs[n]: costs[n] = new_cost parents[n] = node processed.append(node) node = find_lowest_cost_node(costs) print(costs) print(parents) path = [] node = parents['end'] while node != 'start': path.append(node) node = parents[node] i = len(path)-1 final_path = '' while i&gt;=0: final_path = final_path+str(path[i])+'-&gt;' i -= 1 print('start-&gt;'+final_path+'end') ########################## output ############################ # {'A': 3, 'B': 2, 'C': 7, 'D': 9, 'end': 12} # {'A': 'start', 'B': 'start', 'C': 'B', 'D': 'B', 'end': 'C'} # start-&gt;B-&gt;C-&gt;end ","link":"https://Angus1996.github.io/post/Dikstra算法思想及python实现/"},{"title":"自动生成和安装requirements.txt依赖","content":"自动生成和安装requirements.txt依赖 在查看、使用别人的Python项目时，经常会看到一个requirements.txt文件，里面记录了当前项目程序的所有依赖包及其精确版本号。其作用是用来在另一台PC或者另一个环境上重新构建项目所需要的运行环境依赖。 requirements.txt可以通过pip命令自动生成和安装 生成requirements.txt文件 pip freeze &gt; requirements.txt 安装requirements.txt依赖 pip install -r requirements.txt ","link":"https://Angus1996.github.io/post/自动生成和安装requirements-txt依赖/"},{"title":"三层BP神经网络解决T和L字母识别问题","content":"​ 用三层BP神经网络解决字母T和L的识别问题。如图所示，每个字母用3x3的二维二值图表示，令黑方格为1，白方格为0，每个字母有4个样本，包括字母正常位置及旋转90，180和270°的图像。希望输入不同的位置下的T时，网络输出为1，而输入不同位置的L时，网络输出为0。用BP算法求出权系数和阈值。建议：选择网络结构为9-3-1。隐单元非线性函数为f(x)=21+e−ax−1​f(x)=\\frac{2}{1+e^{-ax}}-1​f(x)=1+e−ax2​−1​，输出单元非线性函为f(x)=11+e−ax​f(x)=\\dfrac{1}{1+e^{-ax}}​f(x)=1+e−ax1​​。 1. 数据处理 本次实验数据为上面的字母样本图，每个字母有4个样本，包括字母正常位置及旋转90°，180°和270°的图像。我们令黑方格为1，白方格为0，且按照下图1到9的顺序进行记录，得到数据集矩阵（一列代表一个样本，共八列）。并根据输入不同的位置下的T时，网络输出为1，而输入不同位置的L时，网络输出为0来记录数据标签（八列，每列代表对应样本的输出）。 2. 模型搭建 如下图所示为三层BP神经网络架构，其中第一层到第二层之间权值参数为W1W_1W1​（大小为3×9）和b1b_1b1​（大小为3×1），激活函数为f1(x)=21+e−ax−1f_1(x)=\\dfrac{2}{1+e^{-ax}}-1f1​(x)=1+e−ax2​−1，第二层到第三层之间权值参数为W2W_2W2​（大小为1×3）和b2b_2b2​（大小为1×1），激活函数为f2(x)=11+e−axf_2(x)=\\dfrac{1}{1+e^{-ax}}f2​(x)=1+e−ax1​。 3. 编程实现 使用keras框架实现上述模型得训练： # -*- coding: utf-8 -*- &quot;&quot;&quot; Author: Angus Cai Date: 2019-4-19 &quot;&quot;&quot; from keras.layers import Activation, Dense from keras.models import Sequential from keras.utils.generic_utils import get_custom_objects from keras import backend as K import numpy as np X = [[1,1,1,0,1,0,0,1,0], [1,0,0,1,1,1,1,0,0], [0,1,0,0,1,0,1,1,1], [0,0,1,1,1,1,0,0,1], [1,0,0,1,0,0,1,1,1], [0,0,1,0,0,1,1,1,1], [1,1,1,0,0,1,0,0,1], [1,1,1,1,0,0,1,0,0]] Y = [0,0,0,0,1,1,1,1] X_train = np.array(X) Y_train = np.array(Y) # 隐藏层非线性激活函数 def hidden_activation(X): return 2 * K.sigmoid(X) - 1 # 输出层非线性激活函数 def output_activation(X): return K.sigmoid(X) ## custom activation function get_custom_objects().update({'hidden_activation': Activation(hidden_activation)}) get_custom_objects().update({'output_activation': Activation(output_activation)}) model = Sequential() model.add(Dense(3, input_dim=9)) model.add(Activation(hidden_activation)) model.add(Dense(1)) model.add(Activation(output_activation)) model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) model.fit(X_train, Y_train, epochs=250,batch_size=2) score = model.evaluate(X_train, Y_train, batch_size=2) print('Test loss:', score[0]) print('Test accuracy:', score[1]) model.save('tl_problem.h5') 训练结果如下： 可以看到，设置训练轮数（epoches）为250，可以使得模型得准确率达到100%。 4. 实验结果 模型测试代码如下： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Apr 18 16:28:57 2019 @author: angus &quot;&quot;&quot; from keras.models import load_model from keras.utils.generic_utils import get_custom_objects from keras.layers import Activation from keras import backend as K import numpy as np # 隐藏层非线性激活函数 def hidden_activation(X): return 2 * K.sigmoid(X) - 1 # 输出层非线性激活函数 def output_activation(X): return K.sigmoid(X) get_custom_objects().update({'hidden_activation': Activation(hidden_activation)}) get_custom_objects().update({'output_activation': Activation(output_activation)}) model = load_model('tl_problem.h5') print(model.summary()) weights = [] for layer in model.layers: weights.append(layer.get_weights()) print(&quot;The weight matrix of input_layer to hidden_layer: &quot;) print(weights[0][0]) print(&quot;--------------------------------------------------------&quot;) print(&quot;The bias of the hidden layer:&quot;) print(weights[0][1].tolist()) print(&quot;--------------------------------------------------------&quot;) print(&quot;The weight matrix of hidden_layer to output_layer: &quot;) print(weights[2][0].tolist()) print(&quot;--------------------------------------------------------&quot;) print(&quot;The bias of the output layer:&quot;) print(weights[2][1].tolist()) 测试结果如下： 打印出了模型得结构、参数个数以及最终训练好得权值系数与阈值。 5. 实验总结 该实验通过搭建三层BP神经网络，通过数据预处理，模型搭建以及训练识别三大模块解决字母T和L的识别问题。最后用这八个样本去检验识别结果，与其标签进行比较，得到100%的识别率。 ","link":"https://Angus1996.github.io/post/三层BP神经网络解决T和L字母识别问题/"},{"title":"RTMP、RTSP推流","content":"RTMP、RTSP推流 在上次从萤石云摄像头读取了监控视频后，想要将读取到的视频进行处理，然后将处理后的视频进行推流。目前主要用的协议有RTMP与RTSP两种。 以下是两种协议的百度百科解释： RTMP是Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于TCP，是一个协议族，包括RTMP基本协议及RTMPT/RTMPS/RTMPE等多种变种。RTMP是一种设计用来进行实时数据通信的网络协议，主要用来在Flash/AIR平台和支持RTMP协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括Adobe Media Server/Ultrant Media Server/red5等。 RTSP（Real Time Streaming Protocol），RFC2326，实时流传输协议，是TCP/IP协议体系中的一个应用层协议，由哥伦比亚大学、网景和RealNetworks公司提交的IETF RFC标准。该协议定义了一对多应用程序如何有效地通过IP网络传送多媒体数据。RTSP在体系结构上位于RTP和RTCP之上，它使用TCP或UDP完成数据传输。HTTP与RTSP相比，HTTP请求由客户机发出，服务器作出响应；使用RTSP时，客户机和服务器都可以发出请求，即RTSP可以是双向的。RTSP是用来控制声音或影像的多媒体串流协议，并允许同时多个串流需求控制，传输时所用的网络通讯协定并不在其定义的范围内，服务器端可以自行选择使用TCP或UDP来传送串流内容，它的语法和运作跟HTTP 1.1类似，但并不特别强调时间同步，所以比较能容忍网络延迟。而前面提到的允许同时多个串流需求控制（Multicast），除了可以降低服务器端的网络用量，更进而支持多方视讯会议（Video Conference）。因为与HTTP1.1的运作方式相似，所以代理服务器〈Proxy〉的快取功能〈Cache〉也同样适用于RTSP，并因RTSP具有重新导向功能，可视实际负载情况来转换提供服务的服务器，以避免过大的负载集中于同一服务器而造成延迟。 那到底怎么讲本地视频或者处理过的帧进行推流呢？主要用到的还是FFMPEG。 RTMP推流 主要的命令是： # Windows OS ffmpeg.exe -re -i demo.wmv -vcodec copy -codec copy -f flv rtmp://127.0.0.1:1935/live/123 # Linux OS ffmpeg -re -i demo.mp4 -vcodec copy -codec copy -f flv rtmp://127.0.0.1:1935/live/123 # 1935为默认端口，127.0.0.1即localhost 与python-opencv一起就可以用来处理本地视频或者处理好的帧的推流，此处主要参考了CSDN博客： import cv2 import subprocess as sp rtmpUrl = 'rtmp://localhost/live/123' # 视频来源 地址需要替换自己的可识别文件地址 filePath='C:\\\\Users\\\\angus\\Videos\\\\' camera = cv2.VideoCapture(filePath+&quot;test2.mp4&quot;) # 从文件读取视频 # 视频属性 size = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)), int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))) sizeStr = str(size[0]) + 'x' + str(size[1]) fps = camera.get(cv2.CAP_PROP_FPS) # 30p/self fps = int(fps) hz = int(1000.0 / fps) print('size:'+ sizeStr + ' fps:' + str(fps) + ' hz:' + str(hz)) # 视频文件输出格式 fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter(filePath+'res_mv.avi',fourcc, fps, size) # 直播管道输出 # ffmpeg推送rtmp 重点 ： 通过管道 共享数据的方式 command = ['ffmpeg', '-y', '-f', 'rawvideo', '-vcodec','rawvideo', '-pix_fmt', 'bgr24', '-s', sizeStr, '-r', str(fps), '-i', '-', '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-preset', 'ultrafast', '-f', 'flv', rtspUrl] #管道特性配置 # pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8) pipe = sp.Popen(command, stdin=sp.PIPE) #,shell=False # pipe.stdin.write(frame.tostring()) while True: ret, frame = camera.read() # 逐帧采集视频流 if not ret: break # 绘制推送图片帧信息 # print(len(faces)) # fpsshow = &quot;Fps :&quot; + str(int(fps)) + &quot; Frame:&quot; + str(count) # nframe = &quot;Play :&quot; + str(int(count / fps)) # ntime = &quot;Time :&quot; + time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) ############################图片输出 # 结果帧处理 存入文件 / 推流 / ffmpeg 再处理 pipe.stdin.write(frame.tostring()) # 存入管道用于直播 out.write(frame) #同时 存入视频文件 记录直播帧数据 pass camera.release() # Release everything if job is finished out.release() print(&quot;Over!&quot;) RTSP推流 主要 用到的命令： # Linux OS ffmpeg -re -i demo.mp4 -vcodec copy -codec copy -f rtsp rtsp://127.0.0.1:1935/test # Windows OS ffmpeg.exe -re -i demo.mp4 -vcodec copy -codec copy -f rtsp rtsp://127.0.0.1:1935/test # 与RTMP推流的主要区别在于 -f 这个option 与python-opencv共同使用： import cv2 import subprocess as sp rtspUrl = 'rtsp://localhost/test' # 视频来源 地址需要替换自己的可识别文件地址 filePath='C:\\\\Users\\\\angus\\Videos\\\\' camera = cv2.VideoCapture(filePath+&quot;test2.mp4&quot;) # 从文件读取视频 # 视频属性 size = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)), int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))) sizeStr = str(size[0]) + 'x' + str(size[1]) fps = camera.get(cv2.CAP_PROP_FPS) # 30p/self fps = int(fps) hz = int(1000.0 / fps) print('size:'+ sizeStr + ' fps:' + str(fps) + ' hz:' + str(hz)) # 视频文件输出 fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter(filePath+'res_mv.avi',fourcc, fps, size) # 直播管道输出 # ffmpeg推送rtmp 重点 ： 通过管道 共享数据的方式 command = ['ffmpeg', '-y', '-f', 'rawvideo', '-vcodec','rawvideo', '-pix_fmt', 'bgr24', '-s', sizeStr, '-r', str(fps), '-i', '-', '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-preset', 'ultrafast', '-f', 'rtsp', rtspUrl] #管道特性配置 # pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8) pipe = sp.Popen(command, stdin=sp.PIPE) #,shell=False # pipe.stdin.write(frame.tostring()) while True: ret, frame = camera.read() # 逐帧采集视频流 if not ret: break ############################图片输出 # 结果帧处理 存入文件 / 推流 / ffmpeg 再处理 pipe.stdin.write(frame.tostring()) # 存入管道用于直播 out.write(frame) #同时 存入视频文件 记录直播帧数据 pass camera.release() # Release everything if job is finished out.release() print(&quot;Over!&quot;) 结束 这里为了测试代码，我使用的是EasyDarwin高性能开源RTSP流媒体服务器 如果是在服务器端，需要进行一些相应的配置，具体可自行百度，如此处。 ","link":"https://Angus1996.github.io/post/RTMP、RTSP推流/"},{"title":"基于深度学习的图像修复","content":"基于深度学习的图像修复 2006 年是深度学习走进许多人眼中的一年。加拿大多伦多大学Geoffrey Hinton教授在《Science》上发表了一篇文章《Deep belief networks》[1] 。从此一股关于深度学习(Deep Learning, DL ) 在学术界和工业界被掀起。2012 年中旬，谷歌大脑项目引起了科学家们广泛关注。由斯坦福大学的机器学习教授吴恩达与大规模计算机系统领域的专家Jeff Dean 共同担任项目负责人，使用大规模并行计算平台进行算法部署和模型训练，构建了一个名为“深度神经网络”( DNN，Deep Neural Networks) 的模型。该模型在语音识别[2] 和图像识别[3] 等领域获得了巨大的成功。由此可见深度学习将给各个领域带来的新发展，在图像识别和语音识别领域使用深度神经网络架构的算法己经超过了原有业界最好的算法。深度学习在各个领域的突破开始让人考虑是否能给图像修复领域带来新的发展。将深度学习成功应用于图像修复的成功案例不断涌现。 基于CNN 的图像修复 CNN简介 Hubel 等人在研究猫脑皮层神经元过程中发现独特的网络结构，并且实验证明该神经网络结构可以有效降低反馈神经网络的复杂度, 继而提出了卷积神经网络（Convolutional Neural Networks，CNN）[4] 。卷积神经网络是一种用于处理具有网络状拓扑结构数据的专用神经网络。从命名上看，该网络采用了卷积数学运算，并至少在其一个层中使用卷积代替一般的矩阵乘法。一种用于图像分类问题的卷积神经网络架构图如下图所示。 卷积神经网络主要由输入层、卷积层、池化层、全连接层和softmax 层构成。针对不同的任务网络结构设计也不尽相同。各层的主要功能和详细介绍如下所示：分别是输入层、卷积层、池化全连接层和SoftMax 层。 卷积神经网络以其局部权值共享的特殊结构在自然语言处理[5] 、医药发现[6] 甚至围棋人工智能程序[7] 中都有应用。卷积神经网络的布局非常接近于实际的生物的神经网络，参数共享减少了网络参数，另外一个优点则是多维输入向量的图像可以直接输入网络这一特点，使得特征提取自动化。 图像修复的应用 在CNN 的快速发展下，参考文献[8] 在2016 年就提出了一种基于CNN 的图像修复框架，如下图所示。 该算法需要使用两个网络，一个是内容生成网络，另一个是纹理生成网络。内容生成网络直接用于生成图像，推断缺失部分可能的内容。纹理生成网络用于增强内容网络的产出的纹理，具体则为将生成的补全图像和原始无缺失图像输入进纹理生成网络，在某一层feature_map 上计算损失，记为Loss NN。内容生成网络需要使用自己的数据进行训练，而纹理生成网络则使用已经训练好的VGG Net。 Nvidia 公司在ECCV2018 上发表了一篇名为“Image Inpainting for Irregular Holes Using Partial Convolutions”的论文[9] ，使用“Partial Convolutions”进行图像修复。该模型可以很好地处理任何形状、大小、位置或距离图像边界任何距离的空白。以上的基于深度学习的图像修复方法不够好，因为丢失像素的输出必然取决于输入的值，而这些输入必须提供给神经网络，以找出丢失的像素。这就导致图像中出现诸如颜色差异或模糊之类的失真。 为了解决这个问题，NVIDIA 团队开发了一种方法，确保丢失像素的输出不依赖于为这些像素提供的输入的值。这种方法使用一个“部分卷积”层，根据其对相应的接受域（receptive field）的有效性，对每个输出进行重新归一化（renormalization）。这种重新归一化可以确保输出值与每个接受域中缺失像素的值无关。该模型也是第一个在不规则形状的孔洞上展示深度学习图像修复模型效果的模型。修复效果如下图所示。 CNN 除了在普通图像的图像修复上有所应用，在高光谱图像的修复上也有所应用。参考文献[10] 在CNN 的基础上，同时引入残差学习、扩张卷积和多通道滤波，得到HSI-DeNet 网络，实现了去除HSI 中的混合噪声：随机、结构条带、死线等。HSI-DeNet 的网络结构如下图所示。 HSI-DeNet 网络的输入是三维的高光谱数据，经过网络训练后得到其噪声，然后使用残差学习策略，得到最终的干净图像。在网络中还使用到了扩张卷积和多通道滤波，使用扩张卷积可以在不增加参数的前提下，扩大感受野，从而能够利用更多的局部和非局部信息，多通道滤波则可以增强对光谱信息的表示能力。 基于GAN 的图像修复 GAN简介 生成式对抗网络（GAN, Generative Adversarial Networks）是一种深度学习模型，很巧妙地将机器学习中的生成模型和对抗模型结合起来，是近年来复杂分布上无监督学习中最具影响力也最有效的方法之一。Goodfellow 等人于2014 年提出并给出了相应训练方法和基本框架[11] 。基本框架中包含至少两个模块：生 成模型模块（Generator）和判别模型模块（Discriminator）。通过这两个模块之间的互相博弈，从而使得生成模型可以学习到真实数据的某种分布，从而产生非常好的输出结果。GAN 的基本框图如下图所示。 图像修复的应用 Yeh R A 等人的“Semantic Image Inpainting with Deep Generative Models”[12]论文，利用图像修复所需的环境信息和知觉信息，基于利用DCGAN 进行图像修复。环境信息即根据缺失区域的周围像素点的信息来推断出缺失区域的像素信息；而知觉信息即修复后的图像看起来是否自然，如人脸图像修复后是否还是一张人脸图像。该论文图像修复的主要步骤如图2-7所示。 Pathak 等人的“Context Encoders: Feature Learning by Inpainting”[13] ，将GAN和自编码器相结合，Encoder-Decoder 阶段用于学习图像特征和生成图像待修补区域对应的预测图，GAN 部分用于判断预测图来自训练集和预测集的可能性，当生成的预测图与真实图像在图像内容上达到一致，并且GAN 的判别器无法判断预测图是否来自训练集或预测集时，就认为网络模型参数达到了最优状态。其中的Context Encoder 的结构示意图如图2-8所示。 Ishikawa H 等人的“Globally and locally consistent image completion”[14] 论文中改变了GAN 的结构，将鉴别器（Discriminator）的数量扩展到两个，两个鉴别器分别关注图像的全局以及局部区域。在生成网络中作者还引入了空洞卷积(Dilated Conv) 的方法来提高卷积神经网络的感受野。全局鉴别器和局部鉴别器分别判断全局图像与局部图像是否自然逼真。网络结构如图2-9所示。 与Ishikawa H 等人引入多个鉴别器的想法一样，Yijun Li 等人在论文“Generative Face Completion”[15] 中同样引入了多个鉴别器，不过除此之外, 还引入了一个Parsing network。Parsing network 主要用于进一步完善缺失区域的生成图像的真实性。具体网络结构如图2-10所示。 参考文献 [1] HINTON G E, OSINDERO S, TEH Y-W. A fast learning algorithm for deep belief nets[J]. Neural computation, 2006, 18(7) : 1527 – 1554. [2] YU D, SELTZER M L, LI J, et al. Feature learning in deep neural networks-studies on speech recognition tasks[J]. arXiv preprint arXiv:1301.3605, 2013. [3] MAIRAL J. Sparse coding for machine learning, image processing and computer vision[D]. [S.l.] : Cachan, Ecole normale supérieure, 2010. [4] HUBEL D H, WIESEL T N. Early exploration of the visual cortex.[J]. Neuron, 1998, 20(3) : 401. [5] KIM Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. [6] WALLACH I, DZAMBA M, HEIFETS A. Atomnet: A deep convolutional neural network for bioactivity prediction in structure-based drug discovery[J]. arXiv preprint arXiv:1510.02855, 2015. [7] CLARK C, STORKEY A. Training deep convolutional neural networks to play go[C] // International Conference on Machine Learning. 2015 : 1766 – 1774. [8] CHAO Y, XIN L, ZHE L, et al. High-Resolution Image Inpainting Using Multiscale Neural Patch Synthesis[J], 2016. [9] LIU G, REDA F A, SHIH K, et al. Image Inpainting for Irregular Holes Using Partial Convolutions[J]. arXiv preprint arXiv:1804.07723, 2018. [10] LI Y, JING H, XI Z, et al. Hyperspectral image super-resolution using deep convolutional neural network[J]. Neurocomputing, 2017 : S092523121730841X. [11] GOODFELLOW I, POUGET-ABADIE J, MIRZA M, et al. Generative adversarial nets[C] // Advances in neural information processing systems. 2014 : 2672 – 2680. [12] YEH R A, CHEN C, LIM T Y, et al. Semantic Image Inpainting with Deep Generative Models[J], 2016. [13] PATHAK D, KRAHENBUHL P, DONAHUE J, et al. Context Encoders: Feature Learning by Inpainting[C] // Computer Vision and Pattern Recognition. 2016 : 2536 – 2544. [14] ISHIKAWA H, ISHIKAWA H, ISHIKAWA H. Globally and locally consistent image completion[M]. [S.l.] : ACM, 2017 : 1 – 14. [15] LI Y, LIU S, YANG J, et al. Generative Face Completion[J], 2017. ","link":"https://Angus1996.github.io/post/基于深度学习的图像修复/"},{"title":"keras inference bug in multi_thrad","content":"Tensorflow backend - bug in model._make_predict_function(...) 问题 ​ 最近在写qt界面做模型效果展示时，需要在另一个Qthread里进行深度学习模型的Inference。在单独的文件测试时没有问题。由于qt主线程进行耗时操作时会导致程序卡主崩溃，所以耗时工作需要放在Qthread线程中进行，可是当我在Qthread线程中直接进行模型的Inference，以期得到预测结果时，遇到了如下错误： File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/keras/engine/training.py&quot;, line 1164, in predict self._make_predict_function() File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/keras/engine/training.py&quot;, line 554, in _make_predict_function **kwargs) File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py&quot;, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs) File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py&quot;, line 2546, in __init__ with tf.control_dependencies(self.outputs): File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/tensorflow/python/framework/ops.py&quot;, line 5028, in control_dependencies return get_default_graph().control_dependencies(control_inputs) File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/tensorflow/python/framework/ops.py&quot;, line 4528, in control_dependencies c = self.as_graph_element(c) File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/tensorflow/python/framework/ops.py&quot;, line 3478, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation) File &quot;/home/angus/Envs/face/lib/python3.5/site-packages/tensorflow/python/framework/ops.py&quot;, line 3557, in _as_graph_element_locked raise ValueError(&quot;Tensor %s is not an element of this graph.&quot; % obj) ValueError: Tensor Tensor(&quot;SR/BiasAdd:0&quot;, shape=(?, ?, ?, 3), dtype=float32) is not an element of this graph. 解决方案 解决方案在github Issue中找到了。 #Right after loading or constructing your model, save the TensorFlow graph: graph = tf.get_default_graph() #In the other thread (or perhaps in an asynchronous event handler), do: global graph with graph.as_default(): (... do inference here ...) 这个解决方法相当有效，可能是keras将Tensorflow做backend在多线程模式中的一个Bug。后续版本可能会解决吧。 ","link":"https://Angus1996.github.io/post/keras-inference-bug-in-multi-thrad/"},{"title":"萤石摄像头视频获取","content":"萤石摄像头视频帧获取 近来购买了萤石摄像头进行一些开发，发现网上很多读取海康威视摄像头的都是直接读取视频源地址。这些视频源都是采用RTSP协议的。比如：知乎实例 然而实际使用过程中发现，萤石系列并不提供RTSP地址。所以，要另谋思路。 在stackoverflow中无意看到这么一篇streaming m3u8 file with opencv 所以经过改写，可以有以下方法获取视频并逐帧播放。只是萤石摄像头直播高清和流畅的尺寸不清楚。只是猜测出了高清是1080*720。 获取帧的代码 import subprocess as sp import cv2 import numpy FFMPEG_BIN = &quot;ffmpeg&quot; HD_VIDEO_URL = # VIDEO_URL = cv2.namedWindow(&quot;GoPro&quot;) pipe = sp.Popen([ FFMPEG_BIN, &quot;-i&quot;, HD_VIDEO_URL, &quot;-loglevel&quot;, &quot;quiet&quot;, # no text output &quot;-an&quot;, # disable audio &quot;-f&quot;, &quot;image2pipe&quot;, &quot;-pix_fmt&quot;, &quot;bgr24&quot;, &quot;-vcodec&quot;, &quot;rawvideo&quot;, &quot;-&quot;], stdin = sp.PIPE, stdout = sp.PIPE) while True: # raw_image = pipe.stdout.read(720*480*3) # fluent video raw_image = pipe.stdout.read(1280*720*3) # read 1280*720*3 bytes (= 1 frame)(HD) #image = numpy.fromstring(raw_image, dtype='uint8').reshape((480,720,3)) image = numpy.fromstring(raw_image, dtype='uint8').reshape((720,1280,3)) cv2.imshow(&quot;GoPro&quot;,image) if cv2.waitKey(27) == 1: break cv2.destroyAllWindows() ffmepg的安装 sudo apt install ffmepg ","link":"https://Angus1996.github.io/post/萤石摄像头视频获取/"},{"title":"keras、TensorFlow打造音乐推介系统","content":"keras、TensorFlow打造音乐推荐系统 参考：https://yq.aliyun.com/articles/154475 推荐系统定义 根据百度百科的定义：推荐算法是计算机专业中的一种算法，通过一些数学算法，推测出用户可能喜欢的东西，目前应用推荐算法比较好的地方主要是网络中。所谓推荐算法就是利用用户的一些行为，通过一些数学算法，推测出用户可能喜欢的东西。比如淘宝购物、页面定位广告等。 本文借鉴参考网址的做法，利用深度学习做一个音乐推荐系统，感兴趣的读者可以动手尝试下。 数据准备 本文提供六种根据网易云音乐歌单下载好的六种风格的音乐： 链接: https://pan.baidu.com/s/17uuVklry0ygntfYTKjvBPQ 提取码: c403 其中分为古风、民谣、爵士、说唱、摇滚和轻音乐6种， 分别是300首左右，长短不一。 得到音频的频谱图 一个音频文件包含的数据太多，所以在这部分的整个过程中的很大一部分本质上是试图将信息从音乐中浓缩、提取主要特征并消除所有的“噪音”。它本质上是一个降维的预处理，这第一阶段是将音频转换成图像格式。 利用离散傅里叶变换将音频信号转换到频域上，处理收集的9000个MP3音频文件，每首歌保存为光谱图像。光谱图是一种表示声音的频谱随时间变化的可视化，图片上颜色的强度代表该频率的声音振幅。 本文选择创建成单色光谱图，如下图所示： 为了对这些数据训练一个模型，需要将所有的图像统一为相同的尺寸，所以将所有的光谱图分割为256×256大小。处理好的光谱图可以从以下链接中下载： 链接: https://pan.baidu.com/s/1OcvTAWPSp7yRa2dy8G0Jew 提取码: 368f 神经网络训练 神经网络的网络结构如下： 训练好的神经网络模型下载： 链接: https://pan.baidu.com/s/14Y2V9pkbjWWXnd9AfvcBgQ 提取码: 35hh 神经网络表现 准确度： 损失函数： 测试集上的混淆矩阵： 测试集的分类报告： 特征向量提取 去掉训练好的神经网络的最后几层，取全连接层的128维输出作为特征向量。 特征提取网络的结构如下： 每个256*256的图像的提取的特征向量可以从以下链接获取： 链接: https://pan.baidu.com/s/1WoI1ZPfWJ27dF21AwHcCbA 提取码: 7n83 由于每个音乐长度不一，所以可以得到256*256的频谱图的数量也不一样，简单处理，直接将每一首音乐对应的特征向量加和求平均作为这一首音乐的特征向量。 每一首音乐的特征向量可以从以下链接获取： 链接: https://pan.baidu.com/s/1FLsknuSpKeqmpKU-ctOZZg 提取码: hn60 特征提取模型下载： 链接: https://pan.baidu.com/s/1su27R_459tWlBnbICp8SZg 提取码: yz3b 音乐推荐 为了创建有着类似特征的推荐歌曲，所以需要找到最相似的向量。 随机挑一首音乐的特征向量，从1799首曲库中计算特征向量之间的余弦相似度，找到top6（最高的是自己，余弦相似度为1）。 推荐效果如下： 古风测试歌曲：陌上花开.mp3 推荐歌曲1:空城·旧忆.mp3 推荐歌曲2:燕燕于飞.mp3 推荐歌曲3:春既已逝.mp3 推荐歌曲4:腐草为萤.mp3 推荐歌曲5:旧竹新酒（Cover：长歌红影乱&amp;林斜阳）.mp3 -------------------------------------------- 民谣测试歌曲：旅人的梦.mp3 推荐歌曲1:荏苒冬春去.mp3 推荐歌曲2:小雨日记.mp3 推荐歌曲3:一个西藏.mp3 推荐歌曲4:梦回家乡.mp3 推荐歌曲5:梵高先生.mp3 -------------------------------------------- 爵士测试歌曲：Our Love (Album Version).mp3 推荐歌曲1:So Nice.mp3 推荐歌曲2:Love mail.mp3 推荐歌曲3:You Belong To Me.mp3 推荐歌曲4:Spanish harlem.mp3 推荐歌曲5:I'm Not In Love.mp3 -------------------------------------------- 说唱测试歌曲：The Anthem.mp3 推荐歌曲1:They Reminisce Over You.mp3 推荐歌曲2:Whole Lotta Lovin'.mp3 推荐歌曲3:You Got Me - Album Version (Explicit).mp3 推荐歌曲4:Knock Knock.mp3 推荐歌曲5:Gangsta Gangsta.mp3 -------------------------------------------- 摇滚测试歌曲：10_37.mp3 推荐歌曲1:All I Had.mp3 推荐歌曲2:Little Child.mp3 推荐歌曲3:Dreams Tonite.mp3 推荐歌曲4:Down at the Dinghy.mp3 推荐歌曲5:Runner.mp3 -------------------------------------------- 轻音乐测试歌曲：Life.mp3 推荐歌曲1:Waltz.mp3 推荐歌曲2:Mirage.mp3 推荐歌曲3:The sound of silence.mp3 推荐歌曲4:Down by the Sally Gardens.mp3 推荐歌曲5:Threnody.mp3 -------------------------------------------- 总结 总的来说，整个过程并不复杂。再参考了参考网址中的思想后，自己从库的安装到全部完成只花了大概五天，感兴趣的读者可以自己试试。 相关代码 https://github.com/Angus1996/MusicRecommendation ","link":"https://Angus1996.github.io/post/keras、TensorFlow打造音乐推介系统/"},{"title":"HyperLPR车牌识别","content":"HyperLPR 高性能开源中文车牌识别框架 github链接：https://github.com/zeusees/HyperLPR，更多详情可以参考github中的一些指导链接。 安装 pip install hyperlpr 支持python3,支持Windows Mac Linux 树莓派等。 使用 #导入包 from hyperlpr import * #导入OpenCV库 import cv2 #读入图片 image = cv2.imread(&quot;demo.jpg&quot;) #识别结果 print(HyperLPR_PlateRecogntion(image)) 亲测效果 对于一些比较正比较清晰的图片，识别效果挺好挺快的，但是对于一些有一定角度的图像，车牌识别的效果不是很好 输入测试图 输出结果 输出结果包括识别出的车牌号，置信度，以及车牌的坐标，分别为左上角坐标与右下角坐标。 ","link":"https://Angus1996.github.io/post/HyperLPR车牌识别/"},{"title":"sox命令工具使用","content":"在做将音乐mp3文件提取成光谱图的实验中主要用到以下一条命令： sox inputfile -n spectrogram -Y 300 -X 50 -m -r -o outputfile 将音乐转换为单声道时，主要用到以下一条命令： sox inputfile outputfile remix 1,2 具体安装的话，在ubuntu上安装比较容易，以下内容为转载： SoX是Ubuntu下一个音频处理工具，运行于命令行，安装如下。SoX包含三条主要命令 sox、play和rec，用前者可实现SoX所有功能，而后两者只是为了简化“播放”和“录音”操作。另一条命令soxi可输出音频信息。SoX支持一些常见的音频格式，如wav/mp3/ogg等，参见手册。 sudo apt-get install sox # 安装 # 以下安装是为了支持mp3格式，可选 sudo apt-get install lame sudo apt-get install libsox-fmt-mp3 # 使用示例 sox sample.wav -n stat # 打印sample.wav详细信息 soxi sample.wav # 同样打印信息 play sample.wav # 播放，前提是你的终端支持音频播放 # 将orign.wav从0s开始剪切出10s输出到trimed.wav sox origin.wav trimed.wav trim 0 10 # 对origin.wav重采样，输出16000Hz的音频到out.wav sox origin.wav -r 16000 out.wav # 混合music.wav和voice.wav，输出到mixed.wav sox -m music.wav voice.wav mixed.wav # 拼接short.wav和long.wav，输出到longer.wav sox short.wav long.wav longer.wav # 将sample.mp3转换成wav格式 sox sample.mp3 sample.wav ","link":"https://Angus1996.github.io/post/sox命令工具使用/"},{"title":"Android Strings.xml中输入空格等符号的方法","content":"Android Strings.xml中输入空格等符号的方法 在Android中，用户往往会把所有的字符串保存在string.xml中，目的是方便统一管理，并且利于国际化，但是在这些字符串中直接输入一些符号是不起任何效果的，比如空格，换行，大于号小于号等，这就需要使用转义字符来进行转移，这样才能在使用时正确显示字符。 常用的XML转义字符记录如下： 空格： 出 库 其中的 就代表空格 换行： 你好！\\n世界！ 其中的\\n就代表换行 缩进： 你好！\\t世界！ 其中的\\t就代表按一次Tab键的几个空格 应当注意，由于系统定义的基本的缩进的格数不同，有的代表4个半角字符，有的代表8个半角字符， 所以可能显示时效果不同，建议如果编写界面时尽量少用。 &quot; ： &amp;#34; 或 &amp;quot; ' ： &amp;#39; 或 &amp;apos; &amp; ： &amp;#38; 或 &amp;amp; lt(&lt;) ： &amp;#60; 或 &amp;lt; gt(&gt;) ： &amp;#62; 或 &amp;gt; &amp;#32; == 普通的英文半角空格 &amp;#160; == &amp;nbsp; == &amp;#xA0; == no-break space （普通的英文半角空格但不换行） &amp;#12288; == 中文全角空格 （一个中文宽度） &amp;#8194; == &amp;ensp; == en空格 （半个中文宽度） &amp;#8195; == &amp;emsp; == em空格 （一个中文宽度） &amp;#8197; == 四分之一em空格 （四分之一中文宽度） 一个汉字宽度的空格：&amp; #160;&amp; #160;&amp; #8201; 用两个空格（&amp; #160;&amp; #160;）占一个汉字的宽度时，两个空格比一个汉字略窄，三个空格（&amp; #160;&amp; #160;&amp; #160;）比一个汉字略宽 TextView实现首行缩进的方法： 在string资源文件中，在文字的前面加入”\\u3000\\u3000”即可实现首行缩进 在Java代码中，使用setText(&quot;\\u3000\\u3000&quot;+xxxxx); ","link":"https://Angus1996.github.io/post/Android-Strings-xml中输入空格等符号的方法/"},{"title":"opencv读取存储视频","content":"从摄像头中获取视频： 要捕捉视频，需要创建一个VideoCapture对象。它的参数可以是设备索引或视频文件的名称（下面会讲到）。设备索引只是指定哪台摄像机的号码。0代表第一台摄像机、1代表第二台摄像机。之后，可以逐帧捕捉视频。但最后，不要忘记释放捕获。 import numpy as np import cv2 cap = cv2.VideoCapture(0) while(True): # Capture frame-by-frame ret, frame = cap.read() # Our operations on the frame come here gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Display the resulting frame cv2.imshow('frame',gray) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break # When everything done, release the capture cap.release() cv2.destroyAllWindows() cap.read（）：返回一个布尔值（True / False）。如果帧被正确读取，则返回true，否则返回false。可以通过检查这个返回值来判断视频是否结束。 cap.isOpened（）：检查cap是否被初始化。若没有初始化，则使用cap.open（）打开它。当cap没有初始化时，上面的代码会报错。 cap.get（propId）：访问视频的某些功能，其中propId是一个从0到18的数字，每个数字表示视频的属性（Property Identifier）。其中一些值可以使用cap.set（propId，value）进行修改，value是修改后的值。 举个例子：我通过cap.get（3）和cap.get（4）来检查帧的宽度和高度，默认的值是640x480。但我想修改为320x240，可以使用ret = cap.set（3, 320）和ret = cap.set（4, 240）。 Playing Video from file 从文件中播放视频 和从相机捕获视频相同，只需更改相机索引与视频文件名。 在显示帧时，选择适当的cv2.waitKey（）时间，如果该值太小，视频会非常快，如果它太大，视频会很慢（这可以用来慢动作显示视频）。 正常情况下，25毫秒即可。 import numpy as np import cv2 cap = cv2.VideoCapture('vtest.avi') while(cap.isOpened()): ret, frame = cap.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame',gray) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows() 保存视频： 创建一个VideoWriter对象，指定输出文件名（例如：output.avi）。之后指定FourCC代码（FourCC是用于指定视频编解码器的4字节代码，可用代码列表在fourcc.org有列出）。接下来传递每秒帧数（fps）和帧的尺寸大小。最后一个是isColor标志，如果它为True，编码器编码成彩色帧，否则编码成灰度框帧。 In Fedora: DIVX, XVID, MJPG, X264, WMV1, WMV2. (XVID is more preferable. MJPG results in high size video. X264 gives very small size video) In Windows: DIVX (More to be tested and added) In OSX : (I don’t have access to OSX. Can some one fill this?) FourCC code is passed as cv2.VideoWriter_fourcc('M','J','P','G') or cv2.VideoWriter_fourcc(*'MJPG)for MJPG. 下列代码从摄像头捕捉视频，垂直方向上翻转每一帧然后保存。 import numpy as np import cv2 cap = cv2.VideoCapture(0) # Define the codec and create VideoWriter object fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480)) while(cap.isOpened()): ret, frame = cap.read() if ret==True: frame = cv2.flip(frame,0) # write the flipped frame out.write(frame) cv2.imshow('frame',frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break else: break # Release everything if job is finished cap.release() out.release() cv2.destroyAllWindows() 值得注意的是：这里的帧尺寸大小参数分别为width和height，可以通过cap.get（3）和cap.get（4）来检查帧的宽度和高度，不能弄反了，否则存储的视频无法播放。 ","link":"https://Angus1996.github.io/post/opencv存储视频/"},{"title":"OpenCV之使用MTCNN进行脸部特征检测","content":"OpenCV之使用MTCNN进行脸部特征检测 MTCNN Multi-task Cascaded Convolutional Neural Networks for Face Detection, based on TensorFlow install pip install mtcnn==0.0.8 usage &gt;&gt;&gt; from mtcnn.mtcnn import MTCNN &gt;&gt;&gt; import cv2 &gt;&gt;&gt; &gt;&gt;&gt; img = cv2.imread(&quot;ivan.jpg&quot;) &gt;&gt;&gt; detector = MTCNN() &gt;&gt;&gt; print(detector.detect_faces(img)) [{'box': [277, 90, 48, 63], 'keypoints': {'nose': (303, 131), 'mouth_right': (313, 141), 'right_eye': (314, 114), 'left_eye': (291, 117), 'mouth_left': (296, 143)}, 'confidence': 0.99851983785629272}] 检测器返回一个JSON对象列表。每个JSON对象包含三个键：&quot;box&quot;、&quot;confidence&quot;、&quot;keypoints&quot; 检测框在键&quot;box&quot;下以 [x, y, width, height]格式存在 键“confidence” 是检测框内容是一张脸的概率 关键点包括左眼、右眼、鼻子、左嘴角、右嘴角。每个都是以像素点位置定义 (x, y)。 MTCNN的作者主页 实时检测 import numpy as np import cv2 from mtcnn.mtcnn import MTCNN import cv2 # img = cv2.imread(&quot;me.jpg&quot;) detector = MTCNN() cap = cv2.VideoCapture(0) while True: ret,img = cap.read() faces = detector.detect_faces(img) for face in faces: x,y,w,h = face['box'] cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) cv2.imshow('img',img) if cv2.waitKey(1) &amp;0xFF == ord('q'): break cap.release() cv2.destroyAllWindows() 检测结果（脸太丑就遮起来了）： ","link":"https://Angus1996.github.io/post/OpenCV之使用MTCNN进行脸部特征检测/"},{"title":"OpenCV之使用Haar Cascade进行脸部特征检测","content":"OpenCV之使用Haar Cascade进行脸部特征检测 Haar Cascade常用来做人脸检测，其实它可以检测任何对象。OpenCV项目源码中有很多训练好的Haar分类器。如果你要检测什么物体，先Google，也许已经有训练好的Haar分类器了（像汽车、猫，狗之类的）。 使用OpenCV自带的Haar分类器检测脸和眼睛，代码： import cv2 import sys img = cv2.imread(sys.argv[1]) # 加载分类器 # 路径改为自己的opencv的文件路径 face_haar = cv2.CascadeClassifier(&quot;data/haarcascades/haarcascade_frontalface_default.xml&quot;) eye_haar = cv2.CascadeClassifier(&quot;data/haarcascades/haarcascade_eye.xml&quot;) # 把图像转为黑白图像 gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 检测图像中的所有脸 faces = face_haar.detectMultiScale(gray_img, 1.3, 5) for face_x,face_y,face_w,face_h in faces: cv2.rectangle(img, (face_x, face_y), (face_x+face_w, face_y+face_h), (0,255,0), 2) # 眼长在脸上 roi_gray_img = gray_img[face_y:face_y+face_h, face_x:face_x+face_w] roi_img = img[face_y:face_y+face_h, face_x:face_x+face_w] eyes = eye_haar.detectMultiScale(roi_gray_img, 1.3, 5) for eye_x,eye_y,eye_w,eye_h in eyes: cv2.rectangle(roi_img, (eye_x,eye_y), (eye_x+eye_w, eye_y+eye_h), (255,0,0), 2) cv2.imshow('img', img) cv2.waitKey(0) cv2.destroyAllWindows() 使用摄像头做为输入，实时检测： import cv2 face_haar = cv2.CascadeClassifier(&quot;data/haarcascades/haarcascade_frontalface_default.xml&quot;) eye_haar = cv2.CascadeClassifier(&quot;data/haarcascades/haarcascade_eye.xml&quot;) cam = cv2.VideoCapture(0) while True: _, img = cam.read() gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) faces = face_haar.detectMultiScale(gray_img, 1.3, 5) for face_x,face_y,face_w,face_h in faces: cv2.rectangle(img, (face_x, face_y), (face_x+face_w, face_y+face_h), (0,255,0), 2) roi_gray_img = gray_img[face_y:face_y+face_h, face_x:face_x+face_w] roi_img = img[face_y:face_y+face_h, face_x:face_x+face_w] eyes = eye_haar.detectMultiScale(roi_gray_img, 1.3, 5) for eye_x,eye_y,eye_w,eye_h in eyes: cv2.rectangle(roi_img, (eye_x,eye_y), (eye_x+eye_w, eye_y+eye_h), (255,0,0), 2) cv2.imshow('img', img) key = cv2.waitKey(30) &amp; 0xff if key == 27: break cam.release() cv2.destroyAllWindows() 上面我们使用的是训练好的分类器文件，如果你要检测的物体没有现成的Haar分类器，我们只能自己训练了，其中最费事的部分就是制作训练样本。 训练自己的Haar分类器可以参考http://blog.topspeedsnail.com/archives/10511 ","link":"https://Angus1996.github.io/post/OpenCV之使用Haar-Cascade进行脸部特征检测/"},{"title":"给Hexo + Github page博客绑定域名","content":"给Hexo + Github page博客绑定域名 域名申请 教你申请.tk/.ml/.cf/.gq/.ga等免费域名 绑定域名 然后在你的本地站点目录里的source目录下添加一个CNAME文件，不带后缀，效果如下： 以文本编辑器打开CNAME，里面添加你的域名信息（不加http://） 如下图 填写完了之后再重新部署到github pages上（部署简写命令hexo d -g) 下一步注册DNSpod，然后添加域名，添加记录即可。 添加域名填写你的域名即可，老规矩不用添加http://，然后在点击你的域名点进去在添加记录即可（其中记录中CHAME的值是你的github pages的地址）。 那么现在把你本地的Hexo生成一下在提交到Github pages上吧（生成和提交简写命令hexo d -g），然后打开你的浏览器输入你购买的域名尝试吧。 ","link":"https://Angus1996.github.io/post/给Hexo-Github-page博客绑定域名/"},{"title":"Ubuntu下查看进程pid及结束无响应程序","content":"Ubuntu下查看进程pid及结束无响应程序 在Windows系统中偶尔会碰到程序无响应的情况，大家都知道使用快捷键Ctrl+Alt+Del调出任务管理器，然后结束无响应的进程就OK了。但在Ubuntu系统里又应该如何强制关闭无响应程序呢？今天具体来总结学习一下。 PID:进程标识符，系统为每一个进程分配一个识别码，称为PID。 查看进程及PID 1、用 Ctrl+Shift+T来调出Terminal终端，输入 top，显示的全是现在系统的进程，按占用资源从多到少排列的找到要关掉的进程，记下该进程第一列的PID编号。 2、在终端，输入ps命令来查看进程及对应的PID。 ps命令极为常用，用于显示进程信息，参数可省略： -aux 以BSD风格显示进程 常用 -efH 以System V风格显示进程 -e , -A 显示所有进程 a 显示终端上所有用户的进程 x 显示无终端进程 u 显示详细信息 f 树状显示 w 完整显示信息 l 显示长列表 例如：在终端中输入：ps aux 各列输出字段的含义： 3、pstree 树状显示进程信息 -a 显示完整命令及参数 -c 重复进程分别显示 -c 显示进程ID PID -n 按 PID 排列进程 4、pgrep &lt;进程名&gt; 树状显示指定进程的信息，参数如下： -a 显示完整命令及参数 -c 重复进程分别显示 -c 显示进程ID PID -n 按 PID 排列进程 终止进程 结束进程的命令 有xkill、kill、pkill、killall等： 1、xkill ​ xkill ，一个在桌面用的杀死图形界面的程序，Ubuntu 上是默认安装的，所以无需重新安装。在终端输入xkill，此时光标会变成一个叉(按右键可以取消)，在无响应的程序界面点一下，即可终止进程。 注意：那个叉不要点到终端或系统界面，不然把系统进程终止了。 2、kill ​ 通过前面的内容，先查看要关闭的进程及对应的pid。然后在终端输入sudo kill pid即可。kill命令有很多参数选项，其中： kill -9 pid #用来强制终止指定pid进程（推荐使用此方法） kill -9 -1 #终止你拥有的全部进程 3、pkill &lt;进程名&gt; ​ 例如：在终端输入：pkill firefox 即可关闭火狐浏览器。 **pkill TIM.exe**，即可关闭TIM程序，解决TIM无法再次登陆的问题。 4、killall &lt;进程名&gt; ​ killall命令杀死同一进程组内的所有进程。其允许指定要终止的进程的名称，而非PID。和pkill类似。 如果想杀掉单个进程，还是用kill较好。 ","link":"https://Angus1996.github.io/post/Ubuntu下查看进程pid及结束无响应程序/"},{"title":"OpenCV深度神经网络实现人体姿态评估","content":"OpenCV深度神经网络实现人体姿态评估 OpenCV DNN模块介绍 OpenCV自从发布了DNN模块之后，就开始以开挂的方式支持各种深度学习预训练模型的调用，DNN模块的全称为深度神经网络，但是并不是所有深度学习模型导出到OpenCV DNN模块中都可以使用，只有那些OpenCV声明支持的层与网络模型才会被DNN模块接受,当期OpenCV支持的模型与层类型可以在下面链接中找到相关文档 https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV 模型下载 OpenCV3.4.x的版本开始支持在OpenCV DNN模块中使用openopse的深度学习模型,实现人体单人姿态评估, 首先需要下载人体姿态评估的预训练模型。 基于COCO数据集训练的模型下载地址如下：http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/coco/pose_iter_440000.caffemodel 基于MPI数据集训练的模型下载地址如下：http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel 代码实现 下面只需要如下几步就可以实现基于OpenCV的单人姿态评估： 定义COCO数据集支持的18点人体位置与关系位置 BODY_PARTS = { &quot;Nose&quot;: 0, &quot;Neck&quot;: 1, &quot;RShoulder&quot;: 2, &quot;RElbow&quot;: 3, &quot;RWrist&quot;: 4, &quot;LShoulder&quot;: 5, &quot;LElbow&quot;: 6, &quot;LWrist&quot;: 7, &quot;RHip&quot;: 8, &quot;RKnee&quot;: 9, &quot;RAnkle&quot;: 10, &quot;LHip&quot;: 11, &quot;LKnee&quot;: 12, &quot;LAnkle&quot;: 13, &quot;REye&quot;: 14, &quot;LEye&quot;: 15, &quot;REar&quot;: 16, &quot;LEar&quot;: 17, &quot;Background&quot;: 18 } POSE_PAIRS = [ [&quot;Neck&quot;, &quot;RShoulder&quot;], [&quot;Neck&quot;, &quot;LShoulder&quot;], [&quot;RShoulder&quot;, &quot;RElbow&quot;], [&quot;RElbow&quot;, &quot;RWrist&quot;], [&quot;LShoulder&quot;, &quot;LElbow&quot;], [&quot;LElbow&quot;, &quot;LWrist&quot;], [&quot;Neck&quot;, &quot;RHip&quot;], [&quot;RHip&quot;, &quot;RKnee&quot;], [&quot;RKnee&quot;, &quot;RAnkle&quot;], [&quot;Neck&quot;, &quot;LHip&quot;], [&quot;LHip&quot;, &quot;LKnee&quot;], [&quot;LKnee&quot;, &quot;LAnkle&quot;], [&quot;Neck&quot;, &quot;Nose&quot;], [&quot;Nose&quot;, &quot;REye&quot;], [&quot;REye&quot;, &quot;REar&quot;], [&quot;Nose&quot;, &quot;LEye&quot;], [&quot;LEye&quot;, &quot;LEar&quot;] ] 定义MPI数据集支持的15点人体位置与关系位置 BODY_PARTS = { &quot;Head&quot;: 0, &quot;Neck&quot;: 1, &quot;RShoulder&quot;: 2, &quot;RElbow&quot;: 3, &quot;RWrist&quot;: 4, &quot;LShoulder&quot;: 5, &quot;LElbow&quot;: 6, &quot;LWrist&quot;: 7, &quot;RHip&quot;: 8, &quot;RKnee&quot;: 9, &quot;RAnkle&quot;: 10, &quot;LHip&quot;: 11, &quot;LKnee&quot;: 12, &quot;LAnkle&quot;: 13, &quot;Chest&quot;: 14, &quot;Background&quot;: 15 } POSE_PAIRS = [ [&quot;Head&quot;, &quot;Neck&quot;], [&quot;Neck&quot;, &quot;RShoulder&quot;], [&quot;RShoulder&quot;, &quot;RElbow&quot;], [&quot;RElbow&quot;, &quot;RWrist&quot;], [&quot;Neck&quot;, &quot;LShoulder&quot;], [&quot;LShoulder&quot;, &quot;LElbow&quot;], [&quot;LElbow&quot;, &quot;LWrist&quot;], [&quot;Neck&quot;, &quot;Chest&quot;], [&quot;Chest&quot;, &quot;RHip&quot;], [&quot;RHip&quot;, &quot;RKnee&quot;], [&quot;RKnee&quot;, &quot;RAnkle&quot;], [&quot;Chest&quot;, &quot;LHip&quot;], [&quot;LHip&quot;, &quot;LKnee&quot;], [&quot;LKnee&quot;, &quot;LAnkle&quot;] ] 根据不同数据集调用DNN模块加载指定的预训练模型 inWidth = 368 inHeight = 368 thr = 0.1 protoc = &quot;D:/projects/pose_body/mpi/pose_deploy_linevec_faster_4_stages.prototxt&quot; model = &quot;D:/projects/pose_body/mpi/pose_iter_160000.caffemodel&quot; net = cv.dnn.readNetFromCaffe(protoc, model) 调用OpenCV打开摄像头 cap = cv.VideoCapture(0) height = cap.get(cv.CAP_PROP_FRAME_HEIGHT) width = cap.get(cv.CAP_PROP_FRAME_WIDTH) 使用前馈网络模型预测 frameWidth = frame.shape[1] frameHeight = frame.shape[0] inp = cv.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) net.setInput(inp) out = net.forward() 绘制检测到人体姿态关键点位置 points = [] for i in range(len(BODY_PARTS)): # Slice heatmap of corresponging body's part. heatMap = out[0, i, :, :] # Originally, we try to find all the local maximums. To simplify a sample # we just find a global one. However only a single pose at the same time # could be detected this way. _, conf, _, point = cv.minMaxLoc(heatMap) x = (frameWidth * point[0]) / out.shape[3] y = (frameHeight * point[1]) / out.shape[2] # Add a point if it's confidence is higher than threshold. points.append((x, y) if conf &gt; thr else None) for pair in POSE_PAIRS: partFrom = pair[0] partTo = pair[1] assert(partFrom in BODY_PARTS) assert(partTo in BODY_PARTS) idFrom = BODY_PARTS[partFrom] idTo = BODY_PARTS[partTo] if points[idFrom] and points[idTo]: x1, y1 = points[idFrom] x2, y2 = points[idTo] cv.line(frame, (np.int32(x1), np.int32(y1)), (np.int32(x2), np.int32(y2)), (0, 255, 0), 3) cv.ellipse(frame, (np.int32(x1), np.int32(y1)), (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED) cv.ellipse(frame, (np.int32(x2), np.int32(y2)), (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED) 完整的代码如下： import cv2 as cv import numpy as np dataset = 'MPI' if dataset == 'COCO': BODY_PARTS = { &quot;Nose&quot;: 0, &quot;Neck&quot;: 1, &quot;RShoulder&quot;: 2, &quot;RElbow&quot;: 3, &quot;RWrist&quot;: 4, &quot;LShoulder&quot;: 5, &quot;LElbow&quot;: 6, &quot;LWrist&quot;: 7, &quot;RHip&quot;: 8, &quot;RKnee&quot;: 9, &quot;RAnkle&quot;: 10, &quot;LHip&quot;: 11, &quot;LKnee&quot;: 12, &quot;LAnkle&quot;: 13, &quot;REye&quot;: 14, &quot;LEye&quot;: 15, &quot;REar&quot;: 16, &quot;LEar&quot;: 17, &quot;Background&quot;: 18 } POSE_PAIRS = [ [&quot;Neck&quot;, &quot;RShoulder&quot;], [&quot;Neck&quot;, &quot;LShoulder&quot;], [&quot;RShoulder&quot;, &quot;RElbow&quot;], [&quot;RElbow&quot;, &quot;RWrist&quot;], [&quot;LShoulder&quot;, &quot;LElbow&quot;], [&quot;LElbow&quot;, &quot;LWrist&quot;], [&quot;Neck&quot;, &quot;RHip&quot;], [&quot;RHip&quot;, &quot;RKnee&quot;], [&quot;RKnee&quot;, &quot;RAnkle&quot;], [&quot;Neck&quot;, &quot;LHip&quot;], [&quot;LHip&quot;, &quot;LKnee&quot;], [&quot;LKnee&quot;, &quot;LAnkle&quot;], [&quot;Neck&quot;, &quot;Nose&quot;], [&quot;Nose&quot;, &quot;REye&quot;], [&quot;REye&quot;, &quot;REar&quot;], [&quot;Nose&quot;, &quot;LEye&quot;], [&quot;LEye&quot;, &quot;LEar&quot;] ] else: assert(dataset == 'MPI') BODY_PARTS = { &quot;Head&quot;: 0, &quot;Neck&quot;: 1, &quot;RShoulder&quot;: 2, &quot;RElbow&quot;: 3, &quot;RWrist&quot;: 4, &quot;LShoulder&quot;: 5, &quot;LElbow&quot;: 6, &quot;LWrist&quot;: 7, &quot;RHip&quot;: 8, &quot;RKnee&quot;: 9, &quot;RAnkle&quot;: 10, &quot;LHip&quot;: 11, &quot;LKnee&quot;: 12, &quot;LAnkle&quot;: 13, &quot;Chest&quot;: 14, &quot;Background&quot;: 15 } POSE_PAIRS = [ [&quot;Head&quot;, &quot;Neck&quot;], [&quot;Neck&quot;, &quot;RShoulder&quot;], [&quot;RShoulder&quot;, &quot;RElbow&quot;], [&quot;RElbow&quot;, &quot;RWrist&quot;], [&quot;Neck&quot;, &quot;LShoulder&quot;], [&quot;LShoulder&quot;, &quot;LElbow&quot;], [&quot;LElbow&quot;, &quot;LWrist&quot;], [&quot;Neck&quot;, &quot;Chest&quot;], [&quot;Chest&quot;, &quot;RHip&quot;], [&quot;RHip&quot;, &quot;RKnee&quot;], [&quot;RKnee&quot;, &quot;RAnkle&quot;], [&quot;Chest&quot;, &quot;LHip&quot;], [&quot;LHip&quot;, &quot;LKnee&quot;], [&quot;LKnee&quot;, &quot;LAnkle&quot;] ] inWidth = 368 inHeight = 368 thr = 0.1 protoc = &quot;D:/projects/pose_body/mpi/pose_deploy_linevec_faster_4_stages.prototxt&quot; model = &quot;D:/projects/pose_body/mpi/pose_iter_160000.caffemodel&quot; net = cv.dnn.readNetFromCaffe(protoc, model) cap = cv.VideoCapture(0) height = cap.get(cv.CAP_PROP_FRAME_HEIGHT) width = cap.get(cv.CAP_PROP_FRAME_WIDTH) video_writer = cv.VideoWriter(&quot;D:/pose_estimation_demo.mp4&quot;, cv.VideoWriter_fourcc('D', 'I', 'V', 'X'), 15, (640, 480), True) while cv.waitKey(1) &lt; 0: hasFrame, frame = cap.read() if not hasFrame: cv.waitKey() break frameWidth = frame.shape[1] frameHeight = frame.shape[0] inp = cv.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) net.setInput(inp) out = net.forward() print(len(BODY_PARTS), out.shape[0]) # assert(len(BODY_PARTS) == out.shape[1]) points = [] for i in range(len(BODY_PARTS)): # Slice heatmap of corresponging body's part. heatMap = out[0, i, :, :] # Originally, we try to find all the local maximums. To simplify a sample # we just find a global one. However only a single pose at the same time # could be detected this way. _, conf, _, point = cv.minMaxLoc(heatMap) x = (frameWidth * point[0]) / out.shape[3] y = (frameHeight * point[1]) / out.shape[2] # Add a point if it's confidence is higher than threshold. points.append((x, y) if conf &gt; thr else None) for pair in POSE_PAIRS: partFrom = pair[0] partTo = pair[1] assert(partFrom in BODY_PARTS) assert(partTo in BODY_PARTS) idFrom = BODY_PARTS[partFrom] idTo = BODY_PARTS[partTo] if points[idFrom] and points[idTo]: x1, y1 = points[idFrom] x2, y2 = points[idTo] cv.line(frame, (np.int32(x1), np.int32(y1)), (np.int32(x2), np.int32(y2)), (0, 255, 0), 3) cv.ellipse(frame, (np.int32(x1), np.int32(y1)), (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED) cv.ellipse(frame, (np.int32(x2), np.int32(y2)), (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED) t, _ = net.getPerfProfile() freq = cv.getTickFrequency() / 1000 cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0)) # video_writer.write(frame); # cv.imwrite(&quot;D:/pose.png&quot;, frame) cv.imshow('OpenPose using OpenCV', frame) ","link":"https://Angus1996.github.io/post/OpenCV深度神经网络实现人体姿态评估/"},{"title":"如何用图卷积网络在图上做深度学习","content":"如何用图卷积网络（GCN）在图上做深度学习——翻译自此文 第一部分：对图卷积网络的高层次介绍 图上的机器学习是一项非常困难的任务，因为图是非常复杂但又是信息量丰富的图结构。这篇博客是介绍如何用图卷积网络在图上做深度学习的系列第一篇。GCN是一种非常厉害的神经网络，被设计来直接应用于图并使用图的结构信息。 在这篇博客中，我会对GCNs做个介绍并用代码实例来阐释信息是如何通过隐藏层进行传播的。我们将会明白GCN是如何从前面的层中聚集信息的，并且这种方法是如何产生途中节点的有用的特征表示。 什么是图卷积网络？ GCNs是一种非常有力的用于图上机器学习的神经网络结构。事实上，因为他们太厉害了以至于即使是随机初始化的2层的GCN也能产生网络中的节点的有用的特征表示。下图展示了产生网络中节点2维特征的GCN是如何不经训练保存他们的相对距离。 形式上，一个图卷积网络（GCN）是一种对图进行操作的神经网络。给定一个图$ G=(E,V) $ ,一个GCN网络将如下作为输入： 一个输入的维度${N} \\times {F}^{0} 的特征矩阵的特征矩阵的特征矩阵 X ，其中，，其中，，其中， N $ 是节点数量，$ F^{0}$ 是每个节点的输入特征数 一个 $N \\times N $ 的图结构矩阵表示，比如邻接矩阵$ A $ 一个GCN的隐藏层因此可以记作 $H^i = f(H^{i-1},A) ，其中，其中，其中 H^0 = X $ ，并且fff 是一次传播。每一层$ H^i $ 对应于一个$ N \\times F^i $ 的矩阵，矩阵的每一行是一个节点的特征表示。在每一层，这些特征聚集在一起在传播规则 $ f $ 的作用下形成下一层的特征。以此类推，特征在每一个连续的层变得越来越抽象。在这个框架下，各种各样的GCN只是在传播规则 fff 上有区别。 一种简单的传播规则 一种最简单的传播规则就是：$ f(H^i, A) = \\sigma(AHiWi) $ 其中$ W^i $ 是$ i 层的权重矩阵，层的权重矩阵，层的权重矩阵，\\sigma$ 是非线性激活函数（如ReLUReLUReLU 函数。权重矩阵的维度是$ F^i \\times F^{i+1} $ ，换句话说，权重矩阵的第个维度的大小决定了下一层的特诊数。如果你对卷积神经网络比较熟悉的话，这个操作和过滤操作非常相似，因为这些权重是被图中的节点所共享的。 简化 让我们的看看传播规则最简单的情况下是如何操作的。令： $ i=1，s.t. f $ 是输入特征矩阵的函数 σ\\sigmaσ 是恒等函数 选择权重 s.t.AH0W0=AXW0=AXs.t. AH^0W^0=AXW^0=AXs.t.AH0W0=AXW0=AX. 换句话说，f(X,A)=AXf(X,A)=AXf(X,A)=AX 。这种传播规则可能太简单了，但是稍后我们会加上丢失的部分。PS:现在 AXAXAX 等同于多层一个多层感知机的输入层。 一个简单的图实例 作为一个简单的案例，我们使用如下有向图： 如下是numpy 邻接矩阵表示 A = np.matrix([ [0, 1, 0, 0], [0, 0, 1, 1], [0, 1, 0, 0], [1, 0, 1, 0]], dtype=float ) 接下来，我们需要特征。我们基于每个的节点的索引（index）产生2个整数特征。这会使得后续的矩阵手动计算较为简单验证。 In [3]: X = np.matrix([ [i, -i] for i in range(A.shape[0]) ], dtype=float) X Out[3]: matrix([ [ 0., 0.], [ 1., -1.], [ 2., -2.], [ 3., -3.] ]) 应用传播规则 现在，我们有一张图，它的邻接矩阵AAA 和输入特征xxx 的集合。让我们看看应用传播规则后会发生什么呢？ In [6]: A * X Out[6]: matrix([ [ 1., -1.], [ 5., -5.], [ 1., -1.], [ 2., -2.]] 发现了没？每个节点的表示（每一行）现在是它的邻居特征的总和。换句话说，图卷积层用节点的邻居来表征每个节点。我鼓励你们自己验证以下。注意，在这个案例中，节点 nnn 是节点 vvv 的邻居如果从vvv到nnn存在一条边。 显而易见的问题！ 你也可能发现如下问题： 一个节点的汇集表示不包含自己的特征。一个节点的表征是它邻居节点的特征的汇集，所以只有自循环的节点才会在汇集后包含他们自身的特征 拥有大度数的节点在特征表征中会有较大的值，而度较小的节点特征表征的值也会小。这会导致梯度消失或者梯度爆炸，也是随机梯度下降算法的问题，随机梯度下降算法常被用来训练这种网络并且对每个输入特征的尺度范围较为敏感。 接下来，我分开讨论这两个问题。 加上自循环 为了解决第一个问题，只需给每个节点加上简单的自循环。实际上，只用给邻接矩阵AAA在应用传播规则之前加上一个单位矩阵III 。 In [4]: I = np.matrix(np.eye(A.shape[0])) I Out[4]: matrix([ [1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.] ]) In [8]: A_hat = A + I A_hat * X Out[8]: matrix([ [ 1., -1.], [ 6., -6.], [ 3., -3.], [ 5., -5.]]) 因为现在节点也是他自己的邻居，在求和邻居节点的特征时也包含了节点本身的特征！ 规范化特征表征 通过度矩阵DDD的逆D−1D^{-1}D−1 与邻接矩阵相乘，特征表征可以得到规范化。基于此，我们简化的传播规则如下： $ f(X, A)=D^{-1}AX $ 让我们看看会发生什么！我们先要计算度量矩阵。 In [9]: D = np.array(np.sum(A, axis=0))[0] D = np.matrix(np.diag(D)) D Out[9]: matrix([ [1., 0., 0., 0.], [0., 2., 0., 0.], [0., 0., 2., 0.], [0., 0., 0., 1.] ]) 在应用传播规则之前，我们看看邻接矩阵变形前后的变化。 A = np.matrix([ [0, 1, 0, 0], [0, 0, 1, 1], [0, 1, 0, 0], [1, 0, 1, 0]], dtype=float ) In [10]: D**-1 * A Out[10]: matrix([ [0. , 1. , 0. , 0. ], [0. , 0. , 0.5, 0.5], [0. , 0.5, 0. , 0. ], [1. , 0. , 1. , 0. ] ]) 观察可以发现，邻接矩阵每一行的权重已经被对应于这一行的节点的度除法运算了。我们对变形后的邻接矩阵应用传播规则。 In [11]: D**-1 * A * X Out[11]: matrix([ [ 1. , -1. ], [ 2.5, -2.5], [ 0.5, -0.5], [ 2. , -2. ] ]) 得到对应于邻居节点特征的均值的节点表示。这是因为变形后邻接矩阵中的权重对应于邻居节点特征加权和中的权重。还是同样的，鼓励你们自己验证一下结果。 将所有一起看 我们现在将自循环和规范化的方法结合。另外，我们会重新引入我们之前为了简化讨论所忽略的权重和激活函数。 加回权重 第一件要紧事就是加上权重。注意，这里的D_hatD\\_hatD_hat 是矩阵 A_hat=A+IA\\_hat = A+IA_hat=A+I 的度量矩阵， 即带有自循环的矩阵AAA的度量矩阵。 In [45]: W = np.matrix([ [1, -1], [-1, 1] ]) D_hat**-1 * A_hat * X * W Out[45]: matrix([ [ 1., -1.], [ 4., -4.], [ 2., -2.], [ 5., -5.] ]) 如果我们想要减少输出特征表征的维度，我们可以减小权重矩阵WWW的尺寸： In [46]: W = np.matrix([ [1], [-1] ]) D_hat**-1 * A_hat * X * W Out[46]: matrix([[1.], [4.], [2.], [5.]] ) 加上激活函数 我们选择保留特征表征的维度并且用上ReLUReLUReLU激活函数。 In [51]: W = np.matrix([ [1, -1], [-1, 1] ]) relu(D_hat**-1 * A_hat * X * W) Out[51]: matrix([[1., 0.], [4., 0.], [2., 0.], [5., 0.]]) 瞧！！一个带有邻接矩阵、输入特征、权重和激活函数的完整的隐藏层。 回归现实 现在，最后，我们可以应用图卷积网络在实际的图上。我会展示我们之前看到的如何产生特征表征。 Zachary's Karate Club Zachary's Karate Club 是广泛使用的社交网络，其中节点表示俱乐部的会员，边表示他们的相对关系。当Zachary在研究这个俱乐部时，一个在管理者和指导者之间的矛盾出现，导致俱乐部一分为二。下图展示网络的图表示，节点根据俱乐部的部分进行的标注。管理员和指导者分别记为AAA 和 III 。 建立GCN模型 现在，我们来建立图卷积网络。我们不会实际训练这个网络，只是简单随机初始化来产生我们在这篇博客一开始看到的特征表征。我们使用networkxnetworkxnetworkx ，它使得俱乐部的图表征简单易得，计算A_hatA\\_hatA_hat 和 D_hatD\\_hatD_hat 矩阵。 from networkx import to_numpy_matrix zkc = karate_club_graph() order = sorted(list(zkc.nodes())) A = to_numpy_matrix(zkc, nodelist=order) I = np.eye(zkc.number_of_nodes()) A_hat = A + I D_hat = np.array(np.sum(A_hat, axis=0))[0] D_hat = np.matrix(np.diag(D_hat)) 我们接下来随机初始化权重。 W_1 = np.random.normal( loc=0, scale=1, size=(zkc.number_of_nodes(), 4)) W_2 = np.random.normal( loc=0, size=(W_1.shape[1], 2)) 叠加GCN层。我们在这里使用单位矩阵作为特征表征，即每个节点用独热编码分类变量表示。 def gcn_layer(A_hat, D_hat, X, W): return relu(D_hat**-1 * A_hat * X * W) H_1 = gcn_layer(A_hat, D_hat, I, W_1) H_2 = gcn_layer(A_hat, D_hat, H_1, W_2) output = H_2 我们提取特征表征 feature_representations = { node: np.array(output)[node] for node in zkc.nodes()} 最后，瞧！特征表征清晰得俱乐部的团体，即使我们还没有开始训练。 我需要说明的是在这个例子中随机初始化的权重很有可能在ReLUReLUReLU函数后再x轴或者y轴是0，所以多随机几次才能产生上图。 结论 在这篇博客中，我从较高层次对图卷积网络进行了介绍并且阐释GCN每一层的每一个节点的特征表征是如何基于它们邻居的汇集。我们可以看到我们是如何通过numpy来构建网络，他们是如此强大：即使是随机初始化的GCNs也能分开俱乐部的团体。 ","link":"https://Angus1996.github.io/post/如何用图卷积网络在图上做深度学习/"},{"title":"python文字转图片","content":"文字转图片（支持中文） 最近在做中文输出时，发现opencv的putText方法不支持中文输出。导致中文在图片或者视频中都是问号（？）。查阅相关资料，有用pillow 和 freetype 进行格式转换，可以参考CSDN博客。 本文另辟蹊径，现将文字转换成图片，再进行图像的混合（blend）。 查阅相关资料，目前将文字转为图像的方法有两种，一种是利用 pillow 模块，一种是利用 pygame 模块。下面主要介绍如何利用 pygame 模块进行文字转图片。 pygame的安装 pip install pygame 文字转图片 import pygame pygame.init() #需要初始化 text = u&quot;Hello Word! 世界，你好！&quot; #将文本以unicode编码格式存储 # my_font = pygame.font.SysFont(“arial”, 16) # 使用系统字体 font = pygame.font.Font(&quot;F:\\\\SIMSUN.TTC&quot;, 60) #设置字体 ftext = font.render(text, True, (255, 255, 255, 0.3), (0,0,0)) #渲染字体 pygame.image.save(ftext, &quot;image.png&quot;) #存储图像 其中，“F:\\SIMSUN.TTC&quot;是本人下载的支持中文输出的一种字体。第一个参数是字体名，第二个自然就是大小，一般来说“Arial”字体在很多系统都是存在的，如果找不到的话，就会使用一个默认的字体，这个默认的字体和每个操作系统相关，你也可以使用**pygame.font.get_fonts()**来获得当前系统所有可用字体。 font.render() 第一个参数是写的文字；第二个参数是个布尔值，以为这是否开启抗锯齿，就是说True的话字体会比较平滑，不过相应的速度有一点点影响；第三个参数是字体的颜色；第四个是背景色，如果你想没有背景色（也就是透明），那么可以不加这第四个参数。比如上述代码，(255, 255, 255, 0.3) 是字体颜色，元组第四个代表alpha值，存为png图像会是RGBA格式；(0, 0, 0)是背景颜色，缺省为None（透明） 结果 1）白色字体，黑色背景 2）黑色字体，白色背景 参考链接 pygame官网 pygame.font的官方文档 PyGame Tutorial: Fonts and Text pygame-游戏开发学习笔记（五）–pygame.Font，字体与中文 ","link":"https://Angus1996.github.io/post/python文字转图片/"},{"title":"美赛经验分享","content":"美赛经验分享 距离2018年美赛已经过去差不多8个月了，8个月前的经历记忆犹新，如果时间能够重来，我还是不知道自己会作何选择。 美赛结果出来时，还是很高兴的。第一次参加美赛就拿到了M奖。第一次接触数学建模比赛时，是第十届华中地区数学建模邀请赛。也就是2017年五一期间参加的数学建模比赛。当时的比赛分为个人挑战赛、精英赛和经典赛。本人所在的小组，其中两人之前都没有任何数学建模的经验，所以选择了经典赛。经过三天的奋斗，拿到了三等奖。 2018年的寒假，也是我大学最后一个寒假，也是最后一次参加美赛的机会。由于已经保研，获奖加分的用处就显得不是很大了。不过很幸运，感谢华中赛时的一个队友。在她的促进下，我报名了这次的美赛。 同样应这位朋友的邀约，需要我写一篇经验帖。下面就简单给大家介绍一下自己的一些经验和感想。 美赛介绍 美国大学生数学建模竞赛（MCM/ICM）由美国数学及其应用联合会主办，是唯一的国际性数学建模竞赛，也是世界范围内最具影响力的数学建模竞赛。赛题内容涉及经济、管理、环境、资源、生态、医学、安全、未来科技等众多领域。竞赛要求三人（本科生）为一组，在四天时间内，就指定的问题完成从建立模型、求解、验证到论文撰写的全部工作，体现了参赛选手研究问题、解决方案的能力及团队合作精神。为现今各类数学建模竞赛之鼻祖。（摘自 百度百科——美国大学生数学建模竞赛） 官方介绍就是上面一段话。要说美赛作为一项国际性的数学建模比赛，和国内一些数学建模竞赛的区别的话，我觉得有这么几点。一是语言问题，美赛要求的论文是全英文写作，这对参赛队伍的英语水平有一定的要求；二是美赛注重解决实际的问题，国赛更像是解纯数学题。所以美赛更加需要发散性思维，但也不是让你乱思，是在前人的基础上去创新，所以千万不要忽视“前人的基础”，光勾勾地盯着“创新”。 赛前准备 美赛的报名会提前很久开始，想要参加这项的比赛的话，可以通过赛氪网（sarke）或者是数学中国提供的辅助报名方式。其中也可以选择证书打印服务。因为美赛只提供电子证书，想要纸质证书留念的同学可以选择两家提供的证书打印服务。参赛流程，美赛官网会给一份英文文档，中文文档可以参考各种网站提供的翻译版本。 正式比赛前的大量时间，可以用来未这次比赛做充足的准备。 队友选择 什么样的队友适合一起做比赛？ 看过很多知乎问题，什么情侣不适合一起做数学建模竞赛，因为做完一定吵架会分手。这也反映出数学建模比赛的一个特点，没有标准的答案。每个人都可以有自己的想法，每个人的想法对不对也只有实现了才知道。然而时间有限，一般也就三到四天，除非是非常厉害的人，可以三天内把所有想法都实现。一般都是不太现实的。所以，这个时候就要有所选择，小组内要有广泛地讨论。而讨论的目的就是确定一个比较好的思路。这就要求队友不会太自私、太固执、太一己之见。就本人而言，美赛时候，一名队友是认识交往超过一年的同一届同一个专业的同学，另一个是和我同一个高中毕业的学弟，学弟的秉性也有所了解。两个大四的为了兴趣为了获奖而参赛，学弟为了保研加分而参加比赛，这个队伍都会有一种积极向上的心态。 至于，队伍的性别搭配。网上很多人倡导一个女生两个男生的搭配，这是充分考虑的男生、女生的各自特点的。女生心细、思路较广泛，也比较有条理，而男生推理能力、编程解决问题的能力普遍比女生要好。然而，本人所在队伍虽然也是这种搭配，但是我觉得性别并不是很大的问题，能力和态度才是最重要的。认认真真做下去，不会想中途放弃。笔者认识一支队伍，比赛开始一个人放弃，导致另外两个人也没怎么做了，结果可想而知，他们只是拿了个S奖（成功参与奖）。 软件准备 编程 美赛要求的编程语言并没有限制。自己什么语言擅长便可以采用什么语言。笔者看过许多论文，有用matlab的，也有用C语言编写的程序。美赛通常也并不会要求上传代码或者在论文的附录种提供代码。当然，自己加上去也并不是不可以。 常用的算法，基本都可以在书或者网上找到相应的sample。如果是采用已有的算法，可以使用写好的代码进行改动。如果自己想出来的算法，则需要自己动手编程了。所以一般要求队伍里至少有一名队友阅读代码、编写代码的能力比较强。 画图 一篇论文的成功与否不仅取决于是否成功的解决了问题，更在于能否将解决问题的过程生动形象地向别人展示出来。许多会议的Best paper都是图文并茂、把自己的解决过程讲解地十分详细且生动。这也有助于审稿人对你想法的理解。如果审稿人都不理解你做的工作，又如何给你一个比较好的成绩呢？ 基本的画图工具是Excel，PS等等，也可以通过编程也实现画图。比如Matlab 画图，python的一系列可视化的库。这些都可以作为自己画图的基础进行学习。 数据处理 数据处理是解决问题十分重要的一个环节。要说，数据分析都可以一门职业了。数据如何让清洗、筛选，哪些数据是有用的、哪些数据是没用的。数据之间如何产生关联，如何归一化等等都需要一些数据处理的工作。 常用的数据处理工具包括Excel、SPSS等等。 翻墙梯子 美赛不同于国内的比赛，由于一些国内政策原因，有许多网站是难以直接访问的，比如Google。而Google搜索又比百度搜索比较好用（这一点应该都常识吧）。反正百度广告一大堆，有效信息太难获取。而访问一些被墙的网站就需要翻墙梯子了。常见的翻墙方法就是挂VPN。收费VPN比较稳定、可靠。 在赛前就应该准备自己队伍的翻墙工具。当然除了购买别人的，也可以自己搭建VPN。 论文写作 英文论文写作，我们要注意排版、字体差异。常见的文档写作工具应该就是word了（你要说WPS文档的话，我也没办法）。美赛有word模板，所谓的模板就是在这个文档基础上进行自己的再创作，从而完成自己的论文。 当然，国外也有比较流行的写作方式，即Latex。时间允许的话，建议队伍中的每个队员都学习一下。Latex相比较于word，更加方便，无论是敲公式还是交叉引用、排版。Latex使用的话，建议安装TexLive和TexStudio。使用方法网上都有很多视频，可以参考着，然后自己用Latex写一篇Latex教程来检验自己的掌握程度。当然，Latex的美赛模板也是有的。 知识储备 知识储备这一块，更多需要的是数学建模知识的学习。这里推荐《数模大全》和司守奎的《数学建模算法与应用》两本书。一章一章地学习，队伍内定期一起讨论这些算法。如果时间上不允许的话，每个队员至少应该对基本内容有所了解。包括算法的名字，主要作用、核心思想、应用场景等等。 除了算法之外，历年的O奖优秀论文都值得看一看。对照问题看一下他们的解决思路，也可以看一看他们的行文风格，写作特点。多学习学习。六种题型的O奖论文都要看一看，不能死磕在某一种题型上面。 MCM 类型 ICM 类型 A 连续型 D 运筹学/网络科学 B 离散型 E 环境科学 C 大数据 F 政策 这里推介一款思维导图的软件，可以将阅读心得、笔记进行总结。也可以用来做比赛中的发散的思路讨论。 赛中准备 赛前一天 由于是寒假，队伍中的同学最好还是晚点回家，聚集在学校里，找个地方。准备好比赛期间的电力供应、空调供应、零食和水等等。这些小困难，想要做比赛的话，还是要克服的。 赛前一天的晚上，不要太过劳累，早点休息。整个比赛对脑力、体力的耗费都很大的。许多人坐下来都会觉得心累。 比赛第一天 第一天早上北京时间九点一般就会出题目，美赛采用得是美国东部时间，和北京时间之间有十三个小时的时差。 第一天上午基本就要确定选题。大致看一下每个问题的描述，英文好的请尽量看英文，因为有些题目的翻译真的很坑！！！不能太过依赖于数学家或者数学中国提供的题目翻译版本。ABCDEF，六种不同的题目。队伍之间充分讨论，权衡每一个题目的难易度和自己的长处。在这里，要说明的是，有人会考虑每个题目选的人数，其实我觉得不用考虑。把自己擅长的做出来，总能拿奖的。 上午如果没有选完题目，下午顶多半个下午还可以再讨论讨论。确定题目之后，就是要就每个题目的各个问题进行讨论，队伍之间确定每个问题的解决方案、所需数据。当然也可以一个问题一个问题的思考，一个问题一个问题地解决。讨论过程中也可以查一查有没有类似问题的解决方案。第一天晚上，应该就解决第一个问题了。第一个问题一般不会需要数据支撑。 解决第一问之后，就要注意休息了。和平时一样休息就可以，不要刻意提前，那样只会睡不着反而烦闷。后面还有三天，所以第一天是不建议熬夜的。 比赛第二天 比赛第二天就要开始后续问题的解决了。数据查找上，可以一个人查找，一个人准备模型，一个人准备编程。也可以两个人查找数据，一个人准备模型和编程。数据基本包括模型要的数据、其他可以作为支撑的参考论文。除了Google和百度外，知网、外文数据库、世界银行、国家机构等的数据都是可以使用的。 找到数据之后，就要对数据处理，包括可视化、归一化、去噪声等等。数据处理之后就可以交给编程队员进行进行模型求解了。其他队员可以继续查找一些相关论文或者相关方法和报导。 第二天基本就要解决第二问并确定第三问如何具体开展。解决问题的过程要持续完善第一天的思路，有问题的地方就要及时改正。第二天同样不建议熬夜。 比赛第三天 第三天上午就要在第二天确定的第三问的具体开展计划上进行工作。如果没有更多数据可以查找处理了，编程队员和建模队友进行沟通。另外一个队员就可以先将前两天的结果进行整理，大致写出一个简要的中文文档。第三天下午进行最后一问的求解，一般为模型的推广。这一点最好所有队员一起讨论并确定推广方向。第三天晚上，基本就要把所有问题的求解的中文简要文档写出来了。 比赛第四天 比赛第四天也就是最后一天了，一名队员可以负责做一做模型的敏感性、鲁棒性、优缺点、前提假设条件分析。另外两名队员着手论文的翻译和完善工作了。可以前后分工，也可以分为文字的编写、和图片表格的Latex编写。第四天的晚上，就要一起写一份比较好的有特点的放着首页的summary。既言简意赅，又能把主要工作和思路突出出来。Summary sheet最好保持在一页。如果实在太多，在无法继续精简之后，尝试小一点的字号。 最后检查一遍之后就可以提交了。提交流程最好在赛前就了解清楚，不然四天就白做了。 总结 四天顺利做下来，其实每天都不用熬夜。笔者也就是最好一天写到凌晨两点，前面几天都没有熬夜。 当然，整个四天会遇到各种问题，需要三个人共同面对、解决。遇到没有思路的时候，多讨论讨论。比赛期间，每个人都应该知道队友在干嘛，不要每个人自己做自己的，这样的效率是十分低下的。 写在最后 想起18年美赛时候，笔者做完回到寝室，楼道里的灯坏了，一闪一闪的。整栋楼里差不多只有我一个人了，而那天阿姨又把我的电断了。还好手机那天没怎么用，还有80%多的电。第二天是情人节，然而还是一个人孤独地踏上了回家的路。很是感慨，竟然在本科的结尾做了这么一个比赛。不过学到的东西是很多的！ **最后，**祝愿每位数学建模人都有一个好的成绩，功夫不负有心人！ ​ 2018年10月19日星期五 ​ 华中科技大学南二舍 ","link":"https://Angus1996.github.io/post/美赛经验分享/"},{"title":"Mnist数据集图片化处理","content":"Mnist数据集图片化处理 Step1: 下载mnist数据集 可以去官网下载，也可以用我的我的百度云分享下载； 链接：https://pan.baidu.com/s/13MwGxwNkfvY85ISxaCAkrQ 提取码：pzn0 Step2:提取图片 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on 2018-10-17 @author: Angus Cai &quot;&quot;&quot; import os import struct import numpy as np import matplotlib.pyplot as plt from PIL import Image def load_mnist_image(path, filename, type = 'train'): full_name = os.path.join(path, filename) fp = open(full_name, 'rb') buf = fp.read() index = 0; magic, num, rows, cols = struct.unpack_from('&gt;IIII', buf, index) index += struct.calcsize('&gt;IIII') for image in range(0, num): im = struct.unpack_from('&gt;784B', buf, index) index += struct.calcsize('&gt;784B') im = np.array(im, dtype = 'uint8') im = im.reshape(28, 28) im = Image.fromarray(im) if (type == 'train'): isExists = os.path.exists('./train') if not isExists: os.mkdir('./train') im.save('./train/train_%s.jpeg' %image, 'jpeg') if (type == 'test'): isExists = os.path.exists('./test') if not isExists: os.mkdir('./test') im.save('./test/test_%s.jpeg' %image, 'jpeg') def load_mnist_label(path, filename, type = 'train'): full_name = os.path.join(path, filename) fp = open(full_name, 'rb') buf = fp.read() index = 0; magic, num = struct.unpack_from('&gt;II', buf, index) index += struct.calcsize('&gt;II') Labels = np.zeros(num) for i in range(num): Labels[i] = np.array(struct.unpack_from('&gt;B', buf, index)) index += struct.calcsize('&gt;B') if (type == 'train'): np.savetxt('./train_labels.csv', Labels, fmt='%i', delimiter=',') if (type == 'test'): np.savetxt('./test_labels.csv', Labels, fmt='%i', delimiter=',') return Labels if __name__ == '__main__': path = '.\\\\MNIST_data' # Mnist数据集所在路径 train_images = 'train-images.idx3-ubyte' load_mnist_image(path, train_images, 'train') train_labels = 'train-labels.idx1-ubyte' load_mnist_label(path, train_labels, 'train') test_images = 't10k-images.idx3-ubyte' load_mnist_image(path, test_images, 'test') test_labels = 't10k-labels.idx1-ubyte' load_mnist_label(path, test_labels, 'test') Step3：分类 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on 2018-10-17 @author: Angus Cai &quot;&quot;&quot; import shutil import numpy as np import os import csv image_path = &quot;.\\\\test\\\\&quot; dest0 = &quot;.\\\\0\\\\&quot; dest1 = &quot;.\\\\1\\\\&quot; dest2 = &quot;.\\\\2\\\\&quot; dest3 = &quot;.\\\\3\\\\&quot; dest4 = &quot;.\\\\4\\\\&quot; dest5 = &quot;.\\\\5\\\\&quot; dest6 = &quot;.\\\\6\\\\&quot; dest7 = &quot;.\\\\7\\\\&quot; dest8 = &quot;.\\\\8\\\\&quot; dest9 = &quot;.\\\\9\\\\&quot; label_path = &quot;./&quot; csvFile = open(&quot;test_labels.csv&quot;, &quot;r&quot;) labels = csv.reader(csvFile) for index, label in enumerate(labels): if int(&quot;&quot;.join(label)) == 0: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest0+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 1: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest1+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 2: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest2+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 3: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest3+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 4: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest4+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 5: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest5+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 6: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest6+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 7: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest7+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 8: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest8+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) if int(&quot;&quot;.join(label)) == 9: shutil.move(image_path+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;, dest9+&quot;test_&quot;+str(index)+&quot;.jpeg&quot;) print(index) # print(&quot;&quot;.join(label)) 分类好的Mnist图片数据集下载 链接：https://pan.baidu.com/s/1JGKEGudXBaFEK8eBuZ-EPw 提取码：4wnb ","link":"https://Angus1996.github.io/post/Mnist数据集图片化处理/"},{"title":"FFmpeg参数详细解释","content":"FFmpeg参数详细解释 a) 通用选项 -L license -h 帮助 -fromats 显示可用的格式，编解码的，协议的... -f fmt 强迫采用格式fmt -I filename 输入文件 -y 覆盖输出文件 -t duration 设置纪录时间 hh:mm:ss[.xxx]格式的记录时间也支持 -ss position 搜索到指定的时间 [-]hh:mm:ss[.xxx]的格式也支持 -title string 设置标题 -author string 设置作者 -copyright string 设置版权 -comment string 设置评论 -target type 设置目标文件类型(vcd,svcd,dvd) 所有的格式选项（比特率，编解码以及缓冲区大小）自动设置，只需要输入如下的就可以了：ffmpeg -i myfile.avi -target vcd /tmp/vcd.mpg -hq 激活高质量设置 -itsoffset offset 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件。该偏移被加到输入文件的时戳，定义一个正偏移意味着相应的流被延迟了 offset秒。 [-]hh:mm:ss[.xxx]的格式也支持 b) 视频选项 -b bitrate 设置比特率，缺省200kb/s -r fps 设置帧频 缺省25 -s size 设置帧大小 格式为WXH 缺省160X128.下面的简写也可以直接使用： Sqcif 128X96 qcif 176X144 cif 252X288 4cif 704X576 -aspect aspect 设置横纵比 4:3 16:9 或 1.3333 1.7777 -croptop size 设置顶部切除带大小 像素单位 -cropbottom size –cropleft size –cropright size -padtop size 设置顶部补齐的大小 像素单位 -padbottom size –padleft size –padright size –padcolor color 设置补齐条颜色(hex,6个16进制的数，红:绿:兰排列，比如 000000代表黑色) -vn 不做视频记录 -bt tolerance 设置视频码率容忍度kbit/s -maxrate bitrate设置最大视频码率容忍度 -minrate bitreate 设置最小视频码率容忍度 -bufsize size 设置码率控制缓冲区大小 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。 -sameq 使用同样视频质量作为源（VBR） -pass n 选择处理遍数（1或者2）。两遍编码非常有用。第一遍生成统计信息，第二遍生成精确的请求的码率 -passlogfile file 选择两遍的纪录文件名为file c)高级视频选项 -g gop_size 设置图像组大小 -intra 仅适用帧内编码 -qscale q 使用固定的视频量化标度(VBR) -qmin q 最小视频量化标度(VBR) -qmax q 最大视频量化标度(VBR) -qdiff q 量化标度间最大偏差 (VBR) -qblur blur 视频量化标度柔化(VBR) -qcomp compression 视频量化标度压缩(VBR) -rc_init_cplx complexity 一遍编码的初始复杂度 -b_qfactor factor 在p和b帧间的qp因子 -i_qfactor factor 在p和i帧间的qp因子 -b_qoffset offset 在p和b帧间的qp偏差 -i_qoffset offset 在p和i帧间的qp偏差 -rc_eq equation 设置码率控制方程 默认tex^qComp -rc_override override 特定间隔下的速率控制重载 -me method 设置运动估计的方法 可用方法有 zero phods log x1 epzs(缺省) full -dct_algo algo 设置dct的算法 可用的有 0 FF_DCT_AUTO 缺省的DCT 1 FF_DCT_FASTINT 2 FF_DCT_INT 3 FF_DCT_MMX 4 FF_DCT_MLIB 5 FF_DCT_ALTIVEC -idct_algo algo 设置idct算法。可用的有 0 FF_IDCT_AUTO 缺省的IDCT 1 FF_IDCT_INT 2 FF_IDCT_SIMPLE 3 FF_IDCT_SIMPLEMMX 4 FF_IDCT_LIBMPEG2MMX 5 FF_IDCT_PS2 6 FF_IDCT_MLIB 7 FF_IDCT_ARM 8 FF_IDCT_ALTIVEC 9 FF_IDCT_SH4 10 FF_IDCT_SIMPLEARM -er n 设置错误残留为n 1 FF_ER_CAREFULL 缺省 2 FF_ER_COMPLIANT 3 FF_ER_AGGRESSIVE 4 FF_ER_VERY_AGGRESSIVE -ec bit_mask 设置错误掩蔽为bit_mask,该值为如下值的位掩码 1 FF_EC_GUESS_MVS (default=enabled) 2 FF_EC_DEBLOCK (default=enabled) -bf frames 使用frames B 帧，支持mpeg1,mpeg2,mpeg4 -mbd mode 宏块决策 0 FF_MB_DECISION_SIMPLE 使用mb_cmp 1 FF_MB_DECISION_BITS 2 FF_MB_DECISION_RD -4mv 使用4个运动矢量 仅用于mpeg4 -part 使用数据划分 仅用于mpeg4 -bug param 绕过没有被自动监测到编码器的问题 -strict strictness 跟标准的严格性 -aic 使能高级帧内编码 h263+ -umv 使能无限运动矢量 h263+ -deinterlace 不采用交织方法 -interlace 强迫交织法编码仅对mpeg2和mpeg4有效。当你的输入是交织的并且你想要保持交织以最小图像损失的时候采用该选项。可选的方法是不交织，但是损失更大 -psnr 计算压缩帧的psnr -vstats 输出视频编码统计到vstats_hhmmss.log -vhook module 插入视频处理模块 module 包括了模块名和参数，用空格分开 D)音频选项 -ab bitrate 设置音频码率 -ar freq 设置音频采样率 -ac channels 设置通道 缺省为1 -an 不使能音频纪录 -acodec codec 使用codec编解码 E)音频/视频捕获选项 -vd device 设置视频捕获设备。比如/dev/video0 -vc channel 设置视频捕获通道 DV1394专用 -tvstd standard 设置电视标准 NTSC PAL(SECAM) -dv1394 设置DV1394捕获 -av device 设置音频设备 比如/dev/dsp F)高级选项 -map file:stream 设置输入流映射 -debug 打印特定调试信息 -benchmark 为基准测试加入时间 -hex 倾倒每一个输入包 -bitexact 仅使用位精确算法 用于编解码测试 -ps size 设置包大小，以bits为单位 -re 以本地帧频读数据，主要用于模拟捕获设备 -loop 循环输入流（只工作于图像流，用于ffserver测试） ","link":"https://Angus1996.github.io/post/FFmpeg参数详细解释/"},{"title":"FFmpeg的使用","content":"FFmpeg的使用 最近做视频抽帧处理的时候，利用opencv处理视频，原视频只有8M左右，抽帧处理后保存的视频竟然有56M！！！不可思议，输出视频的数据速率和总比特率有很大提升。然而，这并不是我想要的提升。在Opencv保存视频的参数中，没能找到设置码率的参数。最后求助于FFmpeg 什么是FFmpeg? FFmpeg是一个自由软件，可以运行音频和视频多种格式的录影、转换、流功能，包含了libavcodec ─这是一个用于多个项目中音频和视频的解码器库，以及libavformat——一个音频与视频格式转换库。 ffmpeg的官网地址是：https://ffmpeg.org/ ffmpeg的Github项目地址是：https://github.com/FFmpeg/FFmpeg FFmpeg的组成 FFmpeg的项目由一下部分组成： FFmpeg视频文件转换命令行工具,也支持经过实时电视卡抓取和编码成视频文件; ffserver基于HTTP、RTSP用于实时广播的多媒体服务器.也支持时间平移； ffplay用 SDL和FFmpeg库开发的一个简单的媒体播放器； libavcodec一个包含了所有FFmpeg音视频编解码器的库。为了保证最优性能和高可复用性，大多数编解码器从头开发的； libavformat一个包含了所有的普通音视格式的解析器和产生器的库。 谁在使用？ 使用FFMPEG作为内核视频播放器：Mplayer，ffplay，射手播放器，暴风影音，KMPlayer，QQ影音 使用FFMPEG作为内核的Directshow Filter：ffdshow，lav filters 使用FFMPEG作为内核的转码工具：格式工厂 如何安装？ FFmpeg可以在Windows、Linux还有Mac OS等多种操作系统中进行安装和使用。 这篇文章主要介绍其在Windows下面的安装： 下载编译好的Windows版本：http://ffmpeg.zeranoe.com/builds/（与官网同步） 解压缩，放入合适位置，并在系统的环境变量中添加bin目录路径 FFmpeg分为3个版本：Static、 Shared、 Dev 前两个版本可以直接在命令行中使用。包含了三个exe:ffmpeg.exe，ffplay.exe，ffprobe.exe Static版本中的exe体积较大,那是因为相关的Dll都已经编译进exe里面去了。 Shared版本中exe的体积相对小很多,是因为它们运行的时候还需要到相关的dll中调用相应的功能 Dev版本用于开发,里面包含了库文件xxx.lib以及头文件xxx.h 怎么使用？ 使用命令行工具 ffmpeg.exe 用于转码的应用程序，如以下代码将input.mp4转成码率为640kbps的视频output.mp4： ffmpeg.exe -i input.mp4 -b:v 640k output.mp4 具体用法可以参考：ffmpeg参数中文详细解释 英文官方说明：http://ffmpeg.org/ffmpeg.html ffplay.exe 主要用于播放音视频的应用程序 ffplay.exe test.avi 中文参考：https://blog.csdn.net/leixiaohua1020/article/details/15186441 英文参考：http://ffmpeg.org/ffplay.html ffprobe.exe 主要用于查看文件格式的应用程序 英文文档说明：http://ffmpeg.org/ffprobe.html 使用ffmpeg库进行开发 这部分内容暂时不作介绍 参考资料 FFmpeg官方文档 ","link":"https://Angus1996.github.io/post/FFmpeg的使用/"},{"title":"TFLite 使用mobilenet训练自己的数据集并部署到手机上","content":"TFLite 使用训练自己的数据集并部署到手机上 TFLite部分 第一步：下载代码 打开命令行工具输入以下命令行，从google 的codelabs下载代码： git clone https://github.com/googlecodelabs/tensorflow-for-poets-2 下载完后，会生成一个叫“tensorflow-for-poets”的文件夹。 文件夹内容的组成如下： scripts-----包含机器学习的python代码文件 tf_files-----包含输出文件，比如graph.pb和labels.txt android-----包含安卓app项目，又分为tfmobile和TFLite iOS----包含ios App的项目，需要使用xCode 第二步：下载数据集 下载链接 点击下载链接，下载约200MB的公开数据集，该数据集包含五种分类的花：Rose（玫瑰花）、Daisy（雏菊）、Dandelion（蒲公英）、Sunflower(向日葵) 解压缩到tf_files &gt; flowes_photos目录 第三步：重新训练模型 在tensorflow-for-poets-2目录中打开命令行工具，输入： python scripts/retrain.py --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir=tf_files/flower_photos --architecture=mobilenet_1.0_224 --summaries_dir tf_files/training_summaries/mobilenet_1.0_224 然后开始下载预训练的Mobilenet_1.0_224 的 frozen graph ；并且在tf_files目录中生成 retrained_graph.pb 和retrained_labels.txt 文件 第四步：打开Tensorboard（可跳过） 在Tensorboard中可以观察准确度和交叉熵损失函数的变化。 tensorboard --logdir=tf_files/training_summaries/mobilenet_1.0_244 第五步：确认模型的有效性 从互联网随机下载一张花的图片，放入工作目录中，查看模型识别结果 python scripts/label_image --graph=tf_files/retrained_graph.pb --image=new_rose.jpg 第六步：将模型转成TFLIte格式 系统要求：Ubuntu Toco 使用来将pb文件文件转成.lite格式文件的转换器，更多细节可以使用 toco --help 查看说明。 IMAGE_SIZE=224 toco --graph_def_file=tf_files/retrained_graph.pb --output_file=tf_files/optimized_graph.lite --output_format=TFLITE --input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 --input_array=input \\ --output_array=final_result --inference_type=FLOAT --inference_input_type=FLOAT 上述命令会在tf_files目录中生成optimized_graph.lite 文件 tips: 1)--input_file 已经更新成 --graph_def_file 2)--input_format 对于mobile_net 的计算图没有必要性 移动端部分 Android 第一步：模型和标签的替换 将 tf_files 中生成的 optimized_graph.lite 和 retrained_labels.txt，复制到android &gt;tflite项目的assets中，并替换原有的graph.lite 和 labels.txt 文件 cp tf_files/optimized_graph.lite android/tflite/app/src/main/assets/graph.lite cp tf_files/retrained_labels.txt android/tflite/app/src/main/assets/labels.txt 第二步：生成app 打开Android Studio，并打开已有项目，选中android/tflite目录，点击BUILD--&gt;Bulid APK， app-debug.apk文件就会产生，然后安装到安卓手机上。 IOS 安装Xcode xcode-select --install 安装Cocoapods sudo gem install cocoapods 安装 TFlite Cocoapod pod install --project-directory=ios/tflite/ 替换模型和文件 cp tf_files/optimized_graph.lite ios/tflite/data/graph.lite cp tf_files/retrained_labels.txt ios/tflite/data/labels.txt 打开模拟器，运行项目，查看结果。 ","link":"https://Angus1996.github.io/post/TFLite-使用mobilenet训练自己的数据集并部署到手机上/"},{"title":"轻量级学习论文梳理","content":"轻量级学习方法梳理 深度学习参数多，模型大，有许多研究来解决深度学习中的高效训练和推断。以下是文章的梳理： 浅层网络 1）Cybenko, G.: Approximation by superpositions of a sigmoidal function. Mathematics of control, signals and systems 2(4) (1989) 303–314 【paper】 2）Seide, F., Li, G., Yu, D.: Conversational speech transcription using context-dependent deep neural networks. In: Interspeech. (2011) 437–440 paper 3）Dauphin, Y.N., Bengio, Y.: Big neural networks waste capacity. arXiv preprint arXiv:1301.3583 (2013) paper 4）Ba, J., Caruana, R.: Do deep nets really need to be deep? In: Advances in neural information processing systems. (2014) 2654–2662 paper 压缩预训练的深度网络 1）Hanson, S.J., Pratt, L.Y.: Comparing biases for minimal network construction with backpropagation. In: Advances in neural information processing systems. (1989) 177–185 paper 2）LeCun, Y., Denker, J.S., Solla, S.A., Howard, R.E., Jackel, L.D.: Optimal brain damage. In: NIPs. Volume 89. (1989) paper 3）Hassibi, B., Stork, D.G.: Second order derivatives for network pruning: Optimal brain surgeon. Morgan Kaufmann (1993) paper 4）Han, S., Pool, J., Tran, J., Dally, W.: Learning both weights and connections for efficient neural network. In: Advances in Neural Information Processing Systems. (2015) 1135–1143 paper 5）Van Nguyen, H., Zhou, K., Vemulapalli, R.: Cross-domain synthesis of medical images using efficient location-sensitive deep network. In: Medical Image Computing and ComputerAssisted Intervention–MICCAI 2015. Springer (2015) 677–684 paper 6）Han, S., Mao, H., Dally, W.J.: Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149 (2015) paper 7）Chen, W., Wilson, J.T., Tyree, S., Weinberger, K.Q., Chen, Y.: Compressing neural networks with the hashing trick. arXiv preprint arXiv:1504.04788 (2015) paper 8）Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R.: Exploiting linear structure within convolutional networks for efficient evaluation. In: Advances in Neural Information Processing Systems. (2014) 1269–1277 paper 9）Jaderberg, M., Vedaldi, A., Zisserman, A.: Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:1405.3866 (2014) paper 设计紧凑的网络层 1）Lin, M., Chen, Q., Yan, S.: Network in network. arXiv preprint arXiv:1312.4400 (2013) paper 2）Szegedy, C., Ioffe, S., Vanhoucke, V.: Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR (2016) paper 3）Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K.: Squeezenet: Alexnet-level accuracy with 50x fewer parameters and¡ 1mb model size. arXiv preprint arXiv:1602.07360 (2016) paper 5）Howard A G, Zhu M, Chen B, et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications[J]. 2017. paper 量化参数 1）Gong, Y., Liu, L., Yang, M., Bourdev, L.: Compressing deep convolutional networks using vector quantization. arXiv preprint arXiv:1412.6115 (2014) paper 2）Arora, S., Bhaskara, A., Ge, R., Ma, T.: Provable bounds for learning some deep representations. arXiv preprint arXiv:1310.6343 (2013) paper 3）Vanhoucke, V., Senior, A., Mao, M.Z.: Improving the speed of neural networks on cpus. In: Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop. Volume 1. (2011) paper 4）Hwang, K., Sung, W.: Fixed-point feedforward deep neural network design using weights+ 1, 0, and- 1. In: Signal Processing Systems (SiPS), 2014 IEEE Workshop on, IEEE (2014) 1–6 paper 5）Anwar, S., Hwang, K., Sung, W.: Fixed point optimization of deep convolutional neural networks for object recognition. In: Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on, IEEE (2015) 1131–1135 paper 6）Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y.: Neural networks with few multiplications. arXiv preprint arXiv:1510.03009 (2015) paper 网络二值化 1）Courbariaux, M., Bengio, Y., David, J.P.: Training deep neural networks with low precision multiplications. arXiv preprint arXiv:1412.7024 (2014) paper 2）Soudry, D., Hubara, I., Meir, R.: Expectation backpropagation: parameter-free training of multilayer neural networks with continuous or discrete weights. In: Advances in Neural Information Processing Systems. (2014) 963–971 paper 3）Esser, S.K., Appuswamy, R., Merolla, P., Arthur, J.V., Modha, D.S.: Backpropagation for energy-efficient neuromorphic computing. In: Advances in Neural Information Processing Systems. (2015) 1117–1125 paper 4）Courbariaux, M., Bengio, Y., David, J.P.: Binaryconnect: Training deep neural networks with binary weights during propagations. In: Advances in Neural Information Processing Systems. (2015) 3105–3113 4, 6, 10, 11 paper 5）Courbariaux, M., Bengio, Y.: Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. CoRR (2016) 2, 3, 4, 6, 7, 10, 11, 12 paper 6）Wan, L., Zeiler, M., Zhang, S., Cun, Y.L., Fergus, R.: Regularization of neural networks using dropconnect. In: Proceedings of the 30th International Conference on Machine Learning (ICML-13). (2013) 1058–1066 paper 7）Baldassi, C., Ingrosso, A., Lucibello, C., Saglietti, L., Zecchina, R.: Subdominant dense clusters allow for simple learning and high computational performance in neural networks with discrete synapses. Physical review letters 115(12) (2015) 128101 paper 8）Kim, M., Smaragdis, P.: Bitwise neural networks. arXiv preprint arXiv:1601.06071 (2016) paper 9）Rastegari M, Ordonez V, Redmon J, et al. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks[C]// European Conference on Computer Vision. Springer International Publishing, 2016:525-542. paper ","link":"https://Angus1996.github.io/post/轻量级学习论文梳理/"},{"title":"opencv二值图像膨胀、腐蚀、开与闭运算python实现","content":"输入的原图 采用windows10自带的画图工具画了一张简单的三角形、四边形和圆形的图。 图像的腐蚀 卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是1，那么中心元素就保持原来的像素值，否则就变为零。 根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等。 import cv2 import numpy as np img = cv2.imread('test.jpg',0) kernel = np.ones((5,5),np.uint8) erosion = cv2.erode(img,kernel,iterations = 5) cv2.imwrite('erosion.jpg',erosion) cv2.imshow('erosion',erosion) cv2.waitKey() 腐蚀主要就是调用cv2.erode(img,kernel,iterations)，这个函数的参数是 第一个参数img：img指需要腐蚀的图 第二个参数kernel：kernel指腐蚀操作的内核，默认是一个简单的3X3矩阵，我们也可以利用getStructuringElement（）函数指明它的形状 第三个参数iterations：iterations指的是腐蚀次数，省略是默认为1 腐蚀后的图像如下图所示： 图像的膨胀 与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是1，中心元素的像素值就是1。所以这个操作会增加图像中的白色区域（前景）。一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体。 dilation = cv2.dilate(img,kernel,iterations = 1) 膨胀主要就是调用cv2.dilate(img,kernel,iterations)，这个函数的参数是 第一个参数img：img指需要膨胀的图 第二个参数kernel：kernel指膨胀操作的内核，默认是一个简单的3X3矩阵，我们也可以利用getStructuringElement（）函数指明它的形状 第三个参数iterations：iterations指的是膨胀次数，省略是默认为1 膨胀后的图像如下图所示（此处的内核是3*3）： 图像的开运算 先进性腐蚀再进行膨胀就叫做开运算。就像我们上面介绍的那样，它被用来去除噪声。这里我们用到的函数是cv2.morphologyEx() opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) 开运算后的图像如下图所示： 图像的闭运算 先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。 closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel) 闭运算后的图像如图所示： ","link":"https://Angus1996.github.io/post/opencv二值图像膨胀、腐蚀、开与闭运算python实现/"},{"title":"Xposed & VirtualXposed使用简介","content":"今天简单介绍一下安卓手机中非常有用的两个框架，一个是Xposed框架，一个VirtualXposed框架。人们常说安卓 Android 比苹果 iOS 更具可玩性，其中最能体现这一点的就数 Xposed 框架了，它能让你使用各种“模块”，像外挂一样去修改系统或 APP 来获得不同的新功能特性。 之前想要玩 Xposed 框架，最麻烦在于必须 Root 设备，还要解锁 Bootloader 刷 Recovery，承担手机变砖和系统安全性方面的风险，对很多用户来说上手难度门槛较高。不过，随着黑科技般的 VirtualXposed 出现，大家终于可以免 Root 权限直接使用 Xposed 框架 Xposed框架 Xposed简介 Xposed框架是一款可以在不修改APK的情况下影响程序运行(修改系统)的框架服务，基于它可以制作出许多功能强大的模块，且在功能不冲突的情况下同时运作。（From 百度百科-Xposed框架 词条） Xposed原理 xposed 原理就是修改系统的关键文件，然后当APP调用系统API时，首先经过xposed，而这些基于xposed的模块就可以选择性的在App调用这些api的时候干一些”坏坏”的事情，或者修改返回的结果，这样app在运行的时候效果就会改变，但app本身并没有被破坏，只是调用系统api的时候，Android系统的表现发生了变化，这就是钩子，专业术语hook。所以，说白了，xposed就是个强大的钩子框架。 来一段专业的原理解释吧： 作者通过替换 /system/bin/app_precesss 程序控制zygote进程，使得它在系统启动的过程中会加载Xposed framework的一个jar文件即XposedBridge.jar，从而完成对Zygote进程及其创建的Dalvik虚拟机的劫持，并且能够允许开发者独立的替代任何class，例如framework本身，系统UI又或者随意的一个app。除此之外使用这种方法的好处是ROM，APP都没有产生任何变化，因此理论上就不会造成设备变砖，同时撤掉修改也非常容易，仅需要停用 Xposed framework 即可完全恢复原样。 Xposed Author(s) rovo89, Tungstwenty 几个有用的链接 Xposed官网链接(已被墙) 中文官网 Android 系统上的 Xposed 框架中都有哪些值得推荐的模块？———知乎 VirtualXposed VXP简介 VirtualXposed 是基于VirtualApp 和 epic 在非ROOT环境下运行Xposed模块的实现（支持5.0~8.1)。一直以来Xposed框架最大的入门难度就在于设备需要Root，然后还要Recovery，还有承担变砖的各种搞基风险，现在这一切都不用再担心了！感谢Xposed作者rov89，感谢VirtualApp作者asLody@github！目前来看VirtualXposed的稳定性已经相当出色了！ 下载 首先在 VirtualXposed发布页面 下载最新的VAExposed安装包安装到手机。 界面 框架页面 应用界面 管理界面 使用 安装模块的方式 打开 VirtualXposed，在里面安装要使用的APP，以及相应的Xposed模块即可。 注意：所有的工作（安装Xposed模块，安装APP）必须在 VirtualXposed中进行，否则Xposed模块不会有任何作用！比如，将微信直接安装在系统上（而非VirtualXposed中），防撤回安装在VirtualXposed中；或者把微信安装在VirtualXposed上，防撤回插件直接安装在系统上；或者两者都直接安装在系统上，均不会起任何作用。 在VirtualXposed中安装App的方式 直接复制已经在系统中安装好的APP，比如如果你系统中装了微信，那么可以直接复制一份。 通过外置存储直接安装APK文件；点主界面的➕，然后选择后面两个TAB即可。 在VirtualXposed中安装Xposed模块，可以跟安装正常的APK一样，以上两种安装App的方式也适用于安装Xposed模块。不过，你也可以通过VirtualXposed中内置的XposedInstaller来安装和管理模块，跟通常的XposedInstaller使用方式一样；去下载页面，下载安装即可。 VirtualXposed已知问题 由于暂不支持资源HOOK，因此资源钩子不会起任何作用；使用资源HOOK的模块，相应的功能不会生效。部分插件的兼容性有问题，比如QX模块。 链接 VirtualXposed主页——Github ","link":"https://Angus1996.github.io/post/Xposed-VirtualXposed使用简介/"},{"title":"python常用图像库读取、存储图像","content":"python各类图像库的图片读写方式总结 Python中操作图像的方法包括opencv，matplotlib，PIL(pillow)，scipy.misc, skimage。下面分别进行单独介绍： opencv opencv是今天介绍得所有图像库中最全面也最强大的库，如果我们只想掌握一个图像库，我觉得opencv库肯定是最适合的图像处理库。 图像读取操作 import cv2 import numpy as np #读入图片：默认彩色图，cv2.IMREAD_GRAYSCALE灰度图，cv2.IMREAD_UNCHANGED包含alpha通道 img = cv2.imread('E:\\图片森绘梨佳.jpeg') cv2.imshow('src',img) print(img.shape) # 图像的尺寸(h,w,c) print(img.size) # 像素总数目 print(img.dtype) print(img) cv2.waitKey() 值得注意的是，opencv读进来的图片已经是一个numpy矩阵了，彩色图片维度是（高度，宽度，通道数）。数据类型是uint8。 #gray = cv2.imread('1.jpg',cv2.IMREAD_GRAYSCALE) #灰度图 #cv2.imshow('gray',gray) #也可以这么写，先读入彩色图，再转灰度图 src = cv2.imread('F:/senhuilijia.jpeg') gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY) cv2.imshow('gray',gray) print(gray.shape) print(gray.size) print(gray) cv2.waitKey() 上面提到了两种获取灰度图的方式，读进来的灰度图的矩阵格式是（高度，宽度）。注意，计算图片路径是错的，Opencv也不会提醒你，但print img时得到的结果是None. #如何解决“读到的图片不存在的问题”？ #加入判断语句，如果为空，做异常处理 img2 = cv2.imread('2.jpg') if img2 == None: print('fail to load image!') 图像矩阵转换 opencv读入图片的矩阵格式是：（height,width,channels）。而在深度学习中，因为要对不同通道应用卷积，所以会采取另一种方式：（channels,height,width）。为了应对该要求，我们可以这么做 #注意到，opencv读入的图片的彩色图是一个channel last的三维矩阵（h,w,c），即（高度，宽度，通道） #有时候在深度学习中用到的的图片矩阵形式可能是channel first，那我们可以这样转一下 print(img.shape) img = img.transpose(2,0,1) print(img.shape) 在深度学习搭建CNN时，往往要做相应的图像数据处理，比如图像要扩展维度，比如扩展成（batch_size,channels,height,width）。对于这种要求，我们可以这么做。 #有时候还要扩展维度，比如有时候我们需要预测单张图片，要在要加一列做图片的个数，可以这么做 img = np.expand_dims(img, axis=0) print(img.shape) 上面提到的是预测阶段时预测单张图片的扩展维度的操作，如果是训练阶段，构建batch，即得到这种形式：（batch_size,channels,height,width）。 data_list = [] loop: im = cv2.imread('xxx.png') data_list.append(im) data_arr = np.array(data_list) 图像归一化 #因为opencv读入的图片矩阵数值是0到255，有时我们需要对其进行归一化为0~1 img3 = cv2.imread('1.jpg') img3 = img3.astype(&quot;float&quot;) / 255.0 #注意需要先转化数据类型为float print(img3.dtype) print(img3) 图像存储 #存储图片 cv2.imwrite('test1.jpg',img3) #得到的是全黑的图片，因为我们把它归一化了 #所以要得到可视化的图，需要先*255还原 img3 = img3 * 255 cv2.imwrite('test2.jpg',img3) #这样就可以看到彩色原图了 opencv之BGR opencv对于读进来的图片的通道排列是BGR，而不是主流的RGB！谨记！ #opencv读入的矩阵是BGR，如果想转为RGB，可以这么转 img4 = cv2.imread('1.jpg') img4 = cv2.cvtColor(img4,cv2.COLOR_BGR2RGB) 访问像素 #访问像素 print(img4[10,10]) #3channels print(gray[10,10]) #1channel img4[10,10] = [255,255,255] gray[10,10] = 255 print(img4[10,10]) #3channels print(gray[10,10]) #1channel ROI操作 #roi操作 roi = img4[200:550,100:450,:] cv2.imshow('roi',roi) cv2.waitKey() 通道操作 #分离通道 img5 = cv2.imread('1.jpg') b,g,r = cv2.split(img5) #合并通道 img5 = cv2.merge((b,g,r)) #也可以不拆分 img5[:,:,2] = 0 #将红色通道值全部设0 PIL PIL即Python Imaging Library，也即为我们所称的Pillow，是一个很流行的图像库，它比opencv更为轻巧，正因如此，它深受大众的喜爱。 图像读取 PIL读进来的图像是一个对象，而不是我们所熟知的numpy 矩阵。 from PIL import Image import numpy as np img = Image.open('F:/senhuilijia.jpeg') print(img.format) print(img.size) #注意，省略了通道 (w，h) print(img.mode) #L为灰度图，RGB为真彩色,RGBA为加了透明通道 img.show() # 显示图片 灰度图的获取 gray = Image.open('F:/senhuilijia.jpeg').convert('L') gray.show() #读取不到图片会抛出异常IOError，我们可以捕捉它，做异常处理 try: img2 = Image.open('2.jpg') except IOError: print('fail to load image!') #pillow读进来的图片不是矩阵，我们将图片转矩阵,channel last arr = np.array(img3) print(arr.shape) print(arr.dtype) print(arr) 灰度图的转化与彩图转化一样 arr_gray = np.array(gray) print(arr_gray.shape) print(arr_gray.dtype) print(arr_gray) 图像的存储 #矩阵再转为图像 new_im = Image.fromarray(arr) new_im.save('3.png') 图像操作 #分离合并通道 r, g, b = img.split() img = Image.merge(&quot;RGB&quot;, (b, g, r)) img = img.copy() #复制图像 ROI获取 img3 = Image.open('F:/senhuilijia.jpeg') roi = img3.crop((0,0,300,300)) #(左上x，左上y，右下x，右下y)坐标 roi.show() matplotlib matplotlib是一个科学绘图库。 图像的读取 import matplotlib.pyplot as plt import numpy as np image = plt.imread('1.jpg') plt.imshow(image) plt.show() #也可以关闭显示x，y轴上的数字 image = plt.imread('1.jpg') plt.imshow(image) plt.axis('off') plt.show() #plt.imread读入的就是一个矩阵，跟opencv一样，但彩图读进的是RGB，与opencv有区别 print(image.shape) # (h,w,c) print(image.size) print(image.dtype) print(image) im_r = image[:,:,0] #红色通道 plt.imshow(im_r) plt.show() #此时会发现显示的是热量图，不是我们预想的灰度图，可以添加 cmap 参数解决 plt.imshow(im_r,cmap='Greys_r') plt.show() 与opencv结合使用 #与opencv结合使用 import cv2 im2 = cv2.imread('1.jpg') plt.imshow(im2) plt.axis('off') plt.show() #发现图像颜色怪怪的，原因当然是我们前面提到的RGB顺序不同的原因啦,转一下就好 im2 = cv2.cvtColor(im2,cv2.COLOR_BGR2RGB) plt.imshow(im2) plt.axis('off') plt.show() #所以无论用什么库读进图片，只要把图片改为矩阵，那么matplotlib就可以处理了 与pillow结合使用 #再试一试pillow和matplotlib结合 from PIL import Image im3 = Image.open('1.jpg') im3 = np.array(im3) plt.figure(1) plt.imshow(im3) plt.axis('off') #存储图像，注意，必须在show之前savefig，否则存储的图片一片空白 plt.savefig('timo.jpg') plt.show() 综合例子 #最后以一个综合例子总结matplotlib最基本的图片显示技巧吧 im_lol1 = plt.imread('lol.jpg') im_lol2 = plt.imread('1.jpg') figure = plt.figure(figsize=(20,10)) # 调整显示图片的大小 ''' figsize参数：指定绘图对象的宽度和高度，单位为英寸；dpi参数指定绘图对象的分辨率， 即每英寸多少个像素，缺省值为80。因此本例中所创建的图表窗口的宽度为8*80 = 640像素 ''' plt.axis(&quot;off&quot;)#不显示刻度 ax = figure.add_subplot(121) # 图片以1行2列的形式显示 plt.axis('off') ax.imshow(im_lol1) #第一张图 ax.set_title('lol image 1')#给图片加titile ax = figure.add_subplot(122) plt.axis('off') ax.imshow(im_lol2) ax.set_title('lol image 2')#给图片加titile plt.savefig('twp.jpg') plt.show() scipy.misc from scipy import misc import matplotlib.pyplot as plt im = misc.imread('1.jpg') print(im.dtype) print(im.size) print(im.shape) misc.imsave('misc1.png',im) plt.imshow(im) plt.show() print(im) imageio import imageio import matplotlib.pyplot as plt im2 = imageio.imread('1.jpg') print(im2.dtype) print(im2.size) print(im2.shape) plt.imshow(im) plt.show() print(im2) imageio.imsave('imageio.png',im2) skimage from skimage import io im = io.imread('1.jpg') print(im.shape) # numpy矩阵，(h,w,c) print(im.dtype) print(im.size) io.imshow(im) io.imsave('sk.png',im) print(im) 灰度图的获取 im2 = io.imread('1.jpg',as_grey=True) #读入灰度图 print(im2.dtype) print(im2.size) print(im2.shape) io.imshow(im2) io.imsave('sk_gray.png',im2) io.show() print(im2) 也可以以这种方式获得灰度图： from skimage import color im3 = io.imread('1.jpg') im3 = color.rgb2grey(im3) print(im3.dtype) print(im3.size) print(im3.shape) io.imshow(im3) io.show() ''' skimage.color.rgb2grey(rgb) skimage.color.rgb2hsv(rgb) skimage.color.rgb2lab(rgb) skimage.color.gray2rgb(image) skimage.color.hsv2rgb(hsv) skimage.color.lab2rgb(lab) ''' 总结 除了opencv读入的彩色图片以BGR顺序存储外，其他所有图像库读入彩色图片都以RGB存储。 除了PIL读入的图片是img类之外，其他库读进来的图片都是以numpy 矩阵。 各大图像库的性能，老大哥当属opencv，无论是速度还是图片操作的全面性，都属于碾压的存在，毕竟他是一个巨大的cv专用库。下面那张图就是我从知乎盗来的一张关于各个主流图像库的一些性能比较图，从测试结果看来，opencv确实胜出太多了。 ","link":"https://Angus1996.github.io/post/python常用图像库读取、存储图像/"},{"title":"python数字图像--Canny边缘检测","content":"简介： 1.Canny边缘检测算子是John F. Canny于 1986 年开发出来的一个多级边缘检测算法。 2.Canny 的目标是找到一个最优的边缘检测算法，最优边缘检测的含义是： 好的检测- 算法能够尽可能多地标识出图像中的实际边缘。 好的定位- 标识出的边缘要尽可能与实际图像中的实际边缘尽可能接近。 最小响应- 图像中的边缘只能标识一次，并且可能存在的图像噪声不应标识为边缘。 3.算法步骤： ①高斯模糊 - GaussianBlur ②灰度转换 - cvtColor ③计算梯度 – Sobel/Scharr ④非最大信号抑制 ⑤高低阈值输出二值图像 代码如下 #Canny边缘提取 import cv2 as cv def edge_demo(image): blurred = cv.GaussianBlur(image, (3, 3), 0) gray = cv.cvtColor(blurred, cv.COLOR_RGB2GRAY) # xgrad = cv.Sobel(gray, cv.CV_16SC1, 1, 0) #x方向梯度 # ygrad = cv.Sobel(gray, cv.CV_16SC1, 0, 1) #y方向梯度 # edge_output = cv.Canny(xgrad, ygrad, 50, 150) edge_output = cv.Canny(gray, 50, 150) cv.imshow(&quot;Canny Edge&quot;, edge_output) cv.imwrite('D:/edge_output.jpg', edge_output) dst = cv.bitwise_and(image, image, mask= edge_output) cv.imshow(&quot;Color Edge&quot;, dst) cv.imwrite('D:/dst.jpg', dst) src = cv.imread('D:/xinmuyouzi.jpg') cv.namedWindow('input_image', cv.WINDOW_NORMAL) #设置为WINDOW_NORMAL可以任意缩放 cv.imshow('input_image', src) edge_demo(src) cv.waitKey(0) cv.destroyAllWindows() 注：其中第9行代码可以用6、7、8行代码代替！两种方法效果一样。 运行结果： 注意： OpenCV的Canny函数用于在图像中查找边缘，其函数原型有两种： ①直接调用Canny算法在单通道灰度图像中查找边缘， 其函数原型为：Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -&gt; edges image参数表示8位输入图像。 threshold1参数表示设置的低阈值。 threshold2参数表示设置的高阈值，一般设定为低阈值的3倍 (根据Canny算法的推荐)。 edges参数表示输出边缘图像，单通道8位图像。 apertureSize参数表示Sobel算子的大小。 L2gradient参数表示一个布尔值，如果为真，则使用更精确的L2范数进行计算（即两个方向的倒数的平方和再开方），否则使用L1范数（直接将两个方向导数的绝对值相加）。 ②使用带自定义图像渐变的Canny算法在图像中查找边缘， 其函数原型为：Canny(dx, dy, threshold1, threshold2[, edges[, L2gradient]]) -&gt; edges dx参数表示输入图像的x导数（x导数满足16位，选择CV_16SC1或CV_16SC3） dy参数表示输入图像的y导数（y导数满足16位，选择CV_16SC1或CV_16SC3）。 threshold1参数表示设置的低阈值。 threshold2参数表示设置的高阈值，一般设定为低阈值的3倍 (根据Canny算法的推荐)。 edges参数表示输出边缘图像，单通道8位图像。 L2gradient参数表示L2gradient参数表示一个布尔值，如果为真，则使用更精确的L2范数进行计算（即两个方向的倒数的平方和再开方），否则使用L1范数（直接将两个方向导数的绝对值相加）。 参考： Canny算子原理：https://www.cnblogs.com/techyan1990/p/7291771.html http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html https://blog.csdn.net/sunny2038/article/details/9202641 ","link":"https://Angus1996.github.io/post/python数字图像--Canny边缘检测/"},{"title":"python处理excel表格","content":"Python对Excel的读写主要有xlrd、xlwt、xlutils、openpyxl、xlsxwriter几种 ##1.xlrd主要是用来读取excel文件 import xlrd workbook = xlrd.open_workbook(u'test.xls') sheet_names= workbook.sheet_names() for sheet_name in sheet_names: sheet2 = workbook.sheet_by_name(sheet_name) print sheet_name rows = sheet2.row_values(3) # 获取第四行内容 cols = sheet2.col_values(1) # 获取第二列内容 print rows print cols ##2.xlwt主要是用来写excel文件 import xlwt wbk = xlwt.Workbook() sheet = wbk.add_sheet('sheet 1') sheet.write(0,1,'测试数据')#第0行第一列写入内容 wbk.save('test.xls') ##3.xlutils结合xlrd可以达到修改excel文件目的 import xlrd from xlutils.copy import copy workbook = xlrd.open_workbook(u'test.xls') workbooknew = copy(workbook) ws = workbooknew.get_sheet(0) ws.write(3, 0, 'changed!') workbooknew.save(u'testCopy.xls') 4.openpyxl可以对excel文件进行读写操作 from openpyxl import Workbook from openpyxl import load_workbook from openpyxl.writer.excel import ExcelWriter workbook_ = load_workbook(u&quot;test.xlsx&quot;) sheetnames =workbook_.get_sheet_names() #获得表单名字 print sheetnames sheet = workbook_.get_sheet_by_name(sheetnames[0]) print sheet.cell(row=3,column=3).value sheet['A1'] = '47' workbook_.save(u&quot;test_new.xlsx&quot;) wb = Workbook() ws = wb.active ws['A1'] = 4 wb.save(&quot;test_new2.xlsx&quot;) 5.xlsxwriter可以写excel文件并加上图表 import xlsxwriter def get_chart(series): chart = workbook.add_chart({'type': 'line'}) for ses in series: name = ses[&quot;name&quot;] values = ses[&quot;values&quot;] chart.add_series({ 'name': name, 'categories': 'A2:A10', 'values':values }) chart.set_size({'width': 700, 'height': 350}) return chart if name == 'main': workbook = xlsxwriter.Workbook(u'test.xlsx') worksheet = workbook.add_worksheet(u&quot;每日PV,UV&quot;) headings = ['日期', '平均值'] worksheet.write_row('A1', headings) index=0 for row in range(1,10): for com in [0,1]: worksheet.write(row,com,index) index+=1 series = [{&quot;name&quot;:&quot;平均值&quot;,&quot;values&quot;:&quot;B2:B10&quot;}] chart = get_chart(series) chart.set_title ({'name': 'Test'}) worksheet.insert_chart('H7', chart) workbook.close() ","link":"https://Angus1996.github.io/post/python处理excel表格/"},{"title":"python3 利用opencv读取视频并获取视频相关信息","content":"python3 利用opencv读取视频并获取视频相关信息 import cv2 cap=cv2.VideoCapture(path) #path即视频文件的路径 video_feature = cap.get(propId) #获取视频相关性质，利用get()方法，传入性质ID fram_count = cap.get(7) #获取视频总帧数 fps = cap.get(5) #获取视频帧率 get方法参数按顺序对应下表（从0开始编号，比如这里为了获取视频的总帧数，在下表是排第八个的 CV_CAP_PROP_FRAME_COUNT，则视频总帧数的propId = 7) Property identifier. It can be one of the following: CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp. CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film. CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CV_CAP_PROP_FPS Frame rate. CV_CAP_PROP_FOURCC 4-character code of codec. CV_CAP_PROP_FRAME_COUNT Number of frames in the video file. CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() . CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode. CV_CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras). CV_CAP_PROP_CONTRAST Contrast of the image (only for cameras). CV_CAP_PROP_SATURATION Saturation of the image (only for cameras). CV_CAP_PROP_HUE Hue of the image (only for cameras). CV_CAP_PROP_GAIN Gain of the image (only for cameras). CV_CAP_PROP_EXPOSURE Exposure (only for cameras). CV_CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CV_CAP_PROP_WHITE_BALANCE_U The U value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently) CV_CAP_PROP_WHITE_BALANCE_V The V value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently) CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently) CV_CAP_PROP_ISO_SPEED The ISO speed of the camera (note: only supported by DC1394 v 2.x backend currently) CV_CAP_PROP_BUFFERSIZE Amount of frames stored in internal buffer memory (note: only supported by DC1394 v 2.x backend currently) ","link":"https://Angus1996.github.io/post/python3-利用opencv读取视频并获取视频相关信息/"},{"title":"Think Python术语表（五）","content":"chapter15 类(class)：一个用户定义的类型。类定义会新建一个类对象。 类对象(class object)：一个把票很难用户定义类型的信息的对象。类对象可以用来创建该类型的实例。 实例(instance)：属于某个类的一个对象。 实例化(instanciate)：创建一个新对象。 属性(attribute)：一个对象中关联的有命名的值。 内嵌对象(embedded object)：作为一个对象的属性存储的对象。 浅复制(shallow copy)：复制对象的内容，包括内嵌对象的引用；copy模块中的copy函数实现了这个功能。 深复制(deep copy)：复制对象的内容，也包括内嵌对象，以及他们内嵌的对象，依次类推；copy模块中的deepcopy函数实现了这个功能。 对象图(object diagram)：一个展示对象、对象的属性以及属性的值的图。 chapter16 原型和补丁(prototype and patch)：一种开发计划模式，先编写程序的粗略原型，并测试，在找到错误时更正。 有规划开发(planned development)：一种开发计划模式，先对问题有了高阶的深入理解，并且比增量开发或者原型开发有更多的规划。 纯函数(pure function)：不修改任何形参对象的函数。大部分纯函数都有返回值。 修改器(modifier)：修改一个或多个形参对象的函数。大部分修改器都不返回值，也就是返回None。 函数式编程风格(functional programming style)：一种编程设计风格，其中大部分函数都是纯函数。 不变式(invariant)：在程序的执行过程中应当总是为真的条件。 assert语句(assert statement)：一种检查某个条件，如果检查失败则抛出异常的语句。 chapter17 面向对象语言(object-oriented language)：一种提供诸如用户定义类型和方法之类的语言特性，以方便面向对象编程的语言。 面向对象编程(object-oriented programming)：一种编程风格，数据和修改数据的操作组织成类和方法的形式。 方法(method)：在类定义之内定义的函数，在类的实例上调用。 主体(subject)：调用方法所在的对象。 按位实参(positional argument)：一个不包含参数名字的实参，所以它不是一个关键词实参。 操作符重载(operator overloading)：修改一个类似+号这样的操作符的行为，使之可以用于用户定义类型。 基于类型的分发(type-based dispatch)：一种编程模式，检查操作对象的类型，并对不同类型调用不同的函数。 多态(polymorphic)：函数的一种属性，可以处理多种类型的参数。 信息隐藏(information hiding)：对象提供的接口不应当依赖于其实现，特别是其属性的表达形式的原则。 ","link":"https://Angus1996.github.io/post/Think-Python术语表（五）/"},{"title":"structshape模块判断数据结构","content":"structshape模块 &quot;&quot;&quot;This module contains a code example related to Think Python, 2nd Edition by Allen Downey http://thinkpython2.com Copyright 2015 Allen Downey License: http://creativecommons.org/licenses/by/4.0/ &quot;&quot;&quot; from __future__ import print_function, division &quot;&quot;&quot; This module provides one function, structshape(), which takes an object of any type and returns a string that summarizes the &quot;shape&quot; of the data structure; that is, the type, size and composition. &quot;&quot;&quot; def structshape(ds): &quot;&quot;&quot;Returns a string that describes the shape of a data structure. ds: any Python object Returns: string &quot;&quot;&quot; typename = type(ds).__name__ # handle sequences sequence = (list, tuple, set, type(iter(''))) if isinstance(ds, sequence): t = [] for i, x in enumerate(ds): t.append(structshape(x)) rep = '%s of %s' % (typename, listrep(t)) return rep # handle dictionaries elif isinstance(ds, dict): keys = set() vals = set() for k, v in ds.items(): keys.add(structshape(k)) vals.add(structshape(v)) rep = '%s of %d %s-&gt;%s' % (typename, len(ds), setrep(keys), setrep(vals)) return rep # handle other types else: if hasattr(ds, '__class__'): return ds.__class__.__name__ else: return typename def listrep(t): &quot;&quot;&quot;Returns a string representation of a list of type strings. t: list of strings Returns: string &quot;&quot;&quot; current = t[0] count = 0 res = [] for x in t: if x == current: count += 1 else: append(res, current, count) current = x count = 1 append(res, current, count) return setrep(res) def setrep(s): &quot;&quot;&quot;Returns a string representation of a set of type strings. s: set of strings Returns: string &quot;&quot;&quot; rep = ', '.join(s) if len(s) == 1: return rep else: return '(' + rep + ')' return def append(res, typestr, count): &quot;&quot;&quot;Adds a new element to a list of type strings. Modifies res. res: list of type strings typestr: the new type string count: how many of the new type there are Returns: None &quot;&quot;&quot; if count == 1: rep = typestr else: rep = '%d %s' % (count, typestr) res.append(rep) if __name__ == '__main__': t = [1, 2, 3] print(structshape(t)) t2 = [[1, 2], [3, 4], [5, 6]] print(structshape(t2)) t3 = [1, 2, 3, 4.0, '5', '6', [7], [8], 9] print(structshape(t3)) class Point: &quot;&quot;&quot;trivial object type&quot;&quot;&quot; t4 = [Point(), Point()] print(structshape(t4)) s = set('abc') print(structshape(s)) lt = zip(t, s) print(structshape(lt)) d = dict(lt) print(structshape(d)) it = iter('abc') print(structshape(it)) 导入模块结果展示 from structshape import structshape t = [1,2,3] structshape(t) 'list of 3 int' t2 = [[1,2], [3,4], [5,6]] structshape(t2) 'list of 3 list of 2 int' t3 = [1, 2, 3, 4.0, '5', '6', [7], [8], [9]] structshape(t3) 'list of (3 int, float, 2 str, 3 list of int)' s = 'abc' lt = list(zip(t,s)) structshape(lt) 'list of 3 tuple of (int, str)' d = dict(lt) structshape(d) 'dict of 3 int-&gt;str' ","link":"https://Angus1996.github.io/post/structshape模块判断数据结构/"},{"title":"Think-Python术语表（四）","content":"chapter12 元组(tuple)：一个不可变的元素序列。 元组赋值(tuple assignment)：一个赋值语句，右侧是一个序列，左侧是一个变量的元组。右边的序列会被求值，它的元素依次赋值给左侧元组中的变量。 收集(gather)：组装可变长参数数组的操作。 分散(scatter)：把一个序列当作参数列表的操作。 zip对象(zip object)：调用内置函数zip的结果，它是一个迭代访问由元组组成的序列的对象。 迭代器(iterator)：可以遍历序列的对象，但它不提供列表的操作和方法。 数据结构(data structure)：相关的值的集合，通常组织成列表、字典、元组等。 结构错误(shape error)：某个值由于其结构不对导致的错误，即它的类型或尺寸不对。 chapter13 确定性(deterministic)：程序的一种特性：给定相同的输入，每次运行都会执行相同的操作。 伪随机(pseudorandom)：一序列数：看起来是随机，但实际是由带着确定性的程序生成的。 默认值(default value)：可选形参声明时给定的值，如果函数调用时没有指定这个实参的值，则使用该默认值。 覆盖(override)：使用实参值替换一个默认值。 基准测试(benchmarking)：实现不同的备选方案，并使用各种输入的样本来测试它们，以达到选择使用哪种数据结构的目的。 橡皮鸭调试(rubber duck debugging)：通过向类似橡皮鸭之类的静物解释你的问题，进行调试的过程。虽然橡皮鸭不懂Python，但通过诉说和解释，可以帮助你解决问题。 chapter14 持久性(persistent)：程序的一种属性，它会一直运行，并至少保存一部分数据在永久存储中。 格式操作符(format operator)：一个操作符，即%，它接收一个格式字符串，以及一个元组，并生成字符串，其中包括了元组的各个依据格式字符串里指定的方式格式化的元素。 格式字符串(format string)：一个字符串，被格式操作符所用，内部包含格式序列。 格式序列(format sequence)：格式字符串中出现的字符序列，如%d，它指定一个值如何格式化。 文本文件(text file)：存储在类似硬盘这样的永久存储中的字符串序列。 目录(directory)：有名称的文件集合。也称为文件夹。 路径(path)：用来标定一个文件的字符串。 相对路径(relative path)：从当前目录开始的路径。 绝对路径(absolute path)：从文件系统的顶级目录开始的路径。 捕获(catch)：使用try和except语句来阻止一个异常终止程序的行为。 数据库(database)：一个文件，其内容组织类似字典，将键映射到值。 字节组对象(bytes object)：一个和字符串相似的对象。 命令行(shell)：一个程序，运行用户键入命令并通过调用其他程序来执行这些命令。 管道对象(pipe object)：代表一个运行中的程序的对象，让Python程序可以运行命令并读取结果。 ","link":"https://Angus1996.github.io/post/Think-Python术语表（四）/"},{"title":"Think Python术语表（三)","content":"chapter10 元素(list)：值的序列。 元素(element)：列表（或其他序列）中的一个值，也称为列表项。 嵌套列表(nested list)：作为其他列表的元素的列表。 累加器(accumulator)：在循环中用于加和或者累计某个结果的变量。 累加赋值(augmented assignment)：使用类似+=操作符来更新变量值的语句。 化简(reduce)：一种处理模式，遍历一个序列，并将元素的值累计起来计算为一个单独的结果。 映射(map)：一种处理模式，遍历一个序列，对每个元素进行操作。 过滤(filter)：一种处理模式，遍历一个序列，并选择满足某种条件的元素。 对象(object)：变量可以引用的东西。对象有类型和值。 相等(equivalent)：拥有相同的值。 相同(identical)：是同一个对象(并且也意味着相等)。 引用(reference)：变量和它的值之间的关联。 别名(aliasing)：多个变量同时引用一个对象的情况。 分隔符(delimiter)：用于分隔字符串的一个字符或字符串。 ","link":"https://Angus1996.github.io/post/Think-Python术语表（三）/"},{"title":"Think Python术语表（二）","content":"chapter3 函数(function)：一个有名称的语句序列，可以进行某种有用的操作。函数可以接收或者不接收参数，可以返回或不返回结果。 函数定义(function definition)：一个用来创建新函数的语句，指定函数的名称、参数以及它所包含的语句序列。 函数对象(function object)：函数定义所创建的值。函数名可以用作变量来引用一个函数对象。 函数头(header)：函数定义的第一行。 函数体(body)：函数定义内的语句序列。 形参(parameter)：函数内使用的用来引用作为实参传入的值的名称。 函数调用(function call)：运行一个函数的语句。它由函数名称和括号中的参数列表组成。 实参(argument)：当函数调用时，提供给它的值。这个值会被赋值给对应的形参。 局部变量(local variable)：函数内定义的变量。局部变量只能在函数体内使用。 返回值(return value)：函数的结果。如果函数被当作表达式调用，返回值就是表达式的值。 有返回值函数(fruitful function)：返回一个值的函数。 无返回值函数(void function)：总是返回None的函数。 None：由无返回值函数返回的一个特殊值。 模块(module)：一个包含相关函数以及其他定义的集合的文件。 import语句(import statement)：读入一个模块文件，并创建一个模块对象的语句。 模块对象(module object)：使用import 语句时创建的对象，提供对模块定义的值的访问。 句点表示法(dot notation)：调用另一个模块中的函数的语法，使用模块名加上一个句点符号，再加上函数名。 组合(composition)：使用一个表达式作为更大的表达式的一部分，或者使用语句作为更大的语句的一部分。 执行流程(flow of execution)：语句执行的顺序。 栈图(stack diagram)：函数栈的图形表达形式，也展示它们的变量，以及这些变量引用的值。 图框(frame)：栈图中的一个图框，表达一个函数调用。它包含了局部变量以及函数的参数。 回溯(traceback)：当异常发生时，打印出正在执行的函数栈。 chapter4 方法(method)：与某个对象相关联的一个函数，使用句点表达式调用。 循环(loop)：程序中的一个片段，可以重复运行。 封装(encapsulation)：将一组语句转换成函数定义的过程。 泛化(generalization)：将一些不必要的具体值(如一个数字)替换为合适的通用参数或变量的过程。 关键词参数(keyword argument)：调用函数时，附带了参数名称（作为一个&quot;关键词&quot;来使用）的参数。 接口(interface)：描述函数如何使用的说明。包括函数的名称，以及形参与返回值的说明。 重构(refactoring)：修改代码并改善函数的接口以及代码质量的过程。 开发计划(development plan)：写程序的过程。 文档字符串(docstring)：在函数定义开始处出现的用于说明函数接口的字符串。 前置条件(precondition)：在函数调用开始前应当满足的条件。 后置条件(postcondition)：在函数调用结束后应当满足的条件。 chapter5 向下取整除法(floor division)：用//表示的操作符，用于将两个数相除，并对结果进行向下取整（靠近0取整），得到整数结果。 求模操作符(modulus operator)：用%表示的操作符，用于两个整数，返回两个整数相除的余数。 布尔表达式(boolean expression)：一种表达式，其值是True或False. 关系操作符(relational operator)：用来表示两个操作对象的比较关系的操作符，如下之一：==、!=、&gt;、&lt;、&gt;=和&lt;=。 逻辑操作符(logical operator)：用来组合两个布尔表达式的操作符，有三个：and、or 和 not。 条件语句(conditional statement)：依照某些条件控制程序执行流程的语句。 条件(condition)：条件语句中的布尔表达式，由他决定执行哪一个分支。 复合语句(compound statement)：一个包含语句头和语句体的语句。语句头以冒号(:)结尾。语句体相对语句头缩进一层。 分支(branch)：条件语句中的一个可能性分支语句段。 条件链语句(chained condition)：一种包含多个分支的条件语句。 嵌套条件语句(nested condition)：在其他条件语句的分支中出现的条件语句。 返回语句(return statement)：导致一个函数立即结束并返回到调用者的语句。 递归(recursion)：在当前函数中调用自己的过程。 基准情形(base case)：递归函数中的一个条件分支，里面不会再继续递归调用。 无限递归(infinite recursion)：没有基准情形的递归，或者永远无法达到基准情形的分支的递归调用。最终，这种无限递归会导致运行时错误。 Chapter6 临时变量(temporary variable)：在复杂计算中用于保存中间计算值的变量。 无效代码(dead code)：程序中的一些代码，用于不可能运行。常常是写在return语句之后的代码。 增量开发(incremental development)：一个程序开发计划，但在最终版本中不需要的代码。 脚手架代码(scaffolding)：在开发过程中使用的，但在最终版本中不需要的代码。 守卫(guardian)：一个编程模式。使用条件语句来检查并处理可能产生错误的情形。 chapter7 重新赋值(reassignment)：对一个已经存在的变量赋予一个新值。 更新(update)：一种赋值操作，新值依赖于变量的旧值。 初始化(initialization)：一种赋值操作，给变量一个初始的值，以后可以进行更新。 增量(increment)：一种更新操作，增加变量的值（常常是加1）。 减量(decrement)：一种更新操作，减少变量的值。 迭代(iteration)：使用递归函数调用或者循环来重复执行一组语句。 无限循环(infinite loop)：一个终止条件永远无法满足的循环。 算法(algorithm)：解决一类问题的通用过程。 chapter8 对象(object)：变量可以引用的一种事物。 序列(sequence)：一个有序的值的集合，其中每个使用一个下标来定位。 项(item)：序列中的一个值， 下标(index)：用于在序列中选择元素的整数值。例如，可以用于在字符串中选取字符。在Python中下标从0开始。 切片(slice)：字符串的一部分，通过一个下标范围来定位。 空字符串(empty string)：没有字符，长度为0的字符串，使用一对引号来表示。 不可变(immutable)：序列的一种属性，表示它的元素是不可改变的。 遍历(traverse)：迭代访问序列中的每一个元素，并对每个元素进行相似的操作。 搜索(search)：一种遍历的模式，当找到它想要的元素时停止。 计数器(counter)：一种用来计数的变量，通常初始化为0，后来会递增。 方法调用(invocation)：调用一个方法的语句。 可选参数(optional argument)：函数或方法中，并不必须有的参数。 chapter9 文件对象(file object)：用来表示一个打开的文件的值。 将问题回归到已解决问题(reduction to a previously solved problem)：通过把问题表述为已经解决的某个问题的特例解决问题的一种方式。 特殊情形(special case)：一种不典型或者不明显（因此更可能没有正确处理）的测试用例。 ","link":"https://Angus1996.github.io/post/Think-Python术语表（二）/"},{"title":"Think Python 术语表（一）","content":"chapter1 问题求解（problem solving)：总结问题、寻找解决方案以及表达解决方案的过程。 高级语言（high-level language)：设计来方便人们读写的编成语言，如python。 低级语言（low-level language)：设计来方便计算机执行的编成语言，也被称为“机器语言”或者“汇编语言” 可移植性（portability)：程序的一种属性：可以在多种类型的计算机上运行。 解释器（interpreter)：一个读取其他程序并执行其内容的程序。 提示符（prompt)：解释器显示的文字，提示用户已经准备好接收用户的输入。 程序（program)：一系列代码指令的集合，指定一种计算。 操作符（operator)：一种特殊符号，用来表达加法、乘法或字符串拼接等简单运算。 值（value)：程序操作的数据的基本单位，如一个数字或一个字符串。 类型（type)：值得类别。有整数（int)、浮点数(float)和字符串(str)。 整型（integer)：用来表示整数得类型。 浮点型（floating-point)：用来表示带小数部分的数的类型。 字符串（string)：用来表示一串字符的类型。 自然语言（natural language)：自然演化而来的人们所说的语言。 形式语言（formal language)：人们设计为某种特定目的（如表达数学概念或者计算机程序）设计的任何一种语言。所有编程语言都属于形式语言。 记号（token)：程序的语法结构的最基本单位，类似于自然语言中的词。 语法（syntax)：用于控制程序结构的规则。 语法分析（parse)：检查程序并分析其语法结构。 bug：程序中的错误。 调试（debugging)：发现和纠正bug的过程。 chapter2 变量（variable)：引用一个值的名字。 赋值语句（assignment statement)：将一个值赋值给变量的语句。 状态图（state diagram)：用来展示一些变量以及其值的图示。 关键字（keyword)：编译器或解释器保留的词，用于解析程序；变量名不能使用关键字，如if, def, while等。 操作数（operand)：操作符所操作的值。 表达式（expression)：变量、操作符和值的组合，可以表示一个单独的结果值。 求值（evaluate)：对表达式按照操作的顺序进行计算，求得其结果值。 语句（statement)：表示一个命令或动作的一段代码。 执行（execute)：运行一条语句，看他说的是什么。 交互模式（iteractive mode)：使用Python解释器的一种方式，在提示符之后键入代码。 脚本模式（script mode)：使用Python解释器的一种方式，从脚本中读入代码并运行他。 脚本（script)：保存在文件中的程序。 操作顺序（order of operations)：当表达式中有多个操作符和操作对象要求值时，用于指导求值顺序的规则。 拼接（concatenate)：将两个操作数首尾相连。 注释(comment)：代码中附加的注解信息，用于帮助其他程序员阅读代码，并不影响代码的运行。 语法错误(syntax error)：程序中的一种错误，导致它无法进行语法解析（因此也无法被解释器执行）。 异常(exception)：程序运行中发现的错误。 语义(semantics)：程序表达的含义。 语义错误（semantic error)：程序中的一种错误，导致程序所做的事情不是程序员设想的。 ","link":"https://Angus1996.github.io/post/Think-Python-术语表/"},{"title":"python中使用psutil查看内存使用","content":"有的时候需要对python程序内存占用进行监控，这个时候可以用到psutil库，Anaconda中是自带的，如果import出错，可以用pip install psutil(安装在python中）或conda install psutil（安装在Anaconda中） #常用的： #python2 import psutil import os info = psutil.virtual_memory() print u'内存使用：',psutil.Process(os.getpid()).memory_info().rss print u'总内存：',info.total print u'内存占比：',info.percent print u'cpu个数：',psutil.cpu_count() #常用的： #python3 import psutil import os info = psutil.virtual_memory() print(u'内存使用：',psutil.Process(os.getpid()).memory_info().rss) print(u'总内存：',info.total) print(u'内存占比：',info.percent) print(u'cpu个数：',psutil.cpu_count()) 其他内置的方法或属性还有： boot_time callable collections cpu_count cpu_percent cpu_stats cpu_times cpu_times_percent disk_io_counters disk_partitions disk_usage errno functools long net_connections net_if_addrs net_if_stats net_io_counters os pid_exists pids process_iter pwd signal subprocess swap_memory sys test time traceback users version_info virtual_memory wait_procs win_service_get win_service_iter 查看windows开机时间 import time import psutil print (u'电脑开机时间：{}'.format(time.strftime('%y-%m-%d %H:%M:%S', time.localtime(psutil.boot_time())))) ","link":"https://Angus1996.github.io/post/python中使用psutil查看内存使用/"},{"title":"matlab计时函数","content":"简单地说，tic和toc是用来记录matlab命令执行的时间 tic用来保存当前时间，而后使用toc来记录程序完成时间。 两者往往结合使用，用法如下： tic operations toc 显示时间单位： 秒 clc tic d=zeros(1,10000); for i=1:10000 d(i)=i; end toc tic c=1; for i=1:10000 c=[c:i]; end toc 运行结果如下： Elapsed time is 0.000158 seconds. Elapsed time is 0.152307 seconds. 只要用tic和toc函数，不需要自己计算前后时间的差，tic函数会记录起始时刻，toc函数会自动计算时间差。这两个函数一般配合使用，tic表示计时的开始，toc表示计时的结束。 通过这个程序，可以发现，先把矩阵的大小确定再给矩阵的赋值的方法比边赋值边改变矩阵维数的方法更节省时间。 Matlab****里面的计时函数：Matlab7的计时函数主要有tic,toc,cputime和etime等，计时函数可以定量的计算完成制定程序所消耗的时间资源，因为可以作为比较程序优劣的一个重要标准。 a、tic和toc函数 这两个函数一般配合使用，tic表示计时的开始，toc表示计时的结束。 格式如： tic 任意表达式 toc t=toc b、cputime函数 cputime函数返回从调用该函数起所用的总的Cpu时间，单位以秒计算。 格式如： t=cputime; 任意表达式或者程序 e=cputime-t; c、etime函数 e=etime(t2,t1)命令返回向量t1和t2之间的时间段，t1和t2必须含有由clock函数返回的6个元素，即[Year Month Day Hour Minute Second]。 举例说明： &gt;&gt;x=rand(2048,1); &gt;&gt;t=clock; &gt;&gt;fift(x); &gt;&gt;etime(clock,t); ans= 14.53 ","link":"https://Angus1996.github.io/post/matlab计时函数/"},{"title":"2018华科森林音乐会--转载","content":" ","link":"https://Angus1996.github.io/post/2018华科森林音乐会/"},{"title":"Android开发中的尺寸问题","content":"Android开发中的各种尺度单位 px 像素（pixel)，表示屏幕上的一个物理像素点。不建议直接使用 px 绘制UI，因为受像素密度的影响，以 px 为单位绘制的UI在不同手机上显示的实际大小会不同。 dp 密度无关像素。Android 建议使用的一种虚拟像素单位，可以使定义的UI布局在不同像素密度的设备上具有相同的效果。像素密度dpi = 每英寸长度含有的像素点数量 / 屏幕纵向(横向)长度 / 屏幕纵向(横向)像素数目。这种密度无关像素尺寸等同于160 dpi 屏幕上的一个物理像素。所以 px = dp * (dpi / 160) 。 Android系统定义了四种像素密度： 名称 简称 dpi low ldpi 约120dpi medium mdpi 约160dpi high hdpi 约240dpi extra-high xhdpi 约320dpi extra-extra-high xxhdpi 约480dpi extra-extra-extra-high xxxdpi 约640dpi dip dp 的早期命名，与 dp 完全相同。 sp 缩放无关像素（scale-independent pixel）。sp 和 dp 很类似但区别是，Android 系统允许用户自定义文字尺寸大小（小、正常、大、超大等等），当文字尺寸是“正常”时1sp=1dp，而当文字尺寸是“大”或“超大”时，1sp&gt;1dp。因此sp主要用于定义字体大小，在用户设置放大字体后，只有用sp为单位的文字被放大。 pt 标准长度单位，1pt=1/72英寸=0.035厘米。 in 英寸，1英寸=2.54厘米（约） 基本用法 文字尺寸用sp为单位，非文字的尺寸用dp作单位。特殊情况使用px单位，例如定义分隔线时使用宽度为1px的细线 。 ","link":"https://Angus1996.github.io/post/Android开发中的尺寸问题/"},{"title":"本科毕业设计","content":"华中科技大学本科毕业设计 点击此处查看代码 处理过的64x64x3分辨率的celeba人脸图像数据集 点击此处下载 处理过的128x128x3分辨率放入celeba人脸图像数据集 点击此处下载 checkpoint下载 lsgan64 lsgan128 dcgan64 dcgan128 wgan64 improved_lsgan64 improved_lsgan128 运行代码 训练 将相应分辨率图像文件夹改为image，输入以下命令进行训练神经网络。 python train_lsgan.py ​ 测试 利用已经训练好的模型随机产生更多图像。 python test.py ​ 修复 将待修复图像放入uncompletion_image文件夹，利用生成好的模型修复。 python train_completion.py ​ PYQT5设计 python解释器运行show.py即可。 主界面 开始修复提示 修复完成提示 修复结果展示 单张64x64x3分辨率结果展示 单张128x128x3分辨率结果展示 ","link":"https://Angus1996.github.io/post/毕业设计/"},{"title":"MCM/ICM 2018 Result","content":"MCM/ICM 2018 Result ✨ ✨ ✨ ✨ ✨ 感谢队友陆仪文、殷祖乾，奋斗四天三夜，喜获M奖✨ ✨ ✨ ✨ 突然回想起最后交稿回到宿舍，整栋楼栋只有我一个人还没回家，宿舍也被断电了，看着窗外的孤寂。这是一种别样的奖励吧。 ","link":"https://Angus1996.github.io/post/MCM-ICM-2018-Result/"},{"title":"window更换python pip 的更新源","content":"官网的配置的介绍 首先在windows的文件夹窗口输入： %APPDATA% 然后再其中新建pip文件夹，然后到pip文件夹里面新建个pip.ini，然后用记事本打开pip.ini文件，在其中输入更新源的信息。 豆瓣更新源： [global] timeout = 6000 index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com 阿里更新源： [global] index-url = http://mirrors.aliyun.com/pypi/simple/ [install] trusted-host=mirrors.aliyun.com 效果如下图（安装tensorflow）： ","link":"https://Angus1996.github.io/post/window更换python-pip-的更新源/"},{"title":"2017HUST森林音乐会--转载","content":" ","link":"https://Angus1996.github.io/post/2017HUST森林音乐会/"},{"title":"python中元组（tuple）相关用法","content":"python中元组（tuple）用法相关 tuple也是一个class，是不可变的list类型，不可以增删改 创建 tup1 = ('physics', 'chemistry', 1996); tup2 = (1, 2, 3, 4, 5); tup3 = &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;; 访问 与list一样，tup1[1:5] 修改 不可以修改，只能增加新的部分 tup4 = tup1 + tup2; print(tup4) 任意无符号的对象，以逗号隔开，默认为元组，如下实例 a = 1, 2, 3, 'e' a = (1, 2, 3, 'e') Python元组包含了以下内置函数(与list差不多的函数) cmp(tup1, tup2): 比较两个元组元素。 len(tuple): 计算元组元素个数。 max(tuple): 返回元组中元素最大值。 min(tuple): 返回元组中元素最小值。 tuple的方法 count(): 查找元素在tuple中出现的次数。 index(): 查找元素中的第一个索引值。 Tuple 是不可变 list。 一旦创建了一个 tuple 就不能以任何方式改变它。 Tuple 与 list 的相同之处 定义 tuple 与定义 list 的方式相同, 除了整个元素集是用小括号包围的而不是方括号。 Tuple 的元素与 list 一样按定义的次序进行排序。 Tuples 的索引与 list 一样从 0 开始, 所以一个非空 tuple 的第一个元素总是 t[0]。 负数索引与 list 一样从 tuple 的尾部开始计数。 与 list 一样分片 (slice) 也可以使用。注意当分割一个 list 时, 会得到一个新的 list ；当分割一个 tuple 时, 会得到一个新的 tuple。 Tuple 不存在的方法 不能向 tuple 增加元素。Tuple 没有 append 或 extend 方法。 不能从 tuple 删除元素。Tuple 没有 remove 或 pop 方法。 然而, 可以使用 in 来查看一个元素是否存在于 tuple 中。 用 Tuple 的好处 Tuple 比 list 操作速度快。如果您定义了一个值的常量集，并且唯一要用它做的是不断地遍历它，请使用 tuple 代替 list。 如果对不需要修改的数据进行 “写保护”，可以使代码更安全。使用 tuple 而不是 list 如同拥有一个隐含的 assert 语句，说明这一数据是常量。如果必须要改变这些值，则需要执行 tuple 到 list 的转换。 Tuple 与 list 的转换 list转为tuple： temp_list = [1,2,3,4,5] 将temp_list进行强制转换：tuple(temp_list) 查看是否转换成功：print type(temp_list) tuple 转为list： temp_tuple = (1,2,3) 方法类似，也是进行强制转换即可：list(temp_tuple) 查看是否转换成功：print type(temp_tuple) ","link":"https://Angus1996.github.io/post/python中元组（tuple）相关用法/"},{"title":"pillow包使用之图片裁剪","content":"pillow包使用之图片裁剪 如果系统中没有安装pillow包，安装： pip install pillow 修改图片的大小 ''' author: Angus Cai Date: 2018-3-28 ''' import os import os.path from PIL import Image ''' filein: 输入图片 fileout: 输出图片 width: 输出图片宽度 height:输出图片高度 type:输出图片类型（png, gif, jpeg...） ''' def ResizeImage(filein, fileout, width, height, type): img = Image.open(filein) out = img.resize((width, height),Image.ANTIALIAS) #resize image with high-quality out.save(fileout, type) if __name__ == &quot;__main__&quot;: list = os.listdir(&quot;./&quot;) for i in range(0, len(list)): imgName = os.path.basename(list[i]) if (os.path.splitext(imgName)[1] != &quot;.jpg&quot;): continue print(imgName) filein = imgName fileout = '%s'%imgName width = 64 height = 64 type = 'jpeg' ResizeImage(filein, fileout, width, height, type) 裁剪图片某个部分 裁剪左上角 # 导入pillow from PIL import Image # 加载原始图片 img = Image.open(&quot;lena.jpg&quot;) # 从左上角开始 剪切 200*200的图片 img2 = img.crop((0, 0, 200, 200)) img2.save(&quot;lena2.jpg&quot;) 裁剪右下角 # 导入pillow from PIL import Image # 加载原始图片 img = Image.open(&quot;lena.jpg&quot;) # img.size返回图片的大小元组，list()函数将元组转换成列表 width = list(img.size)[0] # 图片大小 height = list(img.size)[1] img3 = img.crop( ( width - 200, height - 200, width, height ) ) img3.save(&quot;lena3.jpg&quot;) 裁剪中间部分 # 导入pillow from PIL import Image # 加载原始图片 img = Image.open(&quot;lena.jpg&quot;) # img.size返回图片的大小元组，list()函数将元组转换成列表 width = list(img.size)[0] # 图片大小 height = list(img.size)[1] half_the_width = weight / 2 half_the_height = height / 2 img4 = img.crop( ( half_the_width - 50, half_the_height - 75, half_the_width + 50, half_the_height + 75 ) ) img4.save(&quot;lena4.jpg&quot;) 填充 longer_side = max(img4.size) horizontal_padding = (longer_side - img4.size[0]) / 2 vertical_padding = (longer_side - img4.size[1]) / 2 img5 = img4.crop( ( -horizontal_padding, -vertical_padding, img4.size[0] + horizontal_padding, img4.size[1] + vertical_padding ) ) img5.save(&quot;lena5.jpg&quot;) ","link":"https://Angus1996.github.io/post/pillow包使用之图片裁剪/"},{"title":"Ubuntu换源","content":"Ubuntu命令行查看系统版本号 sudo lsb_release -a 第一步：备份原来的源文件 cd /etc/apt 然后会显示下面的源文件sources.list 输入命令 sudo cp sources.list sources.list.bak 就是将sources.list备份到sources.list.bak 第二部：替换源 输入sudo vim sources.list 进入VIM编辑器，输入ggdG删除所有内容，再粘贴以下的源 按下ESC，输入:wq保存退出 清华源 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse 中科大源 deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates main restricted deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates main restricted deb http://mirrors.ustc.edu.cn/ubuntu/ precise universe deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise universe deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates universe deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates universe deb http://mirrors.ustc.edu.cn/ubuntu/ precise multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise multiverse deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates multiverse deb http://mirrors.ustc.edu.cn/ubuntu/ precise-backports main restricted universe multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-backports main restricted universe multiverse deb http://security.ubuntu.com/ubuntu precise-security main restricted deb-src http://security.ubuntu.com/ubuntu precise-security main restricted deb http://security.ubuntu.com/ubuntu precise-security universe deb-src http://security.ubuntu.com/ubuntu precise-security universe deb http://security.ubuntu.com/ubuntu precise-security multiverse deb-src http://security.ubuntu.com/ubuntu precise-security multiverse 网易源 deb http://mirrors.163.com/ubuntu/ precise-updates main restricted deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted deb http://mirrors.163.com/ubuntu/ precise universe deb-src http://mirrors.163.com/ubuntu/ precise universe deb http://mirrors.163.com/ubuntu/ precise-updates universe deb-src http://mirrors.163.com/ubuntu/ precise-updates universe deb http://mirrors.163.com/ubuntu/ precise multiverse deb-src http://mirrors.163.com/ubuntu/ precise multiverse deb http://mirrors.163.com/ubuntu/ precise-updates multiverse deb-src http://mirrors.163.com/ubuntu/ precise-updates multiverse deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse 阿里云 # deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricted deb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial universe deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb http://mirrors.aliyun.com/ubuntu/ xenial multiverse deb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiverse deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-properties deb http://archive.canonical.com/ubuntu xenial partner deb-src http://archive.canonical.com/ubuntu xenial partner deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial-security universe deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse ","link":"https://Angus1996.github.io/post/Ubuntu换源/"},{"title":"pypi清华镜像使用帮助","content":"pypi 镜像使用帮助 临时使用 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple packageName 注意，simple` 不能少, 是 https而不是 http 设为默认 修改 ~/.config/pip/pip.conf (Linux), %APPDATA%\\pip\\pip.ini (Windows 10) 或 $HOME/Library/Application Support/pip/pip.conf (macOS) (没有就创建一个)， 修改 index-url至tuna，例如 [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple pip 和 pip3 并存时，只需修改 ~/.pip/pip.conf。 ","link":"https://Angus1996.github.io/post/pypi清华镜像使用帮助/"},{"title":"pdf文件转word","content":" 下载Adobe Acrobat Pro DC 软件，并激活 链接：https://pan.baidu.com/s/1IsDNPIr-dobVyjsuK9YN-g 密码：1kcn 用Adobe Acrobat Pro DC 打开pdf文件 打开文件选项，导出到Microsoft word 或者是html 文件 英文文件时，html文件用google浏览器打开，再用谷歌翻译可以全文翻译 ","link":"https://Angus1996.github.io/post/pdf文件转word/"},{"title":"过拟合&欠拟合","content":"在机器学习表现不佳的原因要么是过度拟合或欠拟合数据。 机器学习中的逼近目标函数过程 监督式机器学习通常理解为逼近一个目标函数(f)，此函数映射输入变量(X)到输出变量(Y): Y=f(X) 这种特性描述可以用于定义分类和预测问题和机器学习算法的领域。 从训练数据中学习目标函数的过程中，我们必须考虑的问题是模型在预测新数据时的泛化性能。泛化好坏是很重要的，因为我们收集到的数据只是样本，其带有噪音并且是不完全的。 机器学习中的泛化 在机器学习中，我们描述从训练数据学习目标函数的学习过程为归纳性的学习。 归纳与特别的样本中学习到通用的概念有关，而这就是监督式机器学习致力于解决的问题。这与推演不同，其主要是另一种解决问题和寻求从通常的规则中找寻特别的内容。 泛化即是，机器学习模型学习到的概念在它处于学习的过程中时模型没有遇见过的样本时候的表现。 好的机器学习模型的模板目标是从问题领域内的训练数据到任意的数据上泛化性能良好。这让我们可以在未来对模型没有见过的数据进行预测。 在机器学习领域中，当我们讨论一个机器学习模型学习和泛化的好坏时，我们通常使用术语：过拟合和欠拟合. 过拟合和欠拟合是机器学习算法表现差的两大原因。 统计拟合 在统计学中，拟合指的是你逼近目标函数的远近程度。 这个术语同样可以用于机器学习中，因为监督式机器学习算法的目标也是逼近一个未知的潜在映射函数，其把输入变量映射到输出变量。 统计学通常通过用于描述函数和目标函数逼近的吻合程度来描述拟合的好坏。 这类理论中的一些在机器学习中也是有用的(例如，计算残差)，但是一些技巧假设我们已经知道了我们要逼近的函数。这和机器学习的场景就不同了。 如果我们已经知道了目标函数的形式，我们将可以直接用它来做预测，而不是从一堆有噪音的数据中把它费力的学习出来。 机器学习中的过拟合 过拟合指的是模型对于训练数据拟合程度过当的情况。 当某个模型过度的学习训练数据中的细节和噪音，以至于模型在新的数据上表现很差，我们称过拟合发生了。这意味着训练数据中的噪音或者随机波动也被当做概念被模型学习了。而问题就在于这些概念不适用于新的数据，从而导致模型泛化性能的变差。 过拟合更可能在无参数非线性模型中发生，因为学习目标函数的过程是易变的具有弹性的。同样的，许多的无参数器学习算法也包括限制约束模型学习概念多少的参数或者技巧。 例如，决策树就是一种无参数机器学习算法，非常有弹性并且容易受过拟合训练数据的影响。这种问题可以通过对学习过后的树进行剪枝来解决，这种方法就是为了移除一些其学习到的细节。 机器学习中的欠拟合 欠拟合指的是模型在训练和预测时表现都不好的情况。 一个欠拟合的机器学习模型不是一个良好的模型并且由于在训练数据上表现不好这是显然的。 欠拟合通常不被讨论，因为给定一个评估模型表现的指标的情况下，欠拟合很容易被发现。矫正方法是继续学习并且试着更换机器学习算法。虽然如此，欠拟合与过拟合形成了鲜明的对照。 机器学习中好的拟合 理想上，你肯定想选择一个正好介于欠拟合和过拟合之间的模型。 这就是我们学习的目标，但是实际上很难达到。 为了理解这个目标，我们可以观察正在学习训练数据机器学习算法的表现。我们可以把这个过程划分为分别是训练过程和测试过程。 随着时间进行，算法不断地学习，模型在训练数据和测试数据上的错误都在不断下降。但是，如果我们学习的时间过长的话，模型在训练数据上的表现将继续下降，这是因为模型已经过拟合并且学习到了训练数据中的不恰当的细节以及噪音。同时，测试数据集上的错误率开始上升，也即是模型的泛化能力在下降。 这个完美的临界点就处于测试集上的错误率开始上升时，此时模型在训练集和测试集上都有良好的表现。 你可以用你自己喜爱的机器学习算法来实践这个实验。而在实践中这通常是无用的，因为在测试数据上运用这个技巧来选择训练停止的时机，这意味着这个测试集对于我们并不是“不可见的”或者单独的衡量标准。数据的一些知识(许多有用的知识)已经泄露到了训练过程。 通常有两种手段可以帮助你找到这个完美的临界点：重采样方法和验证集方法。 如何限制过拟合 过拟合和欠拟合可以导致很差的模型表现。但是到目前为止大部分机器学习实际应用时的问题都是过拟合。 过拟合是个问题因为训练数据上的机器学习算法的评价方法与我们最关心的实际上的评价方法，也就是算法在位置数据上的表现是不一样的。 当评价机器学习算法时我们有两者重要的技巧来限制过拟合: 使用重采样来评价模型效能 保留一个验证数据集 最流行的重采样技术是k折交叉验证。指的是在训练数据的子集上训练和测试模型k次，同时建立对于机器学习模型在未知数据上表现的评估。 验证集只是训练数据的子集，你把它保留到你进行机器学习算法的最后才使用。在训练数据上选择和调谐机器学习算法之后，我们在验证集上在对于模型进行评估，以便得到一些关于模型在未知数据上的表现的认知。 对于机器学习，使用交叉验证在未知数据上进行验证模型效能是一种良好的标准。如果你拥有数据，使用验证集也是一种良好的实践。 进一步阅读 维基百科上的泛化 维基百科上的过拟合 维基百科上的归纳推理 维基百科上的感应问题 Quora上的过拟合直观解释 总结 泛化是一种关于模型学习到的知识在未知数据上表现程度的概念描述。 过拟合 :在训练数据上表现良好，在未知数据上表现差。 欠拟合 :在训练数据和未知数据上表现都很差 原文链接：https://www.cnblogs.com/nxld/p/6058782.html ","link":"https://Angus1996.github.io/post/过拟合-欠拟合/"},{"title":"交叉熵介绍","content":"交叉熵介绍 交叉熵（Cross Entropy）是Loss函数的一种（也称为损失函数或代价函数），用于描述模型预测值与真实值的差距大小，常见的Loss函数就是均方平方差（Mean Squared Error），定义如下： C=(y−a)22C=\\frac{(y-a)^2}{2} C=2(y−a)2​ 平方差很好理解，预测值与真实值直接相减，为了避免得到负数取绝对值或者平方，再做平均就是均方平方差。注意这里预测值需要经过sigmoid激活函数，得到取值范围在0到1之间的预测值。 平方差可以表达预测值与真实值的差异，但在分类问题种效果并不如交叉熵好，原因可以参考 交叉熵的定义如下： ​ 神经元的输出为：$ a=sigmoid(z), where z=\\sum_jw_jx_j+b $, 那么我们定义这个神经元的交叉熵代价函数为： C=−1n∑x[ylna+(1−y)ln(1−a)]C=-\\frac{1}{n}\\sum_x[ylna+(1-y)ln(1-a)] C=−n1​x∑​[ylna+(1−y)ln(1−a)] 这里的n是训练数据的个数，这个加和覆盖了所有的训练输入x，y是期望输出。 上面的文章也介绍了交叉熵可以作为Loss函数的原因，首先是交叉熵得到的值一定是正数，其次是预测结果越准确值越小，注意这里用于计算的“a”也是经过sigmoid激活的，取值范围在0到1。如果label是1，预测值也是1的话，前面一项y * ln(a)就是1 * ln(1)等于0，后一项(1 – y) * ln(1 – a)也就是0 * ln(0)等于0，Loss函数为0，反之Loss函数为无限大非常符合我们对Loss函数的定义。 Tensorflow的交叉熵函数 tf.nn.sigmoid_cross_entropy_with_logits tf.nn.softmax_cross_entropy_with_logits tf.nn.sparse_softmax_cross_entropy_with_logits tf.nn.weighted_cross_entropy_with_logits sigmoid_cross_entropy_with_logits ​ 我们先看sigmoid_cross_entropy_with_logits，为什么呢，因为它的实现和前面的交叉熵算法定义是一样的，也是TensorFlow最早实现的交叉熵算法。这个函数的输入是logits和targets，logits就是神经网络模型中的 W * X矩阵，注意不需要经过sigmoid，而targets的shape和logits相同，就是正确的label值，例如这个模型一次要判断100张图是否包含10种动物，这两个输入的shape都是[100, 10]。注释中还提到这10个分类之间是独立的、不要求是互斥，这种问题我们成为多目标，例如判断图片中是否包含10种动物，label值可以包含多个1或0个1，还有一种问题是多分类问题，例如我们对年龄特征分为5段，只允许5个值有且只有1个值为1，这种问题可以直接用这个函数吗？答案是不可以 ​ 对W * X得到的值进行sigmoid激活，保证取值在0到1之间，然后放在交叉熵的函数中计算Loss。对于二分类问题这样做没问题，但对于前面提到的多分类，例如年轻取值范围在04，目标值也在04，这里如果经过sigmoid后预测值就限制在0到1之间，而且公式中的1 – z就会出现负数，仔细想一下0到4之间还不存在线性关系，如果直接把label值带入计算肯定会有非常大的误差。因此对于多分类问题是不能直接代入的，那其实我们可以灵活变通，把5个年龄段的预测用onehot encoding变成5维的label，训练时当做5个不同的目标来训练即可，但不保证只有一个为1，对于这类问题TensorFlow又提供了基于Softmax的交叉熵函数 softmax_cross_entropy_with_logits Softmax本身的算法很简单，就是把所有值用e的n次方计算出来，求和后算每个值占的比率，保证总和为1，一般我们可以认为Softmax出来的就是confidence也就是概率，算法实现如下： for each batch i and class j we have softmax = exp(logits)/reduce_sum(exp(logits), dim) softmax_cross_entropy_with_logits和sigmoid_cross_entropy_with_logits很不一样，输入是类似的logits和lables的shape一样，但这里要求分类的结果是互斥的，保证只有一个字段有值，例如CIFAR-10中图片只能分一类而不像前面判断是否包含多类动物。想一下问什么会有这样的限制？在函数头的注释中我们看到，这个函数传入的logits是unscaled的，既不做sigmoid也不做softmax，因为函数实现会在内部更高效得使用softmax，对于任意的输入经过softmax都会变成和为1的概率预测值，这个值就可以代入变形的Cross Entroy算法- y * ln(a) – (1 – y) * ln(1 – a)算法中，得到有意义的Loss值了。如果是多目标问题，经过softmax就不会得到多个和为1的概率，而且label有多个1也无法计算交叉熵，因此这个函数只适合单目标的二分类或者多分类问题，TensorFlow函数定义如下: tf.nn.softmax_cross_entropy_with_logits(logits, labels, dim=-1, name=None) # Compute softmax cross entropy between logits and labels # Measures the probability error in discrete classification tasks in which the classes are mutually exclusive (each entry is in exactly one class).For example,each CIFAR-10 image is labeled with one and only one label:an image can be a dog or a cat, but not both. 再补充一点，对于多分类问题，例如我们的年龄分为5类，并且人工编码为0、1、2、3、4，因为输出值是5维的特征，因此我们需要人工做onehot encoding分别编码为00001、00010、00100、01000、10000，才可以作为这个函数的输入。理论上我们不做onehot encoding也可以，做成和为1的概率分布也可以，但需要保证是和为1，和不为1的实际含义不明确，TensorFlow的C++代码实现计划检查这些参数，可以提前提醒用户避免误用。 sparse_softmax_cross_entropy_with_logits sparse_softmax_cross_entropy_with_logits是softmax_cross_entropy_with_logits的易用版本，除了输入参数不同，作用和算法实现都是一样的。前面提到softmax_cross_entropy_with_logits的输入必须是类似onehot encoding的多维特征，但CIFAR-10、ImageNet和大部分分类场景都只有一个分类目标，label值都是从0编码的整数，每次转成onehot encoding比较麻烦，有没有更好的方法呢？答案就是用sparse_softmax_cross_entropy_with_logits，它的第一个参数logits和前面一样，shape是[batch_size, num_classes]，而第二个参数labels以前也必须是[batch_size, num_classes]否则无法做Cross Entropy，这个函数改为限制更强的[batch_size]，而值必须是从0开始编码的int32或int64，而且值范围是[0, num_class)，如果我们从1开始编码或者步长大于1，会导致某些label值超过这个范围，代码会直接报错退出。这也很好理解，TensorFlow通过这样的限制才能知道用户传入的3、6或者9对应是哪个class，最后可以在内部高效实现类似的onehot encoding，这只是简化用户的输入而已，如果用户已经做了onehot encoding那可以直接使用不带“sparse”的softmax_cross_entropy_with_logits函数。 weighted_sigmoid_cross_entropy_with_logits weighted_sigmoid_cross_entropy_with_logits是sigmoid_cross_entropy_with_logits的拓展版，输入参数和实现和后者差不多，可以多支持一个pos_weight参数，目的是可以增加或者减小正样本在算Cross Entropy时的Loss。实现原理很简单，在传统基于sigmoid的交叉熵算法上，正样本算出的值乘以某个系数接口 总结 这就是TensorFlow目前提供的有关Cross Entropy的函数实现，用户需要理解多目标和多分类的场景，根据业务需求（分类目标是否独立和互斥）来选择基于sigmoid或者softmax的实现，如果使用sigmoid目前还支持加权的实现，如果使用softmax我们可以自己做onehot coding或者使用更易用的sparse_softmax_cross_entropy_with_logits函数。 TensorFlow提供的Cross Entropy函数基本cover了多目标和多分类的问题，但如果同时是多目标多分类的场景，肯定是无法使用softmax_cross_entropy_with_logits，如果使用sigmoid_cross_entropy_with_logits我们就把多分类的特征都认为是独立的特征，而实际上他们有且只有一个为1的非独立特征，计算Loss时不如Softmax有效。这里可以预测下，未来TensorFlow社区将会实现更多的op解决类似的问题，我们也期待更多人参与TensorFlow贡献算法和代码 😃 ","link":"https://Angus1996.github.io/post/交叉熵介绍/"},{"title":"dlib安装","content":"安装face_recognition 根据你的python版本输入指令： pip install face_recognition #python2 pip3 install face_recognition #python3 正常来说，安装过程会出错，会在安装dlib时出错，因为pip在编译dlib时会出错，所以我们需要手动编译dlib再进行安装。 先下载dlib的源码 git clone https://github.com/davisking/dlib.git 编译dlib cd dlib mkdir build cd build cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVX_INSTRUCTIONS=1 cmake --build 编译并安装python的拓展包 cd .. python3 setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA 注意： 这个安装步骤是默认认为没有GPU的，所以不支持cuda。 在自己手动编译了dlib后，我们可以在python中import dlib了。 之后再重新安装，就可以配置成功了。 根据python版本输入指令: pip install face_recognition #python2 pip3 install face_recognition #python3 ","link":"https://Angus1996.github.io/post/dlib安装/"},{"title":"数模大全思维导图","content":"数学建模思维导图 美赛2018年前夕，阅读数模大全，做成思维导图仅供参考！。 ","link":"https://Angus1996.github.io/post/数模大全思维导图/"},{"title":"python lambda表达式简单用法","content":"lambda简介 条件运算时，对于简单的if else 语句，可以使用三元运算来表示，即： # 普通条件语句 if 1==1: name = 'angus' else: name = 'anna' # 三次元运算 name = 'angus' if 1==1 else 'anna' 对于简单的函数，也存在一种简便的表示方式，即：lambda 表达式 # *****************普通函数***************** # 定义函数（普通方式） def func(arg): return arg + 1 # 执行函数 result = func(123) # *******************lambda***************** #定义函数（lambda表达式） my_lambda = lambda arg: arg + 1 # 执行函数 result = my_lambda(123) lambda 存在意义就是对简单函数的简洁表示 内置函数与lambda 一、map 遍历序列，对序列中每个元素进行操作，最终获取新的序列。 # 示例1 li = [11, 22, 33] new_list = map(lambda a : a + 100, li) # 示例2 li = [11, 22, 33] s1 = [1, 2, 3] new_list = map(lambda a, b : a + b, li, s1) 二、filter 对于序列中的元素进行筛选，最终获取符合条件的序列 li = [11, 22, 33] new_list = filter(lambda arg: arg &gt; 22, li) #filter第一个参数为空，将获取原来序列 三、reduce 对于序列内所有元素进行累计操作 li = [11, 22, 33] result = reduce(lambda arg1, arg2: arg1 + arg2, li) # reduce的第一个参数，函数必须要有两个参数 # reduce的第二个参数，要循环的序列 # reduce的第三个参数，初始值 ","link":"https://Angus1996.github.io/post/python-lambda表达式简单用法/"},{"title":"爬虫基本原理","content":"爬虫基本流程 发起请求 通过HTTP库向目标站点发起请求，即发送一个Request，请求可以包含额外的headers等信息，等待服务器响应。 获取响应内容 如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，类型可能有HTML，Json字符串，二进制数据（如图片视频）等类型。 解析内容 得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析。可能是Json，可以直接转为Json对象解析。可能是二进制数据，可以做保存或者进一步的处理。 保存数据 保存形多样，可以存为文本，也可以保存至数据库，或者保存特定格式的文件。 Request与Response （1）浏览器发送消息给该网址所在的服务器，这个过程叫做HTTP Request。 （2）服务器收到浏览器发送的消息后，能够根据浏览器发送消息的内容，做响应处理，然后把消息回传给浏览器。这个过程叫做HTTP Response。 （3）浏览器收到服务器的Response信息后，会对信息进行相应处理，然后展示。 Request 请求方式 主要有GET、POST两种类型，另外还有HEAD、PUT、DELETE、OPTIONS等。 GET请求将参数放在URL中，POST请求的参数包含在form data中。 请求URL URL全称统一资源定位符，如一个网页文档、一张图片、一个视频等都可以用URL唯一来确定。 请求头 包含请求时的头部信息，如User-agent、Host、Cookies等信息。键值对形式。 请求体 请求时额外携带的数据，如表单提交时的表单数据。 Response 响应状态 有多种响应状态，如200表示成功、301跳转、404找不到页面、502服务器错误。 响应头 如内容类型、内容长度、服务器信息、设置Cookie等等。 响应体 最主要的部分，包含了请求资源的内容，如网页HTML、图片二进制数据等。 能抓怎样的数据 网页文本 如HTML文档、Json格式文本 图片 获取到的是二进制文件，保存到图片格式就可以了 视频 同为二进制文件，保存为视频格式即可。 其他 只要是能请求到的，都能获取。 怎么样解析？ 直接处理 Json解析 通过AJAX加载的 正则表达式 BeautifulSoup PyQuery Xpath 为什么我抓到的数据和浏览器看到的不一样？ AJAX接口异步请求，JS渲染 怎样解决JS渲染的问题？ 分析Ajax请求 分析返回的json Selenium/WebDriver from selenium import webdriver driver = webdriver.Chrome() driver.get('http://m.weibo.com') # 得到和element一样的源代码 print(driver.page_source) Splash ,也是模拟JS渲染的 PyV8、Ghost.py 怎么样保存数据 文本 纯文本、Json、Xml等。 关系型数据库 如MySQL、Oracle、SQL Server等具有结构化表结构形式存储。 非关系型数据库 如MongoDB、Redis等Key-Value形式存储。 二进制文件 如图片、视频、音频等等直接保存成特定格式即可。 ","link":"https://Angus1996.github.io/post/爬虫基本原理/"},{"title":"想你","content":"2007年的圣诞前夕，天空中飘着雪。 昏黄的路灯下，十几阶的楼梯上，你叫住了我。 送了我一盏灯，说，圣诞快乐。 从此，再也没有下雪的圣诞节。 就像你再也不在我身边。 我怀恋与你同桌的日子， 怀恋会吃你醋的日子， 怀恋能看你午睡时候可爱模样的日子， 怀恋晚自习上你递给我的阿尔卑斯糖。 超市里的阿尔卑斯糖， 没有递给我吃的草莓味。 可我嘴里依旧有它的味道。 现在，每当沮丧，失望难过时， 那盏灯会出现在脑海里。 小小的房间，投影出星星与长窗， 温暖而有希望。 不知道你现在过得怎么样， 只希望别在半夜醒来。 我还有灯， 看着你的灯， 心里有光，梦里有你，脸上有笑。 ","link":"https://Angus1996.github.io/post/想你/"},{"title":"最美好的事","content":" 《最美好的事》 春日晴空下的微风 夏夜星空下的蝉鸣 秋日暖阳下的果实 冬夜路灯下的飘雪 ** 以及 十五岁的我 和，六年后 遇见的二十岁的你 ","link":"https://Angus1996.github.io/post/最美好的事/"},{"title":"Problems when using Hexo","content":"使用Hexo deploy 自动部署到github page的时候出现了错误： FATAL bash: /dev/tty: No such device or address error: failed to execute prompt script (exit code 1) fatal: could not read Username for 'https://github.com': Invalid argument Error: bash: /dev/tty: No such device or address error: failed to execute prompt script (exit code 1) fatal: could not read Username for 'https://github.com': Invalid argument 最后把_config.yml 中git仓库链接改成了ssh链接，然后给git账户增加了ssh key才解决了问题。 生成 ssh key 命令行中输入： ssh-key -t rsa -C anguscaiwuhan@qq.com $ ssh-keygen -t rsa -C 884816034@qq.com Generating public/private rsa key pair. Enter file in which to save the key (/c/Users/Angus/.ssh/id_rsa): id_rsa.pub Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in id_rsa.pub. Your public key has been saved in id_rsa.pub.pub. The key fingerprint is: SHA256:48wDY7QtaIxCNDHQPBBomRZo8bLZ2nIUS79Orgmccww 884816034@qq.com The key's randomart image is: +---[RSA 2048]----+ |B%* | |+*B | |+o = . | |. *o+o o | |.E.++.* S | |..B. ..B . | | B = o = | | * = . | | o.o | +----[SHA256]-----+ 这样在/c/Users/Angus/.ssh/id_rsa文件中就生成了公钥。 配置github账户的ssh key 打开id_rsa.pub文件将一整串公钥拷贝下来 进入你的github账户设置，在ssh and GPG keys中新增一个ssh key 验证ssh key ssh -T git@github.com 出现下面的语句就说明的ssh key已经配置好了 Hi Angus1996! You've successfully authenticated, but GitHub does not provide she ll access. 修改站点配置文件 将仓库修改为ssh链接，如下： deploy: type: git repository: git@github.com:Angus1996/Angus1996.github.io.git branch: master 到此就可以一如往常使用hexo d更新博客站点了。 ","link":"https://Angus1996.github.io/post/Problems-when-using-Hexo/"},{"title":"机器学习的几种方式","content":"1. 在线学习&amp;离线学习 离线学习中，在模型训练的阶段，所有的训练数据必须是可得到的。只有当模型训练完成后，模型才能够用来做预测问题。 相反地，在线算法序列般地处理数据。在一开始没有完整训练数据集的情况下，产生一个模型并将其放入操作当中。这个模型是随着数据的到达而连续更新的。 2. 增量学习&amp;减量学习 incremental learning增量学习，是指一个学习系统能不断地从新样本中学习新的知识,并能保存大部分以前已经学习到的知识。增量学习非常类似于人类自身的学习模式。因为人在成长过程中,每天学习和接收新的事物,学习是逐步进行的,而且,对已经学习到的知识,人类一般是不会遗忘的。 Less restrictive than online algorithms are incremental algorithms that process input examples one by one (or batch by batch) and update the decision model after receiving each example. Incremental algorithms may have random access to previous examples or representative/selected examples. In such a case, these algorithms are called in- cremental algorithms with partial memory. Typically, in incremental algorithms, for any new presentation of data, the update operation of the model is based on the previous one. Streaming algorithms are online algorithms for processing high-speed continuous flows of data. In streaming, examples are processed sequentially as well and can be examined in only a few passes (typically just one). These algorithms use limited memory and limited processing time per item. 一个增量学习算法应同时具有以下特点: 1)可以从新数据中学习新知识; 2)以前已经处理过的数据不需要重复处理; 3)每次只有一个训练观测样本被看到和学习; 4)学习新知识的同时能保存以前学习到的大部分知识; 5)—旦学习完成后训练观测样本被丢弃; 6)学习系统没有关于整个训练样本的先验知识; 增量式算法：就是每当新增数据时，并不需要重建所有的知识库，而是在原有知识库的基础上，仅做由于新增数据所引起的更新，这更加符合人的思维原理。 decremental learning递减学习，即抛弃“价值最低”的保留的训练样本。这两个概念在incremental and decremental svm这篇论文里面可以看到具体的操作过程。 3.主动学习&amp;直推学习 主动学习(active learning)，指的是这样一种学习方法：有的时候，有类标的数据比较稀少而没有类标的数据是相当丰富的，但是对数据进行人工标注又非常昂贵，这时候，学习算法可以主动地提出一些标注请求，将一些经过筛选的数据提交给专家进行标注。 这个筛选过程也就是主动学习主要研究的地方了，怎么样筛选数据才能使得请求标注的次数尽量少而最终的结果又尽量好。 主动学习的过程大致是这样的，有一个已经标好类标的数据集K(初始时可能为空)，和还没有标记的数据集U，通过K集合的信息，找出一个U的子集C，提出标注请求，待专家将数据集C标注完成后加入到K集合中，进行下一次迭代。 按wiki上所描述的看，主动学习也属于半监督学习的范畴了，但实际上是不一样的，半监督学习和直推学习(transductive learning)以及主动学习，都属于利用未标记数据的学习技术，但基本思想还是有区别的。如上所述，主动学习的“主动”，指的是主动提出标注请求，也就是说，还是需要一个外在的能够对其请求进行标注的实体(通常就是相关领域人员)，即主动学习是交互进行的。 而半监督学习，特指的是学习算法不需要人工的干预，基于自身对未标记数据加以利用。 直推学习，它与半监督学习一样不需要人工干预，不同的是，直推学习假设未标记的数据就是最终要用来测试的数据，学习的目的就是在这些数据上取得最佳泛化能力。相对应的，半监督学习在学习时并不知道最终的测试用例是什么。 也就是说，直推学习其实类似于半监督学习的一个子问题，或者说是一个特殊化的半监督学习，所以也有人将其归为半监督学习。 4.迁移学习 Less restrictive than online algorithms are incremental algorithms that process input examples one by one (or batch by batch) and update the decision model after receiving each example. Incremental algorithms may have random access to previous examples or representative/selected examples. In such a case, these algorithms are called in- cremental algorithms with partial memory. Typically, in incremental algorithms, for any new presentation of data, the update operation of the model is based on the previous one. Streaming algorithms are online algorithms for processing high-speed continuous flows of data. In streaming, examples are processed sequentially as well and can be examined in only a few passes (typically just one). These algorithms use limited memory and limited processing time per item. 在传统的机器学习的框架下，学习的任务就是在给定充分训练数据的基础上来学习一个分类模型；然后利用这个学习到的模型来对测试文档进行分类与预测。然而，我们看到机器学习算法在当前的Web挖掘研究中存在着一个关键的问题：一些新出现的领域中的大量训练数据非常难得到。我们看到Web应用领域的发展非常快速。大量新的领域不断涌现，从传统的新闻，到网页，到图片,再到博客、播客等等。传统的机器学习需要对每个领域都标定大量训练数据，这将会耗费大量的人力与物力。而没有大量的标注数据，会使得很多与学习相关研究与应用无法开展。其次，传统的机器学习假设训练数据与测试数据服从相同的数据分布。然而，在许多情况下，这种同分布假设并不满足。通常可能发生的情况如训练数据过期。这往往需要我们去重新标注大量的训练数据以满足我们训练的需要，但标注新数据是非常昂贵的，需要大量的人力与物力。从另外一个角度上看，如果我们有了大量的、在不同分布下的训练数据，完全丢弃这些数据也是非常浪费的。如何合理的利用这些数据就是迁移学习主要解决的问题。迁移学习可以从现有的数据中迁移知识，用来帮助将来的学习。迁移学习（Transfer Learning）的目标就是将从一个环境中学到的知识用来帮助新环境中的学习任务。因此，迁移学习不会像传统机器学习那样作同分布假设。举一个通俗的例子，一个会下象棋的人可以更容易的学会下围棋；一个认识桌子的人可以更加容易的认识椅子； 在迁移学习方面的工作目前可以分为以下三个部分：同构空间下基于实例的迁移学习，同构空间下基于特征的迁移学习与异构空间下的迁移学习。基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广泛的知识迁移能力，而异构空间的迁移具有广泛的学习与扩展能力。 迁移学习即一种学习对另一种学习的影响，它广泛地存在于知识、技能、态度和行为规范的学习中。任何一种学习都要受到学习者已有知识经验、技能、态度等的影响，只要有学习，就有迁移。迁移是学习的继续和巩固，又是提高和深化学习的条件，学习与迁移不可分割。 5.出处 作者：Scofield 链接：https://www.zhihu.com/question/38713098/answer/161717769 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ","link":"https://Angus1996.github.io/post/机器学习的几种方式/"},{"title":"大三暑假实习——ionic应用开发","content":"度益科技有限公司个人办公APP 需求&amp;功能实现&amp;进度安排 截图 ","link":"https://Angus1996.github.io/post/大三暑假实习——ionic应用开发/"},{"title":"夏朦的故事","content":"​ 快十年了，我们都改变了很多！ ​ 今天在自习室看到一个女生的侧脸，不是惊艳的美好，只是分外的熟悉。我想起了小学六年级的一个同桌。 ​ 那时候的老师十分严厉，体罚这一说似乎还没有被社会提出来，老师打人是十分平常的事。家长呢，本着孩子不打不成才的观点，对于老师对自己孩子的打骂，也并没有一点反抗意识。2007年秋季到2008年夏季，一条教鞭窜起了师生之间的共同记忆。那时候的教鞭是用白色的包装带做的，好多根包装带叠在一起，再用透明胶粘起来。一条不太硬也不太软、打起人来却很疼的教鞭就完成了。不知道是哪路大罗神仙想出来这种主意。从四大发明开始，可能中国人中从来不缺能发明东西的人。 ​ 记忆中，她是被班主任——一个矮胖女人用教鞭打过最多的人之一。印象中有一次她的头发都被班主任揪着要把她拖出教室，班主任口中喊着“滚回去，上什么学，什么都不会！”那个时候，不会似乎成了一种罪过，会被判刑。审判的是老师，执行的也是老师，老师似乎变得十分厉害，一人兼职好多角色。即使老师在办公室叫来了她的母亲，也并没有因为母亲在场而减弱了气势，倒像是来了一个一同讨伐她的帮手。 ​ 即使在那样的日子里，她依然会笑。笑得很灿烂，很美好。一如那揪不断的头发，坚韧、坚强。我不懂为什么是这样，虽然她是我的同桌，可是我却不敢问！因为那段日子里我俨然是老师的得力助手，白色的教鞭也经常被我握在手里，“煞是威风”。成绩好而成为“上层人”，成绩差而被口诛笔伐，这是老师心里的标准。 ​ 虽然并不是每个老师都会像班主任那般肆无忌惮，可是每个老师“恨铁不成钢”的总会多少带点这种习惯。 ​ 前年过年去超市买年货，看见了她，依旧是那副脸庞，身材却纤细了，也长高了。她在那里做导购员，我不知道是兼职还是固定职业，我一年也不会逛几次。也没有上前打招呼，横在我们两个中间的是那条白色的教鞭和她那灿烂的笑容。 ​ 我也曾看过许多小时候被老师严重体罚过的同学，慢慢的同社会的地痞流氓开始鬼混，烟酒成了生活的必须。初中有一次，一个小学同学在路边朝我吐了一口烟气，似乎在向我耀武扬威。”你这可怜的人还泡在读书的苦海里，看我多潇洒。”面对那口烟我不知如何应对，只好匆匆走开，本来也是好几年没说过话的同学了。堕落成了生活痛苦的唯一出口，那是他们找到的答案。 ​ 虽然我也曾堕落过，见过许多“大哥”，小学跟着班里的老大混。可那样的日子却只是一时快乐，却能给自己伤害的人带来阴影，给爱自己的人带来失望。很庆幸我并没有在那条路上走得太远。 ​ 生活从来不是胜者为王，败者为寇！堕落也不会是痛苦的真正出口。真正失败的是失去了生活下去的信心与勇气。真正的出口是笑着面对生活给予的一切。即使面对生活中的狂风暴雨，依旧能笑得出来。那是她——夏朦的故事。 ","link":"https://Angus1996.github.io/post/夏朦的故事/"},{"title":"屏幕前的孤独玩家","content":"半夜醒来后再难以入睡，第一感觉就是拿起手机，不知道想干嘛。翻着手机空间，每个好友在我睡着期间又发生了什么。这是一个人对外部世界正常的好奇心。 屏幕前的我，与屏幕前的你，因为移动互联网而得以联系。如果没有互联网呢，是否还会愿意费力去联系？ 人为什么要与他人联系？因为孤独感使然。我记得初中摘抄一个同学的读书笔记，里面有亚里士多德这么一句话“喜欢孤独的不是上帝就是野兽”。这句话描述了人性深处的是害怕孤独，讨厌孤独的。最近看了点圣经，创世纪里耶和华神在造了亚当后说“那人独居不好，我要为他造一个配偶帮助他”。男女关系就这样成了。亚当也不再孤独。中国神话里关于男女关系的起源有没有类似的我不知道。这句话值得深思，上帝说独居不好那就真的不好？上帝想到了找个配偶帮助他，难道上帝也不喜欢孤独？如果连上帝都不喜欢孤独，人又何德何能说自己喜欢孤独呢？ 正是孤独感让我们在一起，成为屏幕前的玩家。可是人又有得寸进尺的习性，在正确的人身上是积极进取，在平庸的人身上便是一种恶习劣根。拥有了成百上千个网友又如何？想要找到一个人化解自己的孤独还不是那么的困难。于是出现了一个怪状:我们因为孤独选择了手机，却成了手机前的孤独玩家，孤独有时并找不到出路。 像一头被关起来的猛兽，肆意挣扎却难以逃脱。没有钥匙或者有错误钥匙的人，接近它却打不开它，反而成了一种挑衅。只待一个对的人拿着一把正确的钥匙。打开了囚笼，慢慢抚慰名为孤独的猛兽，最后放走了它，让它再也不用挣扎。可是人有千千万万，钥匙却只有一把！ ","link":"https://Angus1996.github.io/post/屏幕前的孤独玩家/"},{"title":"关于","content":"博主个人信息页面，想了解我的，点进来啊😬 欢迎来到我的小站呀❤️，很高兴遇见你！🤝 🏠 关于本站 一个记录与分享的地方。希望对进来的人都有所帮助，也希望自己能够在分享中成长！ 👨‍💻 博主是谁 • 2014年9月—2018年6月，Hust EIC 电子信息工程，本科生； • 2018年9月—2021年6月，Hust EIC 信息与通信工程，硕士研究生；研究方向主要是机器学习、深度学习、信息安全 • 2021年7月1日-至今，阿里巴巴集团CRO线-安全工程师 🚀 个人荣誉 • 2017 年华中地区数学建模邀请赛经典组三等奖； • 2016-2017 学年度国家励志奖学金； • 2018 年美国大学生数学建模竞赛Meritorious Winner(一等奖)； • 2018 年 6 月获华中科技大学 2018 届优秀毕业生荣誉称号； • 2018 年本科毕设《基于生成对抗网络的图像修复研究与实现》获华中科技大学 2018 届优秀毕业设计（论文）奖； • 2019 AIIA 杯-航天科工站火眼金睛大战七十二变(对抗样本攻防) 第三名(队伍：机器学习从入门到放弃 )，奖金5000元； • 2019 CCF-大数据与计算智能大赛-蚂蚁金服多人种人脸识别赛题第 24/919 名(队伍：angusaha)； • 2019“华为云杯”人工智能创新应用大赛(图像分类)第50/723名(队伍：关山口小队)； • 2020年研究生国家奖学金 📄发表论文 [1] W. Yuan, Y. Jiang, H. Li and M. Cai, &quot;A Lightweight On-Device Detection Method for Android Malware,&quot; in IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 51, no. 9, pp. 5600-5611, Sept. 2021, doi: 10.1109/TSMC.2019.2958382. （JCR Q1，中科院一区，IF=13.451/2020) [2] M. Cai, Y. Jiang, C. Gao, H. Li and W. Yuan, &quot;Learning features from enhanced function call graphs for android malware detection&quot;. Neurocomputing, vol. 423, pp. 301-307, 2021.（JCR Q1，中科院二区top，IF=5.719/2020） ⛹ 兴趣爱好 读书、跑步、骑行、K歌、吃东西（没错！！就是吃东西） 📬 联系我呀 cai_minghui@qq.com，欢迎骚扰 ","link":"https://Angus1996.github.io/post/about/"}]}